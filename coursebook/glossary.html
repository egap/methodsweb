<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Methods for Impact Evaluations – glossary</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../img/egap-logo.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Methods for Impact Evaluations</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../guides.html">
 <span class="menu-text">Guides</span></a>
  </li>  
  <li class="dropdown-header">
 <span class="menu-text">about.qmd</span></li>
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#appendix-appendix" id="toc-appendix-appendix" class="nav-link active" data-scroll-target="#appendix-appendix">(APPENDIX) Appendix</a></li>
  <li><a href="#glossary-of-terms" id="toc-glossary-of-terms" class="nav-link" data-scroll-target="#glossary-of-terms">Glossary of Terms</a>
  <ul class="collapse">
  <li><a href="#key-concepts" id="toc-key-concepts" class="nav-link" data-scroll-target="#key-concepts">Key Concepts</a></li>
  <li><a href="#statistical-inference" id="toc-statistical-inference" class="nav-link" data-scroll-target="#statistical-inference">Statistical Inference</a></li>
  <li><a href="#randomization-strategies" id="toc-randomization-strategies" class="nav-link" data-scroll-target="#randomization-strategies">Randomization Strategies</a></li>
  <li><a href="#factorial-designs" id="toc-factorial-designs" class="nav-link" data-scroll-target="#factorial-designs">Factorial Designs</a></li>
  <li><a href="#threats" id="toc-threats" class="nav-link" data-scroll-target="#threats">Threats</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="appendix-appendix" class="level1 unnumbered">
<h1 class="unnumbered">(APPENDIX) Appendix</h1>
</section>
<section id="glossary-of-terms" class="level1 tabset">
<h1 class="tabset">Glossary of Terms</h1>
<p>Below are some core terms frequently used throughout the book and more broadly in discussions of randomized field experiments.</p>
<section id="key-concepts" class="level2">
<h2 class="anchored" data-anchor-id="key-concepts">Key Concepts</h2>
<p>See the module on <a href="causal-inference.html">causal inference</a>, <a href="estimands-and-estimators.html">estimands and estimators</a>.</p>
<ul>
<li><strong>Potential outcome <span class="math inline">\(Y_i(T)\)</span></strong> The outcome <span class="math inline">\(Y\)</span> that unit <span class="math inline">\(i\)</span> <em>would</em> have under treatment condition <span class="math inline">\(T\)</span>. We think of these as fixed quantities for a specific point in time. <span class="math inline">\(T\)</span> can be 0 for control or 1 for treatment if there is only one type of treatment. See the module on <a href="causal-inference.html">causal inference</a>.</li>
<li><strong>Treatment effect <span class="math inline">\(\tau_i\)</span> for unit <span class="math inline">\(i\)</span></strong> The contrast between potential outcomes under two treatment conditions for unit <span class="math inline">\(i\)</span>. We typically define the treatment effect as the difference in potential outcomes under treatment and control, <span class="math inline">\(Y_i(1)-Y_i(0)\)</span>. See the module on <a href="causal-inference.html">causal inference</a>.</li>
<li><strong>Fundamental problem of causal inference</strong> in the counterfactual framework. We can’t observe both <span class="math inline">\(Y_i(1)\)</span> and <span class="math inline">\(Y_i(0)\)</span> for a given unit, so we can’t get <span class="math inline">\(\tau_i\)</span> directly. See the module on <a href="causal-inference.html">causal inference</a>.</li>
<li><strong>Estimand</strong> The thing you want to estimate. An example of an estimand is the average treatment effect. In counterfactual causal inference, this is a function of potential outcomes, not fully observed outcomes. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
<li><strong>Estimator</strong> How you make a guess about the value of your estimand from the data you have (i.e., observed). An example of an estimator is the difference-in-means. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.
<ul>
<li><strong>Average treatment effect, ATE</strong> The average of the treatment effect for all individuals in your subject pool. This is a type of <strong>estimand</strong>. If we define <span class="math inline">\(\tau_i\)</span> to be <span class="math inline">\(Y_i(1)-Y_i(0)\)</span>, then the ATE is <span class="math inline">\(\overline{Y_i(1)-Y_i(0)}\)</span>, which is also equivalent to <span class="math inline">\(\overline{{Y}_i(1)}-\overline{{Y}_i(0)}\)</span>. Notice that we do not use the <span class="math inline">\(E[Y_i (1)]\)</span> style of notation here because <span class="math inline">\(E[]\)</span> means “average over repeated operations,” but <span class="math inline">\(\overline{Y}\)</span> means “average over a set of observations”. See the module on <a href="causal-inference.html">causal inference</a> and the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
</ul></li>
<li><strong>Random sampling</strong> Selecting subjects from a population with known probabilities strictly between 0 and 1.</li>
<li><strong><span class="math inline">\(k\)</span>-arm experiment</strong> An experiment that has <span class="math inline">\(k\)</span> treatment conditions (including control). See the module on <a href="randomization.html">randomization</a>.</li>
<li><strong>Random assignment</strong> Assigning subjects to experimental conditions with known probabilities strictly between 0 and 1. This is equivalent to random sampling without replacement from the potential outcomes. There are several strategies for random assignment: simple, complete, cluster, block, blocked-cluster. See the module on <a href="randomization.html">randomization</a>.</li>
<li><strong>External validity</strong> Findings from your study teach you about contexts outside of your sample — in other locations or for other interventions.</li>
</ul>
</section>
<section id="statistical-inference" class="level2">
<h2 class="anchored" data-anchor-id="statistical-inference">Statistical Inference</h2>
<p>See modules on <a href="hypothesis-testing.html">hypothesis testing</a> and <a href="statistical-power-and-design-diagnosands.html">statistical power</a>.</p>
<ul>
<li><strong>Hypothesis</strong> A simple, clear, falsifiable claim about the world. In counterfactual causal inference, this is a statement about a relationship among potential outcomes, like <span class="math inline">\(H_0: Y_i(T_i=0) = Y_i(T_i=1) + \tau_i\)</span> for the hypothesis that the potential outcome under treatment is the potential outcome under control plus some effect for each unit <span class="math inline">\(i\)</span>. See the module on <a href="hypothesis-testing.html">hypothesis testing</a>.</li>
<li><strong>Null hypothesis</strong> A conjecture about the world that you may reject after seeing the data. See the module on <a href="hypothesis-testing.html">hypothesis testing</a>.</li>
<li><strong>Sharp null hypothesis of no effect</strong> The null hypothesis that there is no treatment effect for any subject. This means <span class="math inline">\(Y_i(1)=Y_i(0)\)</span> for all <span class="math inline">\(i\)</span>. We might write this as <span class="math inline">\(H_0: Y_i(T_i=0) = Y_i(T_i=1)\)</span>. See the module on <a href="hypothesis-testing.html">hypothesis testing</a>.</li>
<li><strong><span class="math inline">\(p\)</span>-value</strong> The probability of seeing a test statistic as large (in absolute value) as or larger than the test statistic calculated from observed data. See the module on <a href="hypothesis-testing.html">hypothesis testing</a>.</li>
<li><strong>One-sided vs.&nbsp;two-sided test</strong> When you have a strong expectation that the effect is either positive or negative, you can conduct a one-sided test. When you do not have such a strong expectation, conduct a two-sided test. A one-sided test has more power than a two-sided test for the same experiment. See the module on <a href="hypothesis-testing.html">hypothesis testing</a>.</li>
<li><strong>Standard deviation</strong> Square root of the mean-square deviation from the average of a variable. It is a measure of the dispersion or spread of a statistic. <span class="math inline">\(SD_x=\sqrt{\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2}\)</span></li>
<li><strong>False Positive Rate/Type I Error of a Test</strong> A well-operating hypothesis test rejects a hypothesis about a true causal effect no more than <span class="math inline">\(\alpha\)</span> % of the time. The false positive rate is the rate at which a test will cast doubt on a true hypothesis. It is the rate at which the test will encourage the analyst to say “statistically significant” when, in fact, there is no causal relationship. See the module on <a href="hypothesis-testing.html">hypothesis testing</a>.</li>
<li><strong>Sampling distribution</strong> The distribution of estimates (e.g., estimates of the ATE) for all possible treatment assignments. In design-based statistical inference for randomized experiments, the distribution of estimates from an estimator is generated from randomizations. Many call this a “sampling distribution” because textbooks often use the idea of repeated samples from a population rather than repeated randomizations to describe this kind of variation.</li>
<li><strong>Standard error</strong> The standard deviation of the sampling distribution. A bigger standard error means that our estimates are more susceptible to sampling variation. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
<li><strong>Coverage of a confidence interval</strong> A well-operating confidence interval contains the true causal effect <span class="math inline">\(100 ( 1 - \alpha)\)</span> % of the time. A confidence interval has <em>incorrect coverage</em> when it excludes the true parameter less than <span class="math inline">\(100 (1 - \alpha)\)</span>% of the time. For example, a 95% confidence interval is supposed to only exclude the true parameter less than 5% of the time.</li>
<li><strong>Statistical power of a test</strong> Probability that a test of causal effects will detect a statistically significant treatment effect if the effect exists. See the module on <a href="statistical-power-and-design-diagnosands.html">statistical power</a>. This depends on:
<ul>
<li>The number of observations in each arm of the experiment</li>
<li>Effect size (usually measured in standardized units)</li>
<li>Noisiness of the outcome variable</li>
<li>Significance level (<span class="math inline">\(\alpha\)</span>, which is fixed by convention)</li>
<li>Other factors including what proportion of your units are assigned to different treatment conditions.</li>
</ul></li>
<li><strong>Intra-cluster correlation</strong> How correlated the potential outcomes of units are within clusters compared to across clusters. Higher intra-cluster correlation hurts power.</li>
<li><strong>Unbiased</strong> An estimator is unbiased if you <em>expect</em> that it will return the right outcome. That means that if you were to run the experiment many times, the estimate might be too high or to low sometimes but it will be right on average. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
<li><strong>Bias</strong> Bias is the difference between the average value of the estimator across its sampling distribution and the single, fixed value of the estimand. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
<li><strong>Consistency of an estimator</strong> An estimator that produces answers that become ever nearer to the true value of the estimand as the sample size increases is a <em>consistent estimator</em> of that estimand. A consistent estimator may or may not be unbiased. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
<li><strong>Precision/Efficiency of an estimator</strong> The variation in or width of the sampling distribution of an estimator. See the module on <a href="estimands-and-estimators.html">estimands and estimators</a>.</li>
</ul>
</section>
<section id="randomization-strategies" class="level2">
<h2 class="anchored" data-anchor-id="randomization-strategies">Randomization Strategies</h2>
<p>See the module on <a href="randomization.html">randomization</a>.</p>
<ul>
<li><strong>Simple</strong> An independent coin flip for each unit. You are not guaranteed that your experiment will have a specific number of treated units.</li>
<li><strong>Complete</strong> Assign <span class="math inline">\(m\)</span> out of <span class="math inline">\(N\)</span> units to treatment. You know how many units will be treated in your experiment and each unit has a <span class="math inline">\(m/N\)</span> probability of being treated. The number of ways treatment can be assigned (number of permutations of treatment assignment) is <span class="math inline">\(\frac{N!}{m!(N-m)!}\)</span>.</li>
<li><strong>Block</strong> First divide the sample into blocks, then do complete randomization separately in each block. A block is a set of units within which you conduct random assignment.</li>
<li><strong>Cluster</strong> Clusters of units are randomly assigned to treatment conditions. A cluster is a set of units that will always be assigned to the same treatment status.</li>
<li><strong>Blocked-Cluster</strong> First form blocks of clusters. Then in each block, randomly assign the clusters to treatment conditions using complete randomization.</li>
</ul>
</section>
<section id="factorial-designs" class="level2">
<h2 class="anchored" data-anchor-id="factorial-designs">Factorial Designs</h2>
<p>See the module on <a href="randomization.html">randomization</a>.</p>
<ul>
<li><strong>Factorial design</strong> A design with more than one treatment, with each treatment assigned independently. The simplest factorial design is a 2 by 2.</li>
<li><strong>Conditional marginal effect</strong> The effect of one treatment, conditional on the other being held at a fixed value. For example: <span class="math inline">\(Y_i(T_1=1|T_2=0)-Y_i(T_1=0|T_2=0)\)</span> is the marginal effect of <span class="math inline">\(T_1\)</span> conditional on <span class="math inline">\(T_2=0\)</span>.</li>
<li><strong>Average marginal effect</strong> Main effect of each treatment in a factorial design. It is the average of the conditional marginal effects for all the conditions of the other treatment, weighted by the proportion of the sample that was assigned to each condition.</li>
<li><strong>Interaction effect</strong> In a factorial design, we may also estimate interaction effects.
<ul>
<li>No interaction effect: one treatment does not amplify or reduce the effect of the other treatment.</li>
<li>Multiplicative interaction effect: the effect of one treatment depends on which condition a unit was assigned for the other treatment. This means one treatment <em>does</em> amplify or reduce the effect of the other. The effect of two treatments together is <em>not</em> the sum of the effect of each treatment.</li>
</ul></li>
</ul>
</section>
<section id="threats" class="level2">
<h2 class="anchored" data-anchor-id="threats">Threats</h2>
<p>See the module on <a href="threats-to-internal-validity-of-randomized-experiments.html">threats</a>.</p>
<ul>
<li><strong>Hawthorne effect</strong> When a subject responds to being observed.</li>
<li><strong>Spillover</strong> When a subject responds to another subject’s treatment status. Example: my health depends on whether my neighbor is vaccinated, as well as whether I am vaccinated.</li>
<li><strong>Attrition</strong> When outcomes for some subjects are not measured. This might be caused, for example, by people migrating, refusing to respond to endline surveys, or dying. This is especially problematic for inference when it is correlated with treatment status.</li>
<li><strong>Compliance</strong> A unit’s treatment status matches its assigned treatment condition. Example of non-compliance: a unit assigned to treatment doesn’t take it. Example of compliance: a unit assigned to control does not take treatment.</li>
<li><strong>Compliance types</strong> There are four types of units in terms of compliance:
<ul>
<li><strong>Compliers</strong> Units that would take treatment if assigned to treatment and would be untreated if assigned to control.</li>
<li><strong>Always-takers</strong> Units that would take treatment if assigned to treatment and if assigned to control.</li>
<li><strong>Never-takers</strong> Units that would be untreated if assigned to treatment and if assigned to control.</li>
<li><strong>Defiers</strong> Units that would be untreated if assigned to treatment and would take treatment if assigned to control.</li>
</ul></li>
<li><strong>One-sided non-compliance</strong> The experiment has only compliers and <em>either</em> always-takers or never-takers. Usually, we think of one-sided non-compliance as having only never-takers and compliers, meaning that that local average treatment effect is the effect of treatment on the treated.</li>
<li><strong>Two-sided non-compliance</strong> The experiment may have all four latent groups.</li>
<li><strong>Encouragement design</strong> An experiment that randomizes <span class="math inline">\(T\)</span> (treatment assignment), and we measure <span class="math inline">\(D\)</span> (whether the unit takes treatment) and <span class="math inline">\(Y\)</span> (outcome). We can estimate the ITT and the LATE (local average treatment effect, aka CACE—complier average causal effect). It requires three assumptions.
<ul>
<li><strong>Monotonicity</strong> Assumption of either no defiers or no compliers. Usually we assume no defiers which means that the effect of assignment on take up of treatment is either positive or zero but not negative.</li>
<li><strong>First stage</strong> Assumption that there is an effect of <span class="math inline">\(T\)</span> on <span class="math inline">\(D\)</span>.</li>
<li><strong>Exclusion restriction</strong> Assumption that <span class="math inline">\(T\)</span> affects <span class="math inline">\(Y\)</span> only through <span class="math inline">\(D\)</span>. This is usually the most problematic assumption.</li>
</ul></li>
<li><strong>Intention-to-treat effect (ITT)</strong> The effect of <span class="math inline">\(T\)</span> (treatment assignment) on <span class="math inline">\(Y\)</span>.</li>
<li><strong>Local average treatment effect (LATE)</strong> The effect of <span class="math inline">\(D\)</span> (taking treatment) on <span class="math inline">\(Y\)</span> for compliers. Also known as the complier average causal effect (CACE). Under the exclusion restriction and monotonicity, the LATE is equal to ITT divided by the proportion of your sample who are compliers.</li>
<li><strong>Downstream experiment</strong> An encouragement design study that takes advantage of the randomization of <span class="math inline">\(T\)</span> by a previous study. The outcome from that previous study is the <span class="math inline">\(D\)</span> in the downstream experiment.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>