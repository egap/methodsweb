[
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Methods guides",
    "section": "",
    "text": "Macartan Humphreys\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDonald Green & Molly Offer-Westort\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLindsay Dolan\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides.html#planning-research-and-evaluations",
    "href": "guides.html#planning-research-and-evaluations",
    "title": "Methods guides",
    "section": "Planning research and evaluations",
    "text": "Planning research and evaluations\n\n\n\n\n\n\n\n\n\n\n10 Things You Need to Know About Statistical Power\n\n\n\n\n\n\nAlexander Coppock\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EGAP Learning",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "guides/getting-started/causal-inference_en.html",
    "href": "guides/getting-started/causal-inference_en.html",
    "title": "10 Things You Need to Know About Causal Inference",
    "section": "",
    "text": "1. A causal claim is a statement about what didn‚Äôt happen.\nFor most experimentalists, the statement ‚Äú\\(X\\) caused \\(Y\\)‚Äù means that \\(Y\\) is present and \\(Y\\) would not have been present if \\(X\\) were not present. This definition requires a notion of what could have happened, but did not happen.2 Similarly, the ‚Äúeffect‚Äù of \\(X\\) on \\(Y\\) is thought of as the difference between the value that \\(Y\\) would have taken given one value of \\(X\\) and the value that \\(Y\\) would have taken given another value of \\(X\\). Because of the focus on differences in outcomes, this approach is sometimes called the ‚Äúdifference making‚Äù or ‚Äúcounterfactual‚Äù approach to causation.\nTechnical Note: Statisticians employ the ‚Äúpotential outcomes‚Äù framework to describe counterfactual relations. In this framework, we let \\(Y_i(1)\\) denote the outcome for unit \\(i\\) that would be observed under one condition (e.g., if unit \\(i\\) received a treatment) and \\(Y_i(0)\\) the outcome that would be observed in another condition (e.g., if unit \\(i\\) did not receive the treatment). One causal effect of the treatment for unit \\(i\\) might be a simple difference of the potential outcomes \\(œÑ_i=Y_i(1)‚àíY_i(0)\\). A treatment has a (positive or negative) causal effect on \\(Y\\) for unit \\(i\\) if \\(Y_i(1)‚â†Y_i(0)\\).\n\n\n2. There is no causation without manipulation.\nThe ‚Äúcounterfactual‚Äù definition of causality requires one to be able to think through what outcomes may result in different conditions. How would things look if one party as opposed to another was elected? Everyday causal statements often fall short of this requirement in one of two ways.\n\nFirst, some statements do not specify clear counterfactual conditions. For example the claim that ‚Äúthe recession was caused by Wall Street‚Äù does not point to an obvious counterfactual‚Äî are we to consider whether there would have been a recession if Wall Street did not exist? Or is the statement really a statement about particular actions that Wall Street could have taken but did not. If so, which actions? The validity of such statements is hard to assess, and can depend on which counterfactual conditions are implied by a statement.\nSecond, some statements involve counterfactual conditions that cannot be imagined. For example, the claim that Peter got the job because he is Peter implies a consideration of what would have happened if Peter was not Peter. Alternatively, the claim that Peter got the job because he is a man requires considering Peter as other than a man. The problem is that the counterfactuals in these cases imply a change not just in the condition facing an individual but in the individual themselves.\n\nTo avoid such problems, some statisticians urge a restriction of causal claims to treatments that can conceivably (not necessarily practically) be manipulated.3 For example, while we might have difficulties with the claim that Peter got the job because he was a man, we have no such difficulties with the claim that Peter got the job because the hiring agency thought he was a man.\n\n\n3. Causes are non-rival.\nEven though we may focus on the effect of a single cause \\(X\\) on an outcome \\(Y\\), we generally do not expect that there is ever only a single cause of \\(Y\\).4 Moreover, if you add up the causal effects of different causes, there is no reason to expect them to add up to 100%. Hence, there is not much point trying to ‚Äúapportion‚Äù outcomes to different causal factors. In other words, causes are not rival. The National Rifle Association argues, for example, that guns don‚Äôt kill people, people kill people. That statement does not make much sense in the counterfactual framework. Take away guns and you have no deaths from gunshot wounds. So guns are a cause. Take away people and you also have no deaths from gunshot wounds, so people are also a cause. Put differently, these two factors are simultaneously causes of the same outcomes.\n\n\n4. \\(X\\) can cause \\(Y\\) even if \\(X\\) is not a necessary condition or a sufficient condition for \\(Y\\).\nWe often talk about causal relations in deterministic terms. Even the Lewis quote at the top of this page seems to suggest a deterministic relation between causes and effects. Sometimes causal relations are thought to entail necessary conditions (for \\(Y\\) to occur, \\(X\\) has to happen); sometimes such relations are thought to entail sufficient conditions (if \\(X\\) occurs, then \\(Y\\) occurs). But once we are talking about multiple units, there are at least two ways in which we can think of \\(X\\) causing \\(Y\\) even if \\(X\\) is neither a necessary nor a sufficient condition for \\(Y\\). The first is to reinterpret everything in probabilistic terms: by \\(X\\) causes \\(Y\\), we simply mean that the probability of \\(Y\\) is higher when \\(X\\) is present. Another is to allow for contingencies ‚Äî for example, \\(X\\) may cause \\(Y\\) if condition \\(Z\\) is present, but not otherwise.5\n\n\n5. There is a fundamental problem of causal inference.\nIf causal effects are statements about the difference between what happened and what could have happened, then causal effects cannot be measured. That‚Äôs bad news. Prospectively, you can arrange things so that you can observe either what happens if someone gets a treatment or what happens if they do not get the treatment. Yet, for the same person, you will never be able to observe both of these outcomes and hence also not the difference between them. This inability to observe unit-level causal effects is often called the ‚Äúfundamental problem of causal inference.‚Äù\n\n\n6. You can estimate average causal effects even though you cannot observe any individual causal effects.\nEven though you cannot observe whether \\(X\\) causes \\(Y\\) for any given unit, it can still be possible to figure out whether \\(X\\) causes \\(Y\\) on average. The key insight here is that the average causal effect equals the difference between the average outcome across all units if all units were in the control condition and the average outcome across all units if all units were in the treatment condition. Many strategies for causal identification (see 10 Strategies for Figuring Out If X Caused Y) focus on ways to learn about these average potential outcomes.6\n10 Things to Know About Hypothesis Testing describes how one can learn about individual causal effects rather than average causal effects given the fundamental problem of causal inference.\n\n\n7. Estimating average causal effects does not require that treatment and control groups are identical.\nOne strategy that people use to learn about average causal effects is to create treatment and control groups through randomization (see 10 Strategies for Figuring Out If X Caused Y). When doing so, researchers sometimes worry if they find that the resulting treatment and control groups do not look the same along relevant dimensions.\nThe good news is that the argument for why differences in average outcomes across randomly assigned treatment and control groups capture average treatment effects (in expectation across repeated randomizations within the same pool of units) does not rely on treatment and control groups being similar in their observed characteristics. It relies only on the idea that, on average, the outcomes in the treated and control groups will capture the average outcomes for all units in the experimental pool if they were, respectively, in treatment or in control. In practice actual treatment and control groups will not be identical.7\n\n\n8. Correlation is not causation.\nA correlation between \\(X\\) and \\(Y\\) is a statement about relations between actual outcomes in the world, not about the relation between actual outcomes and counterfactual outcomes. So statements about causes and correlations don‚Äôt have much to do with each other. Positive correlations can be consistent with positive causal effects, no causal effects, or even negative causal effects. For example taking cough medication is positively correlated with coughing but hopefully has a negative causal effect on coughing.8\n\n\n9. If you know that, on average, \\(A\\) causes \\(B\\) and \\(B\\) causes \\(C\\), this does not mean that, on average, \\(A\\) causes \\(C\\).\nYou might expect that if \\(A\\) causes \\(B\\) and \\(B\\) causes \\(C\\) that therefore \\(A\\) causes \\(C\\).9 But there is no reason to believe that average causal relations are transitive in this way. To see why, imagine \\(A\\) caused \\(B\\) for men but not women and \\(B\\) caused \\(C\\) for women but not men. Then on average \\(A\\) causes \\(B\\) and \\(B\\) causes \\(C\\) but there may still be no one for whom \\(A\\) causes \\(C\\) through \\(B\\).\n\n\n10. It‚Äôs easier to learn about the ‚Äúeffects of causes‚Äù than to learn about the ‚Äúcauses of effects.‚Äù\nThough it might sound like two ways of saying the same thing, there is a difference between understanding what the effect of \\(X\\) on \\(Y\\) is (the ‚Äúeffects of a cause‚Äù) and whether an outcome \\(Y\\) was due to cause \\(X\\) (the ‚Äúcause of an effect‚Äù).10 Consider the following example. Suppose we run an experiment with a sample that contains an equal number of men and women. The experiment randomly assigns men and women to a binary treatment \\(X\\) and measures a binary outcome \\(Y\\). Further, suppose that \\(X\\) has a positive effect of 1 for all men, i.e.¬†men‚Äôs control potential outcome is zero (\\(Y_i(0) = 0\\)) and their treated potential outcome is one (\\(Y_i(1) = 1\\)). For all women, \\(X\\) has a negative effect of \\(-1\\), i.e., women‚Äôs control potential outcome is one (\\(Y_i(0) = 1\\)) and their treated potential outcome is zero (\\(Y_i(1) = 0\\)). In this example, the average effect of \\(X\\) on \\(Y\\) is zero. But for all participants in the treatment group with \\(Y=1\\), it is the case that \\(Y=1\\) because \\(X=1\\). Similarly, for all participants in the treatment group with \\(Y=0\\), it is the case that \\(Y=0\\) because \\(X=1\\). Experimentation can get an exact answer to the question about the ‚Äúeffects of a cause‚Äù, but generally it is not possible to get an exact answer to the question about the ‚Äúcause of an effect‚Äù.11\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Macartan Humphreys. Minor revisions: Winston Lin and Donald P. Green, 24 Jun 2016. Revisions MH 6 Jan 2020. Revisions Anna Wilke May 2021. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits.‚Ü©Ô∏é\nHolland, Paul W. ‚ÄúStatistics and causal inference.‚Äù Journal of the American Statistical Association 81.396 (1986): 945-960.‚Ü©Ô∏é\nHolland, Paul W. ‚ÄúStatistics and causal inference.‚Äù Journal of the American Statistical Association 81.396 (1986): 945-960.‚Ü©Ô∏é\nIn some accounts this has been called the ‚ÄúProblem of Profligate Causes‚Äù.‚Ü©Ô∏é\nFollowing Mackie, sometimes the idea of ‚ÄúINUS‚Äù conditions is invoked to capture the dependency of causes on other causes. Under this account, a cause may be an Insufficient but Necessary part of a condition which is itself Unnecessary but Sufficient. For example dialing a phone number is a cause of contacting someone since having a connection and dialing a number is sufficient (S) for making a phone call, whereas dialing alone without a connection alone would not be enough (I), nor would having a connection (N). There are of course other ways to contact someone without making phone calls (U). Mackie, John L. ‚ÄúThe cement of the universe.‚Äù London: Oxford Uni (1974).‚Ü©Ô∏é\nTechnical Note: The key technical insight is that the difference of averages is the same as the average of differences. That is, using the ‚Äúexpectations operator,‚Äù \\(ùîº(œÑ_i)=ùîº(Y_i(1)‚àíY_i(0))=ùîº(Y_i(1))‚àíùîº(Y_i(0))\\). The terms inside the expectations operator in the second quantity cannot be estimated, but the terms inside the expectations operators in the third quantity can be.6 See illustration here.‚Ü©Ô∏é\nFor this reason \\(t\\)-tests to check whether ‚Äúrandomization worked‚Äù do not make much sense, at least if you know that a randomized procedure was followed ‚Äî just by chance 1 in 20 such tests will show statistically detectable differences between treated and control groups. If there are doubts about whether a randomized procedure was correctly implemented these tests can be used to test the hypothesis that the data was indeed generated by a randomized procedure. This later reason for randomization tests can be especially important in field experiments where chains of communication from the person creating random numbers and the person implementing treatment assignment may be long and complex.‚Ü©Ô∏é\nTechnical Note: Let \\(D_i\\) be an indicator for whether unit \\(i\\) has received a treatment or not. Then the difference in average outcomes between those that receive the treatment and those that do not can be written as \\(\\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}‚àí\\frac{‚àë_i (1‚àíD_i)√óY_i(0)}{‚àë_i (1‚àíD_i)}\\). In the absence of information about how treatment was assigned, we can say little about whether this difference is a good estimator of the average treatment effect, i.e., of the difference in average treated and control potential outcomes across all units. What matters is whether \\(\\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}\\) is a good estimate of \\(\\frac{‚àë_i 1√óY_i(1)}{‚àë_i1}\\) and whether \\(\\frac{‚àë_i (1‚àíD_i)√óY_i(0)}{‚àë_i (1‚àíD_i)}\\) is a good estimate of \\(\\frac{‚àë_i 1√óY_i(0)}{‚àë_i1}\\). This might be the case if those who received treatment are a representative sample of all units, but otherwise there is no reason to expect that it would be.‚Ü©Ô∏é\nInterpret ‚Äú\\(A\\) causes \\(B\\), on average‚Äù as ‚Äúthe average effect of \\(A\\) on \\(B\\) is positive.‚Äù‚Ü©Ô∏é\nSome reinterpret the ‚Äúcauses of effects‚Äù question to mean: what are the causes that have effects on outcomes. See Andrew Gelman and Guido Imbens, ‚ÄúWhy ask why? Forward causal inference and reverse causal questions‚Äù, NBER Working Paper No.¬†19614 (Nov.¬†2013).‚Ü©Ô∏é\nSee, for example, Tian, J., Pearl, J. 2000. ‚ÄúProbabilities of Causation: Bounds and Identification.‚Äù Annals of Mathematics and Artificial Intelligence 28:287‚Äì313.‚Ü©Ô∏é"
  },
  {
    "objectID": "guides/getting-started/adaptive_en.html",
    "href": "guides/getting-started/adaptive_en.html",
    "title": "10 Things to Know About Adaptive Experimental Design",
    "section": "",
    "text": "2. What are the potential advantages of an adaptive design?\nAdaptive designs have the potential to detect the best-performing experimental arm(s) more quickly than a static design (i.e., with fewer data-collection sessions and fewer subjects). When these efficiencies are realized, resources may be reallocated to achieve other research objectives.\nAdaptive designs also have the potential to lessen the ethical concerns that arise when subjects are allocated to inferior treatment arms. For therapeutic interventions, adaptive designs may reduce subjects‚Äô exposure to inferior treatments; for interventions designed to further broad societal objectives, adaptive designs may hasten the discovery of superior interventions.\nTo illustrate the potential advantages of adaptive design, we simulate an RCT involving a control group and eight treatment arms. We administer treatments and gather 100 outcomes during each ‚Äúperiod.‚Äù The simulation assumes that each subject‚Äôs outcome is binary (e.g., good versus bad). The adaptive allocation of subjects is based on interim analyses conducted at the end of each period. We allocate next period‚Äôs subjects according to posterior probabilities that a given treatment arm is best (see below). The simulation assumes that the probability of success is 0.10 for all arms except one, which is 0.20. The stopping rule is that the RCT is halted when one arm is found to have a 95% posterior probability of being best.\nIn the adaptive trial depicted below, the best arm (the red line) is correctly identified, and the trial is halted after 23 periods (total N=2300).\n\n\n\n3. What are the potential disadvantages of adaptive designs?\nThere is no guarantee that adaptive design will be superior in terms of speed or accuracy. For example, adaptive designs may result in a lengthy trial in cases where all of the arms are approximately equally effective. Even when one arm is truly superior, adaptive searches have some probability of resulting in long, circuitous searches (and considerable expense) if by chance they get off to a bad start (i.e., one of the inferior arms appears to be better than the other based on an initial round of results).\nFor instance, consider the following scenario in which all but one of the arms have a 0.10 probability of success, and the superior arm has a 0.12 probability of success (with the same trial design as in the previous example). The design eventually settles on the truly superior arm but only after more than 200 periods (N = 23,810). Even after 50 periods, the results provide no clear sense that any of the arms is superior.\n\nA further disadvantage of adaptive designs is they may produce biased estimates of the average treatment effect of the apparent best arm vis-√†-vis the control group. Bias arises because the trial stops when the best arm crosses a threshold suggesting optimality; this stopping rule tends to favor lucky draws that suggest the efficacy of the winning arm. Conversely, when adaptive algorithms associate sampling probability with observed history, under-estimation for inferior arms, including the control group, may persist until stopping time (Nie et al., 2017).\nFor example, in the first scenario described above in which all arms have a 0.10 probability of success except for the best arm, which is 0.20, the average estimated success probability for the truly best arm is 0.202 across 1000 simulated experiments, while the control group average is found to 0.083. The average estimated difference in success probabilities (i.e., the average treatment effect) is 0.119, as compared to the true value of 0.10.\nIn the second scenario, in which the best arm‚Äôs success probability is just 0.12, the average estimated success probability for the best arm is 0.121, and the average estimated ATE is 0.027, as compared to the true ATE of 0.02. Bias in this case is relatively small on a percentage point scale due to the very large size of the average experiment.\n\n\n4. What kinds of experiments lend themselves to adaptive design?\nAdaptive designs require multiple periods of treatment and outcome assessment.\nAdaptive designs are well suited to survey, on-line, and lab experiments, where participants are treated and outcomes measured in batches over time.\nSome field experiments are conducted in stages, although the logistics of changing treatment arms may be cumbersome, as discussed below. One possible opportunity for adaptive design in a field context occurs when a given experiment is to be deployed over time in a series of different regions. This allows for adaptation based on region-by-region interim analyses.\nAdaptive designs are ill-suited to one-shot interventions with outcomes measured at a single point in time. For example, experiments designed to increase voter turnout in a given election do not lend themselves to adaptive design because everyone‚Äôs outcome is measured at the same time, leaving no opportunity for adaptation.\n\n\n5. What is the connection between adaptive designs and ‚Äúmulti-arm bandit problems‚Äù?\nThe multi-arm bandit problem (Scott 2010) is a metaphor for the following optimization problem. Imagine that you could drop a coin in one of several slot machines that may pay off at different rates. (Slot machines are sometimes nicknamed ‚Äúone-arm bandits,‚Äù hence the name.) You would like to make as much money as possible. The optimization problem may be characterized as a trade off between learning about the relative merits of the various slot machines ‚Äì exploration ‚Äì and reaping the benefits of employing the best arm ‚Äì exploitation. A static design may be viewed as an extreme case of allocating subjects solely for exploration.\nAs applied to RCTs, the aim is to explore the merits of the various treatment arms while at the same time reaping the benefits of the best arm or arms. Although the MAB problem is not specifically about estimating treatment effects, one could adjust the optimization objective so that the aim is to find the treatment arm with the greatest apparent superiority over the control group.\n\n\n6. What are some widely used algorithms for automating ‚Äúadaptation‚Äù?\nThe most commonly used methods employ some form of ‚ÄúThompson sampling‚Äù (Thompson 1933). Interim results are assessed periodically, and in the next period subjects are assigned to treatment arms in proportion to the posterior probability that a given arm is best. The more likely an arm is to be ‚Äúbest,‚Äù the more subjects it receives.\nMany variations on this basic assignment routine have been proposed, and some are designed to make it less prone to bias. If an adaptive trial is rolled out during a period in which success rates tend to be growing, increasing allocation of subjects to the best arm will tend to exaggerate that arm‚Äôs efficacy relative to the other arms, which receive fewer subjects during the high-yield period. In order to assess bias and correct for it, it may be useful to allocate some subjects in every period according to a static design. In this case, inverse probability weights for each period may be used to obtain unbiased estimates of the average treatment effect. (See Gerber and Green 2012 on the use of inverse probability weights for estimation of average treatment effects when the probability of assignment varies from block to block.)\n\n\n7. What are the symptoms of futile search?\nAlthough it is impossible to know for sure whether a drawn out search reflects an unlucky start or an underlying reality in which no arm is superior, the longer an adaptive trial goes, the more cause for concern. The following graphs summarize the distribution of stopping times for three scenarios. Stopping was dictated by at 10% value remaining criterion. Specifically, the trial stopped when the top of the 95% confidence interval showed that no other arm was likely to offer at least a 10 percent (not percentage point) gain in success rate. The first two scenarios were described above; the third scenario considers a case in which there are two superior arms. The graph illustrates how adaptive trials tend to conclude faster when the superiority of the best arm(s) is more clear-cut.\n\n\n\n8. What implications do adaptive designs have for pre-analysis plans?\nThe use of adaptive designs introduces additional decisions, which ideally should be addressed ex ante so as to limit researcher bias. For example, the researcher should specify which algorithms will be used for allocation. It is especially important to specify the stopping rule. Depending on the researcher‚Äôs objectives, this rule may focus on achieving a desired posterior probability, or it may use a ‚Äúvalue remaining‚Äù criterion that considers whether one or more arms have shown themselves to be good enough vis-√†-vis the alternative arms. Other hybrid stopping criteria may also be specified. The pre-analysis plan should also describe the analytic steps that will be taken to correct for bias.\n\n\n9. Are multi-arm bandit trials frequently used in social science?\nMany of the applications to date have taken place in commercial settings, such as website design for high-volume e-commerce, or in settings such as on-line fundraising. Relatively few applications have been written up in detail for a scholarly audience. Surprisingly rare are applications in biomedical research. As Villar et al.¬†(2015, p.200) note, ‚ÄúDespite this apparent near-perfect fit between a real-world problem and a mathematical theory, the MABP has yet to be applied to an actual clinical trial.‚Äù\nPutting aside the use of multi-arm bandit approaches, the use of adaptive trials is gradually winning acceptance in biomedical research. For details, see Chin (2016).\n\n\n10. What other considerations should inform the decision to use adaptive design?\nAs noted above, adaptive designs add to the complexity of the research design and analysis. They also may increase the challenges of implementation, particularly in field settings where the logistical or training costs associated with different arms vary markedly. Even when one arm is clearly superior (inferior), the lead-time necessary to staff or outfit this arm may make it difficult to scale it up (down). Adaptive designs are only practical if adaptation is feasible.\nOn the other hand, funders and implementation partners may welcome the idea of an experimental design that responds to on-the-ground conditions such that problematic arms are scaled back. A middle ground between static designs and designs that envision adaptation over many periods are adaptive designs involving only two or three interim analyses and adjustments. Such trials are winning increased acceptance in biomedical research (Chow and Chang 2008) and are likely to become more widely used in the social sciences too. The growing interest in replication and design-based extensions of existing experiments to aid generalization are likely to create opportunities for adaptive design.\n\n\nReferences\nChin, Richard. 2016. Adaptive and flexible clinical trials. New York: CRC Press.\nChow, Shein-Chung, and Mark Chang. 2008. ‚ÄúAdaptive design methods in clinical trials ‚Äì a review.‚Äù Orphanet Journal of Rare Diseases 3:11.  Link to article \nNie, Xinkun, Xiaoying Tian, Jonathan Taylor, and James Zou. 2017. ‚ÄúWhy Adaptively Collected Data Have Negative Bias and How to Correct for It.‚Äù arXiv:1708.01977\nScott, Steven L. 2010. ‚ÄúA modern Bayesian look at the multi-armed bandit.‚Äù Applied Stochastic Models in Business and Industry 26:639‚Äì658.\nThompson, William R. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika 25:285‚Äì294.\nVillar, Sof√≠a S., Jack Bowden, and James Wason. ‚ÄúMulti-Armed Bandit Models for the Optimal Design of Clinical Trials: Benefits and Challenges.‚Äù Statistical science: a review journal of the Institute of Mathematical Statistics 30.2 (2015): 199‚Äì215.\n\n\n\n\n\n\nFootnotes\n\n\nThis guide originally authored by Donald Green (Columbia University) and Molly Offer-Westort (Yale University) and published on February 23, 2018.‚Ü©Ô∏é"
  },
  {
    "objectID": "guides/getting-started/causal-inference_esp.html",
    "href": "guides/getting-started/causal-inference_esp.html",
    "title": "10 cosas que debe saber sobre la inferencia causal",
    "section": "",
    "text": "1. Una afirmaci√≥n causal es un enunciado sobre lo que no sucedi√≥\nPara la mayor√≠a de investigadores que realizan experimentos, el enunciado ‚Äú\\(X\\) caus√≥ \\(Y\\)‚Äù significa que \\(Y\\) ocurri√≥ y que no habr√≠a ocurrido si \\(X\\) no hubiera estado presente. Esta definici√≥n requiere que tengamos una noci√≥n de lo que podr√≠a haber sucedido, pero no sucedi√≥.3 De manera similar, el ‚Äúefecto‚Äù de \\(X\\) en \\(Y\\) se considera la diferencia entre el valor que \\(Y\\) habr√≠a tomado dado un valor de \\(X\\) y el valor que \\(Y\\) habr√≠a tomado dado otro valor de \\(X\\). Debido al enfoque en la diferencia de los resultados, este enfoque a veces se conoce como el enfoque de causalidad basado en ‚Äúhacer diferencias‚Äù o en lo ‚Äúcontrafactual‚Äù.\nNota t√©cnica: Los estad√≠sticos emplean el marco de ‚Äúresultados potenciales‚Äù para describir las relaciones contrafactuales. En este marco, dejamos que \\(Y_i(1)\\) denote el valor que la unidad \\(i\\) tomar√≠a bajo la condici√≥n uno (por ejemplo, si la unidad \\(i\\) recibi√≥ un tratamiento) y \\(Y_i(0)\\) el valor que habr√≠a sido observado en otra condici√≥n (por ejemplo, si la unidad \\(i\\) no recibi√≥ el tratamiento). Un efecto causal del tratamiento para la unidad \\(i\\) puede ser una simple diferencia de los resultados potenciales \\(\\tau_i = Y_i(1)-Y_(0)\\). Un tratamiento tiene un efecto causal (positivo o negativo) en \\(Y\\) para la unidad \\(i\\) si \\(Y_i (1) \\neq Y_i (0)\\).\n\n\n2. No hay relaci√≥n causal sin manipulaci√≥n.\nLa definici√≥n ‚Äúcontrafactual‚Äù de causalidad requiere que uno sea capaz de pensar qu√© valores podemos observar en diferentes condiciones. ¬øC√≥mo ser√≠an las cosas si se eligiera un partido en lugar de otro? Las declaraciones causales cotidianas a menudo no cumplen con este requisito en alguna de estas dos formas:\n\nPrimero, algunas declaraciones no especifican condiciones contrafactuales claras. Por ejemplo, la afirmaci√≥n de que ‚Äúla recesi√≥n fue causada por Wall Street‚Äù no apunta a un contrafactual obvio: ¬ødebemos considerar si habr√≠a habido una recesi√≥n si Wall Street no existiera? ¬øO es la afirmaci√≥n realmente una afirmaci√≥n sobre acciones particulares que Wall Street podr√≠a haber tomado pero no lo hizo? Si es as√≠, ¬øqu√© acciones? Es dif√≠cil evaluar la validez de tales declaraciones. Adem√°s, puede depender de qu√© condiciones contrafactuales est√©n impl√≠citas en una afirmaci√≥n.\nEn segundo lugar, algunos enunciados implican condiciones contrafactuales que no son posibles de imaginar. Por ejemplo, la afirmaci√≥n de que Peter consigui√≥ el trabajo porque es Peter implica una consideraci√≥n de lo que habr√≠a sucedido si Peter no fuera Peter. Alternativamente, la afirmaci√≥n de que Peter consigui√≥ el trabajo porque es un hombre requiere considerar a Peter como algo diferente de un hombre. El problema es que los contrafactuales en estos casos implican un cambio no solo en la condici√≥n que enfrenta un individuo sino en el propio individuo.\n\nPara evitar estos problemas, algunos estad√≠sticos instan a restringir las afirmaciones causales a los tratamientos que pueden manipularse, al menos en la imaginaci√≥n, y no necesariamente en la pr√°ctica.4 Por ejemplo, si bien podr√≠amos tener dificultades con la afirmaci√≥n de que Peter consigui√≥ el trabajo porque es hombre, no tendr√≠amos las mismas dificultades con la afirmaci√≥n de que Peter consigui√≥ el trabajo porque la agencia de contrataci√≥n pens√≥ que era hombre\n\n\n3. Las causas no tienen por qu√© ser rivales.\nAunque nos podemos centrar en el efecto de una sola causa \\(X\\) en un variable de resultado \\(Y\\), generalmente no esperamos que \\(Y\\) tenga solo una causa.5 Adem√°s, si sumamos los efectos causales de diferentes causas, no hay raz√≥n para esperar que sumen el 100%. Por lo tanto, no tiene mucho sentido tratar de ‚Äúdistribuir‚Äù los resultados entre diferentes factores causales. En otras palabras, las causas no tienen por qu√© ser rivales. La Asociaci√≥n Nacional del Rifle de Estados Unidos sostiene, por ejemplo, que las armas no matan a la gente, la gente mata a la gente. Esa afirmaci√≥n no tiene mucho sentido en el marco hipot√©tico. Quita las armas y no tendr√°s muertes por heridas de bala. Entonces las armas son una causa. Quita a la gente y tampoco tendr√°s muertes por heridas de bala, por lo que las personas tambi√©n son una causa. Dicho de otra manera, estos dos factores son simult√°neamente causas de los mismos resultados.\n\n\n4. \\(X\\) puede causar \\(Y\\) incluso si \\(X\\) no es una condici√≥n necesaria o una condici√≥n suficiente para que \\(Y\\) ocurra.\nA menudo hablamos de relaciones causales en t√©rminos deterministas. Incluso la cita de Lewis en la parte superior de esta p√°gina parece sugerir una relaci√≥n determinista entre causas y efectos. A veces se piensa que las relaciones causales implican condiciones necesarias (para \\(Y\\) que ocurra, \\(X\\) tiene que suceder ); a veces se piensa que tales relaciones implican condiciones suficientes (si ocurre \\(X\\), entonces ocurre \\(Y\\)). Pero una vez que hablamos de m√∫ltiples unidades, hay al menos dos formas en las que podemos pensar en que \\(X\\) causa \\(Y\\) incluso si \\(X\\) no es una condici√≥n necesaria ni suficiente para \\(Y.\\) La primera es reinterpretar todo en t√©rminos probabil√≠sticos: que \\(X\\) cause \\(Y\\), simplemente quiere decir que la probabilidad de \\(Y\\) es mayor cuando \\(X\\) est√° presente. Otra forma es permitir contingencias. Por ejemplo, \\(X\\) puede causar \\(Y\\) si la condici√≥n \\(Z\\) est√° presente, pero no de otra manera.6\n\n\n5. Existe un problema fundamental de la inferencia causal\nSi los efectos causales son enunciados sobre la diferencia entre lo que sucedi√≥ y lo que podr√≠a haber sucedido, entonces no los podemos medir. Malas noticias. De manera prospectiva, puede organizar las cosas para que pueda observar lo que sucede si alguien recibe un tratamiento o lo que sucede si no recibe el tratamiento. Sin embargo, para la misma persona nunca podr√° observar ambos resultados y, por lo tanto, tampoco la diferencia entre ellos. Esta incapacidad para observar efectos causales a nivel de la unidad de estudio a menudo se denomina ‚Äúproblema fundamental de la inferencia causal‚Äù.\n\n\n6. Usted puede estimar el efecto causal promedio aun cuando no pueda observar ning√∫n efecto causal individual.\nAunque no pueda observar si \\(X\\) causa \\(Y\\) para una unidad determinada, s√≠ es posible determinar si \\(X\\) causa \\(Y\\) en promedio. La idea clave aqu√≠ es que el efecto causal promedio es igual a la diferencia entre la variable de resultado promedio para todas las unidades, si todas est√°n en la condici√≥n de control y la variable de resultado promedio para todas las unidades si todas est√°n en la condici√≥n de tratamiento. Muchas estrategias para la identificaci√≥n causal (ver 10 estrategias para determinar si X caus√≥ Y) se enfocan en formas de aprender acerca de estas resultados potenciales promedio.7\n10 cosas que debe saber sobre las pruebas de hip√≥tesis nos muestra c√≥mo podemos aprender acerca de efectos causales individuales en vez de efectos promediodato el problema fundamental de la inferencia causal.\n\n\n7. La estimaci√≥n del efecto causal promedio no requiere que los grupos de tratamiento y control sean id√©nticos.\nUna estrategia que la gente usa para aprender acerca del efecto causal promedio es crear grupos de tratamiento y control a trav√©s de la aleatorizaci√≥n (ver 10 estrategias para determinar si X caus√≥ Y). Es com√∫n que algunos investigadores se preocupen por que los grupos de tratamiento y control resultantes no sean similares en dimensiones relevantes.\nLa buena noticia es que la raz√≥n por la cual las diferencias en los resultados promedio entre los grupos de control y tratamiento asignados aleatoriamente capturan los efectos promedio del tratamiento (en valor esperado a trav√©s de aleatorizaciones repetidas dentro del mismo grupo de unidades) no se basa en que los grupos de tratamiento y control sean similares en las caracter√≠sticas observadas. Sino que se basa √∫nicamente en la idea de que, en promedio, los resultados en los grupos tratados y de control capturar√°n los resultados promedio para todas las unidades en el grupo experimental si estuvieran, respectivamente, en tratamiento o en control. En la pr√°ctica, los grupos de tratamiento y de control no ser√°n id√©nticos.8\n\n\n8. Correlaci√≥n no es igual a causalidad.\nUna correlaci√≥n entre \\(X\\) y \\(Y\\) es un enunciado sobre las relaciones entre los valores reales de estas variables y no sobre la relaci√≥n entre los valores reales y los valores contrafactuales. Entonces las afirmaciones sobre causas y correlaciones no tienen mucho que ver entre s√≠. Las correlaciones positivas pueden ser consistentes con efectos causales positivos, efectos causales nulos o incluso con efectos causales negativos. Por ejemplo, tomar medicamentos para la tos se correlaciona positivamente con la tos, pero es de esperar que tenga un efecto causal negativo sobre la tos.9\n\nSi usted sabe que, en promedio, \\(A\\) causa $ B $ y \\(B\\) causa \\(C\\), esto no significa que, en promedio, \\(A\\) cause \\(C\\).\n\n== Se podr√≠a esperar que si \\(A\\) causa \\(B\\) y \\(B\\) causa \\(C\\), entonces \\(A\\) causa \\(C\\).10 Pero no hay raz√≥n para creer que las relaciones causales promedio sean transitivas. Para entender por qu√©, imagine que \\(A\\) caus√≥ \\(B\\) en los hombres pero no en las mujeres y \\(B\\) caus√≥ \\(C\\) en las mujeres pero no en los hombres. Entonces, en promedio, \\(A\\) causa \\(B\\) y \\(B\\) causa \\(C\\), pero es posible que no haya nadie para quien \\(A\\) tenga un efecto en \\(C\\) mediado por \\(B\\).\n\n\n10. Es m√°s f√°cil aprender sobre los ‚Äúefectos de las causas‚Äù que aprender sobre las ‚Äúcausas de los efectos‚Äù.\nAunque puedan parecer dos formas de decir exactamente lo mismo, existe una diferencia entre comprender cu√°l es el efecto de \\(X\\) en \\(Y\\) (los ‚Äúefectos de una causa‚Äù) y si el valor que tom√≥ \\(Y\\) se debi√≥ a \\(X\\) (la ‚Äúcausa de un efecto‚Äù).11 Considere el siguiente ejemplo. Supongamos que realizamos un experimento con una muestra que contiene el mismo n√∫mero de hombres y mujeres. El experimento asigna aleatoriamente a hombres y mujeres a un tratamiento binario \\(X\\) y mide una variable de resultado binaria \\(Y\\). Adem√°s suponga que \\(X\\) tiene un efecto positivo de 1 para todos los hombres, es decir, el resultado potencial del control de los hombres es cero (\\(Y_i(0) = 0\\)) y la salida potencial cuando son tratados es uno (\\(Y_i(1) = 1\\)). Para todas las mujeres, \\(X\\) tiene un efecto negativo de \\(-1\\), es decir, la salida potencial de las mujeres bajo el control es uno (\\(Y_i (0) = 1\\)) y su salida potencial cuando son tratadas es cero (\\(Y_i (1) = 0\\)) En este ejemplo, el efecto promedio de \\(X\\) en $ Y $ es cero. Pero la raz√≥n para que los participantes en el grupo de tratamiento tengan \\(Y= 1\\), es porque \\(X = 1\\). De manera similar, todos los participantes en el grupo de tratamiento con \\(Y = 0\\), tienen \\(Y = 0\\) porque \\(X = 1\\). Los experimentos nos permiten obtener una respuesta exacta a la pregunta sobre los ‚Äúefectos de una causa‚Äù, pero en general no es posible obtener una respuesta exacta a la pregunta sobre la ‚Äúcausa de un efecto‚Äù.12\n\n\n\n\n\nFootnotes\n\n\nLewis, David. ‚ÄúCausation.‚Äù The journal of philosophy (1973): 556-567.‚Ü©Ô∏é\nAutor: Macartan Humphreys. Revisiones menores: Winston Lin y Donald P. Green, 24 de junio de 2016. Revisiones MH 6 de enero de 2020. Revisiones Anna Wilke de mayo de 2021. Esta gu√≠a es un documento din√°mico y est√° sujeta a actualizaci√≥n por parte de los miembros de EGAP; los colaboradores enumerados no son responsables de las ediciones posteriores.‚Ü©Ô∏é\nHolland, Paul W. ‚ÄúStatistics and causal inference.‚Äù Journal of the American Statistical Association 81.396 (1986): 945-960.‚Ü©Ô∏é\nHolland, Paul W. ‚ÄúStatistics and causal inference.‚Äù Journal of the American Statistical Association 81.396 (1986): 945-960.‚Ü©Ô∏é\nEsto se conoce a veces como el ‚ÄúProblema de las causas excesivas‚Äù.‚Ü©Ô∏é\nDe acuerdo a Mackie, a veces se invoca la idea de condiciones ‚ÄúINUS‚Äù para capturar la dependencia de las causas de otras causas. Seg√∫n esta explicaci√≥n, una causa puede ser parte Insuficiente pero Necesaria de una condici√≥n que en s√≠ misma es Innecesaria pero Suficiente. Por ejemplo, marcar un n√∫mero de tel√©fono es una causa de contacto con alguien, ya que tener una conexi√≥n y marcar un n√∫mero es suficiente (S) para hacer una llamada telef√≥nica, mientras que marcar solo sin una conexi√≥n no ser√≠a suficiente (I), ni tener una conexi√≥n (N). Por supuesto, hay otras formas de contactar a alguien sin hacer llamadas telef√≥nicas (U). Mackie, John L. ‚ÄúEl cemento del universo‚Äù. Londres: Oxford Uni (1974).‚Ü©Ô∏é\nNota t√©cnica: La idea t√©cnica clave es que la diferencia de promedios es la misma que el promedio de diferencias. Es decir, usando el ‚Äúoperador de expectativas‚Äù, \\(\\text{E}(\\tau_i) = \\text{E}(Y_i (1) -Y_i (0)) = \\text{E}(Y_i (1)) - \\text{E}(Y_i (0))\\). Los t√©rminos dentro del operador de esperanzas en la segunda cantidad no se pueden estimar, pero los t√©rminos dentro de los operadores de expectativas en la tercera cantidad si se pueden ser estimados7 Vea la ilustraci√≥n [aqu√≠] (https://raw.githubusercontent.com/egap/ gu√≠as-m√©todos / maestro / inferencia-causal / PO.jpg).‚Ü©Ô∏é\nPor esta raz√≥n usar las pruebas \\(t\\) para verificar si ‚Äúla asignaci√≥n aleatoria funcion√≥ bien‚Äù no tiene mucho sentido, al menos si se sabe que se sigui√≥ una procedimiento aleatorio: por simple chance, 1 de cada 20 de esas pruebas mostrar√° diferencias estad√≠sticamente detectables entre los grupos tratados y de control. Si existen dudas sobre si la asignaci√≥n aleatoria se realiz√≥ correctamente, estas pruebas se pueden utilizar para probar la hip√≥tesis de que los datos se generaron efectivamente mediante un procedimiento aleatorio. Esta √∫ltima raz√≥n para las pruebas de aleatorizaci√≥n puede ser especialmente importante en experimentos de campo donde las cadenas de comunicaci√≥n entre la persona que crea los n√∫meros aleatorios y la persona que implementa la asignaci√≥n del tratamiento son largas y complejas.‚Ü©Ô∏é\nNota t√©cnica: Sea \\(D_i\\) un indicador de si la unidad \\(i\\) ha recibido un tratamiento o no. Entonces la diferencia en los resultados promedio entre los que reciben el tratamiento y los que no lo reciben se puede escribir como \\(\\frac{\\sum_i D_i √ó Y_i (1)} {\\sum_iD_i} - \\frac {\\sum_i(1 - D_i) \\times Y_i (0)}{\\sum_i (1 - D_i)}\\). Sin informaci√≥n sobre c√≥mo se asign√≥ el tratamiento, no hay mucho por decir sobre si esta diferencia es un buen estimador del efecto promedio del tratamiento. Es decir, de la diferencia en los resultados potenciales promedio de las unidades en el grupo de tratamiento y control para todas las unidades. Lo que importa es si \\(\\frac{\\sum_i D_i √ó Y_i (1)} {\\sum_iD_i}\\) es una buena estimaci√≥n de \\(\\frac{\\sum_i 1 √ó Y_i (1)} {\\sum_i1}\\) y si \\(\\frac{\\sum_i (1 - D_i) √ó Y_i (0)}{\\sum_i(1 - D_i)}\\) es una buena estimaci√≥n de \\(\\frac{\\sum_i 1 √ó Y_i (0)} {\\sum_i1}\\). Este puede ser el caso si los que recibieron tratamiento son una muestra representativa de todas las unidades, pero de lo contrario no hay raz√≥n para esperar que as√≠ sea.‚Ü©Ô∏é\nEnti√©ndase la expresi√≥n ‚Äú\\(A\\) causa \\(B\\), en promedio‚Äù como ‚Äúel efecto promedio de \\(A\\) sobre \\(B\\) es positivo‚Äù.‚Ü©Ô∏é\nA veces se reinterpreta la pregunta ‚Äúcausas de los efectos‚Äù en el sentido de: ¬øcu√°les son las causas que tienen efectos sobre las variable de resultado? V√©ase Andrew Gelman and Guido Imbens, ‚ÄúWhy ask why? Forward causal inference and reverse causal questions‚Äù, NBER Working Paper No.¬†19614 (Nov.¬†2013).‚Ü©Ô∏é\nVer, por ejemplo, Tian, J., Pearl, J. 2000. ‚ÄúProbabilities of Causation: Bounds and Identification.‚Äù Annals of Mathematics and Artificial Intelligence 28:287‚Äì313.‚Ü©Ô∏é"
  },
  {
    "objectID": "guides/getting-started/causal-inference_fr.html",
    "href": "guides/getting-started/causal-inference_fr.html",
    "title": "10 choses √† savoir sur l‚Äôinf√©rence causale",
    "section": "",
    "text": "1. Une assertion causale est une d√©claration sur ce qui ne s‚Äôest pas produit.\nPour la plupart des exp√©rimentalistes, la d√©claration ‚Äú\\(X\\) a caus√© \\(Y\\)‚Äù signifie que \\(Y\\) est pr√©sent et \\(Y\\) n‚Äôaurait pas √©t√© pr√©sent si \\(X\\) n‚Äôavait pas √©t√© pr√©sent. Cette d√©finition requiert une notion de ce qui aurait pu arriver, mais ne s‚Äôest pas produit.3 De m√™me, ‚Äúl‚Äôeffet‚Äù de \\(X\\) sur \\(Y\\) est la diff√©rence entre la valeur que \\(Y\\) aurait prise √©tant donn√© une valeur de \\(X\\) et la valeur que \\(Y\\) aurait prise √©tant donn√© une autre valeur de \\(X\\). En raison de l‚Äôaccent mis sur les diff√©rences entre les r√©sultats, cette approche est parfois appel√©e approche ‚Äúdes diff√©rences‚Äù ou ‚Äúcontrefactuelle‚Äù de la causalit√©.\nNote technique: Les statisticiens emploient le cadre des ‚Äúr√©sultats potentiels‚Äù pour d√©crire les relations contrefactuelles. Dans ce cadre, \\(Y_i(1)\\) d√©signe le r√©sultat pour l‚Äôunit√© \\(i\\) qui serait observ√© sous une condition (par exemple, si l‚Äôunit√© \\(i\\) a re√ßu un traitement) et \\(Y_i(0)\\) d√©signe le r√©sultat qui serait observ√© dans une autre condition (par exemple, si l‚Äôunit√© \\(i\\) n‚Äôa pas re√ßu le traitement). Un effet causal du traitement pour l‚Äôunit√© \\(i\\) pourrait √™tre une simple diff√©rence des r√©sultats potentiels \\(œÑ_i=Y_i(1)‚àíY_i(0)\\). Un traitement a un effet causal (positif ou n√©gatif) sur \\(Y\\) pour l‚Äôunit√© \\(i\\) si \\(Y_i(1)‚â†Y_i(0)\\).\n\n\n2. Pas de causalit√© sans manipulation.\nLa d√©finition ‚Äúcontrefactuelle‚Äù de la causalit√© exige que l‚Äôon soit capable de r√©fl√©chir aux r√©sultats qui peuvent entra√Æner des conditions diff√©rentes. Quelle serait la situation si un parti plut√¥t qu‚Äôun autre √©tait √©lu ? Les d√©clarations causales de tous les jours ne r√©pondent souvent pas √† cette exigence de l‚Äôune des deux mani√®res suivantes.\n\nPremi√®rement, certaines d√©clarations ne pr√©cisent pas de conditions contrefactuelles claires. Par exemple, l‚Äôaffirmation selon laquelle ‚Äúla r√©cession a √©t√© caus√©e par Wall Street‚Äù n‚Äôindique pas de contrefactuel √©vident ‚Äî devons-nous examiner s‚Äôil y aurait eu une r√©cession si Wall Street n‚Äôavait pas exist√© ? Ou est-ce une d√©claration sur des d√©cisions particuli√®res que Wall Street aurait pu prendre mais n‚Äôa pas prises ? Si oui, quelles d√©cisions ? La validit√© de telles d√©clarations est difficile √† √©valuer et peut d√©pendre des conditions contrefactuelles impliqu√©es par une d√©claration.\nDeuxi√®mement, certaines d√©clarations impliquent des conditions contrefactuelles qui ne peuvent √™tre imagin√©es. Par exemple, l‚Äôaffirmation selon laquelle Peter a obtenu le poste parce qu‚Äôil est Peter implique une consid√©ration de ce qui se serait pass√© si Peter n‚Äô√©tait pas Peter. Alternativement, l‚Äôaffirmation selon laquelle Peter a obtenu le poste parce qu‚Äôil est un homme n√©cessite de consid√©rer Peter comme autre qu‚Äôun homme. Le probl√®me est que les contrefactuels dans ces cas impliquent un changement non seulement de la condition √† laquelle fait face un individu, mais de l‚Äôindividu lui-m√™me.\n\nPour √©viter de tels probl√®mes, certains statisticiens recommandent de restreindre les assertions causales aux traitements qui peuvent en th√©orie (pas n√©cessairement en pratique) √™tre manipul√©s.4 Par exemple, alors que nous pourrions avoir des difficult√©s avec l‚Äôaffirmation selon laquelle Peter a obtenu le poste parce qu‚Äôil √©tait un homme, nous n‚Äôavons pas de telles difficult√©s avec l‚Äôaffirmation selon laquelle Peter a obtenu le poste parce que l‚Äôagence de recrutement pensait qu‚Äôil √©tait un homme.\n\n\n3. Les causes sont non rivales.\nM√™me si nous pouvons nous concentrer sur l‚Äôeffet d‚Äôune seule cause \\(X\\) sur un r√©sultat \\(Y\\), nous ne nous attendons g√©n√©ralement pas √† ce qu‚Äôil n‚Äôy ait qu‚Äôune seule cause de \\(Y\\).5 De plus, si vous additionnez les effets causaux de diff√©rentes causes, il n‚Äôy a aucune raison de s‚Äôattendre √† ce qu‚Äôils totalisent 100 %. Par cons√©quent, il ne sert √† rien d‚Äôessayer de ‚Äúr√©partir‚Äù les r√©sultats entre diff√©rents facteurs de causalit√©. En d‚Äôautres termes, les causes sont non rivales. La National Rifle Association soutient, par exemple, que les armes √† feu ne tuent pas les gens, les gens tuent les gens. Cette d√©claration n‚Äôa pas beaucoup de sens dans le cadre contrefactuel. Enlevez les armes √† feu et vous n‚Äôaurez pas de morts par balles. Les armes √† feu sont donc une cause. Enlevez les gens et vous n‚Äôaurez pas non plus de d√©c√®s par balle, donc les gens sont aussi une cause. En d‚Äôautres termes, ces deux facteurs sont simultan√©ment les causes des m√™mes r√©sultats.\n\n\n4. \\(X\\) peut causer \\(Y\\) m√™me si \\(X\\) n‚Äôest pas une condition n√©cessaire ou une condition suffisante pour \\(Y\\).\nOn parle souvent des relations causales en termes d√©terministes. M√™me la citation de Lewis en haut de cette page semble sugg√©rer une relation d√©terministe entre les causes et les effets. On pense parfois que les relations causales impliquent des conditions n√©cessaires (pour que \\(Y\\) se produise, \\(X\\) doit se produire); on pense parfois que de telles relations impliquent des conditions suffisantes (si \\(X\\) se produit, alors \\(Y\\) se produit). Mais une fois que nous parlons d‚Äôunit√©s multiples, il y a au moins deux fa√ßons de penser que \\(X\\) cause \\(Y\\) m√™me si \\(X\\) n‚Äôest ni une condition n√©cessaire ni une condition suffisante pour \\(Y\\). La premi√®re consiste √† tout r√©interpr√©ter en termes probabilistes : par \\(X\\) cause \\(Y\\), on entend simplement que la probabilit√© de \\(Y\\) est plus √©lev√©e lorsque \\(X\\) est pr√©sent. Une autre consiste √† tenir compte des contingences ‚Äî par exemple, \\(X\\) peut causer \\(Y\\) si la condition \\(Z\\) est pr√©sente, mais pas dans le cas contraire.6\n\n\n5. Le probl√®me fondamental de l‚Äôinf√©rence causale.\nSi les effets causaux sont des d√©clarations sur la diff√©rence entre ce qui s‚Äôest produit et ce qui aurait pu se produire, alors les effets causaux ne peuvent pas √™tre mesur√©s. Mauvaise nouvelle ! De mani√®re prospective, vous pouvez organiser les choses de mani√®re √† observer ce qui se passe si une personne re√ßoit un traitement ou ce qui se passe si elle ne re√ßoit pas le traitement. Pourtant, pour la m√™me personne, vous ne pourrez jamais observer ces deux r√©sultats et leur diff√©rence. Cette incapacit√© √† observer les effets causaux au niveau de l‚Äôunit√© est souvent appel√©e le ‚Äúprobl√®me fondamental de l‚Äôinf√©rence causale‚Äù.\n\n\n6. Vous pouvez estimer l‚Äôeffet causal moyen m√™me si vous ne pouvez observer aucun effet causal individuel.\nM√™me si vous ne pouvez pas observer si \\(X\\) cause \\(Y\\) pour une unit√© donn√©e, il est peut-√™tre toujours possible de d√©terminer si \\(X\\) cause \\(Y\\) en moyenne. L‚Äôeffet causal moyen est √©gal √† la diff√©rence entre le r√©sultat moyen pour toutes les unit√©s si elles √©taient toutes dans la condition de contr√¥le et le r√©sultat moyen pour toutes les unit√©s si elles √©taient toutes dans la condition de traitement. De nombreuses strat√©gies d‚Äôidentification causale (voir 10 strat√©gies pour d√©terminer si X a caus√© Y) se concentrent sur des fa√ßons d‚Äôen savoir plus sur ces r√©sultats potentiels moyens.7\n10 choses √† savoir sur les tests d‚Äôhypoth√®se d√©crit comment en savoir plus sur les effets causaux individuels plut√¥t que sur les effets causaux moyens √©tant donn√© le probl√®me fondamental de l‚Äôinf√©rence causale.\n\n\n7. L‚Äôestimation de l‚Äôeffet causal moyen ne n√©cessite pas que les groupes de traitement et de contr√¥le soient identiques.\nUne strat√©gie que les gens utilisent pour en savoir plus sur l‚Äôeffet causal moyen consiste √† cr√©er des groupes de traitement et de contr√¥le par randomisation (voir 10 Strat√©gies pour d√©terminer si X a caus√© Y). Ce faisant, les chercheurs s‚Äôinqui√®tent parfois s‚Äôils constatent que les groupes de traitement et de contr√¥le qui en r√©sultent ne sont pas comparables sur certaines dimensions importantes.\nLa bonne nouvelle est que l‚Äôargument expliquant pourquoi les diff√©rences dans les r√©sultats moyens entre les groupes de traitement et de contr√¥le assign√©s de mani√®re al√©atoire capturent l‚Äôeffet moyen du traitement (en esp√©rance pour des randomisations r√©p√©t√©es au sein du m√™me groupe d‚Äôunit√©s) ne repose pas sur le fait que les groupes de traitement et de contr√¥le ont des caract√©ristiques observ√©es similaires. Il repose uniquement sur l‚Äôid√©e que, en moyenne, les r√©sultats dans les groupes de traitement et de contr√¥le captureront les r√©sultats moyens pour toutes les unit√©s du groupe exp√©rimental si elles √©taient, respectivement, dans le traitement ou dans le contr√¥le. En pratique, les groupes de traitement et de contr√¥le r√©els ne seront pas identiques.8\n\n\n8. La corr√©lation n‚Äôest pas la causalit√©.\nUne corr√©lation entre \\(X\\) et \\(Y\\) est une d√©claration sur les relations entre les r√©sultats r√©els, et non sur la relation entre les r√©sultats r√©els et les r√©sultats contrefactuels. Ainsi, les d√©clarations sur les causes et les corr√©lations n‚Äôont pas grand-chose √† voir les unes avec les autres. Des corr√©lations positives peuvent √™tre coh√©rentes avec des effets causaux positifs, aucun effet causal ou m√™me des effets causaux n√©gatifs. Par exemple, la prise de m√©dicaments contre la toux est positivement corr√©l√©e √† la toux mais a, esp√©rons-le, un effet causal n√©gatif sur la toux.9\n\n\n9. Si vous savez qu‚Äôen moyenne \\(A\\) cause \\(B\\) et \\(B\\) cause \\(C\\), cela ne veut pas dire qu‚Äôen moyenne \\(A\\) cause \\(C\\).\nVous pourriez vous attendre √† ce que si \\(A\\) cause \\(B\\) et \\(B\\) cause \\(C\\), alors \\(A\\) cause \\(C\\).10 Mais il n‚Äôy a aucune raison que les relations causales moyennes soient transitives. Imaginez que \\(A\\) cause \\(B\\) pour les hommes mais pas les femmes et \\(B\\) cause \\(C\\) pour les femmes mais pas les hommes. Ensuite, en moyenne, \\(A\\) cause \\(B\\) et \\(B\\) cause \\(C\\), mais \\(A\\) ne cause pas \\(C\\) √† travers \\(B\\).\n\n\n10. Il est plus facile d‚Äôen apprendre davantage sur les ‚Äúeffets des causes‚Äù que sur les ‚Äúcauses des effets‚Äù.\nBien que cela puisse sembler √™tre deux fa√ßons de dire la m√™me chose, il y a une diff√©rence entre comprendre quel est l‚Äôeffet de \\(X\\) sur \\(Y\\) (les ‚Äúeffets d‚Äôune cause‚Äù) et si un r√©sultat \\(Y\\) √©tait d√ª √† une cause \\(X\\) (la ‚Äúcause d‚Äôun effet‚Äù).11 Consid√©rez l‚Äôexemple suivant. Supposons que nous menions une exp√©rience avec un √©chantillon qui contient un nombre √©gal d‚Äôhommes et de femmes. L‚Äôexp√©rience assigne de mani√®re al√©atoire des hommes et des femmes √† un traitement binaire \\(X\\) et mesure un r√©sultat binaire \\(Y\\). De plus, supposons que \\(X\\) ait un effet positif de 1 pour tous les hommes, c‚Äôest-√†-dire le r√©sultat potentiel de contr√¥le des hommes est de z√©ro, \\(Y_i(0) = 0\\), et leur r√©sultat potentiel trait√© est de un, \\(Y_i(1) = 1\\). Pour toutes les femmes, \\(X\\) a un effet n√©gatif de \\(-1\\), c‚Äôest-√†-dire que le r√©sultat potentiel de contr√¥le des femmes est de un, \\(Y_i(0) = 1\\), et leur r√©sultat potentiel trait√© est de z√©ro, \\(Y_i(1) = 0\\). Dans cet exemple, l‚Äôeffet moyen de \\(X\\) sur \\(Y\\) est nul. Mais pour tous les participants du groupe de traitement avec \\(Y=1\\), il est vrai que \\(Y=1\\) car \\(X=1\\). De m√™me, pour tous les participants du groupe de traitement avec \\(Y=0\\), il est vrai que \\(Y=0\\) car \\(X=1\\). L‚Äôexp√©rimentation peut obtenir une r√©ponse exacte √† la question sur les ‚Äúeffets d‚Äôune cause‚Äù, mais il n‚Äôest g√©n√©ralement pas possible d‚Äôobtenir une r√©ponse exacte √† la question sur la ‚Äúcause d‚Äôun effet‚Äù.12\n\n\n\n\n\nFootnotes\n\n\nLewis, David. ‚ÄúCausation.‚Äù The journal of philosophy (1973): 556-567.‚Ü©Ô∏é\nAuteur d‚Äôorigine : Macartan Humphreys. R√©visions mineures : Winston Lin et Donald P. Green, 24 juin 2016. R√©visions MH 6 janvier 2020. R√©visions Anna Wilke mai 2021. Le guide est un document vivant et peut √™tre mis √† jour par les membres de EGAP √† tout moment ; les contributeurs r√©pertori√©s ne sont pas responsables des modifications ult√©rieures.‚Ü©Ô∏é\nHolland, Paul W. ‚ÄúStatistics and causal inference.‚Äù Journal of the American Statistical Association 81.396 (1986): 945-960.‚Ü©Ô∏é\nHolland, Paul W. ‚ÄúStatistics and causal inference.‚Äù Journal of the American Statistical Association 81.396 (1986): 945-960.‚Ü©Ô∏é\nCertains appellent cela le ‚Äúprobl√®me des causes de prodigalit√©‚Äù.‚Ü©Ô∏é\nMackie a pr√©sent√© l‚Äôid√©e de conditions dites ‚ÄúINSS‚Äù (‚ÄúINUS‚Äù en anglais) pour capturer la d√©pendance des causes sur d‚Äôautres causes. Une cause peut √™tre une partie Insuffisante mais N√©cessaire d‚Äôune condition qui est elle-m√™me Superflue mais Suffisante. Par exemple, composer un num√©ro de t√©l√©phone est une cause de ‚Äúcontacter quelqu‚Äôun‚Äù car avoir une connexion et composer un num√©ro est suffisant (S) pour passer un appel t√©l√©phonique, alors que composer seul sans connexion ne suffirait pas (I), ni avoir un connexion (N). Il existe bien s√ªr d‚Äôautres moyens de contacter quelqu‚Äôun sans passer d‚Äôappels t√©l√©phoniques (S). Mackie, John L. ‚ÄúThe cement of the universe.‚Äù London: Oxford Uni (1974).‚Ü©Ô∏é\nNote technique : La principale id√©e technique est que la diff√©rence des moyennes est la m√™me que la moyenne des diff√©rences. C‚Äôest-√†-dire, en utilisant ‚Äúl‚Äôop√©rateur d‚Äôesp√©rance‚Äù, \\(ùîº(œÑ_i)=ùîº(Y_i(1)‚àíY_i(0))=ùîº(Y_i(1))‚àíùîº(Y_i(0))\\). Les termes √† l‚Äôint√©rieur de l‚Äôop√©rateur d‚Äôesp√©rance dans la deuxi√®me quantit√© ne peuvent pas √™tre estim√©s, mais les termes √† l‚Äôint√©rieur de l‚Äôop√©rateur d‚Äôesp√©rance dans la troisi√®me quantit√© peuvent l‚Äô√™tre.7Voir l‚Äôillustration ici.‚Ü©Ô∏é\nPour cette raison, les tests-\\(t\\) pour v√©rifier si ‚Äúla randomisation a fonctionn√©‚Äù n‚Äôont pas beaucoup de sens, du moins si vous savez qu‚Äôune proc√©dure randomis√©e a √©t√© suivie ‚Äî simplement par hasard, 1 test sur 20 montrera des diff√©rences statistiquement d√©tectables entre les groupes de traitement et de contr√¥le. En cas de doute sur la mise en ≈ìuvre correcte d‚Äôune proc√©dure randomis√©e, ces tests peuvent √™tre utilis√©s pour tester l‚Äôhypoth√®se selon laquelle les donn√©es ont bien √©t√© g√©n√©r√©es par une proc√©dure randomis√©e. Ces tests peuvent alors √™tre particuli√®rement importants pour des exp√©riences de terrain o√π les cha√Ænes de communication entre la personne randomisant et la personne mettant en ≈ìuvre l‚Äôassignation du traitement peuvent √™tre longues et complexes.‚Ü©Ô∏é\nNote technique: soit \\(D_i\\) un indicateur pour savoir si l‚Äôunit√© \\(i\\) a re√ßu un traitement ou non. Alors, la diff√©rence des r√©sultats moyens entre ceux qui re√ßoivent le traitement et ceux qui ne le re√ßoivent pas peut s‚Äô√©crire \\(\\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}‚àí\\frac{‚àë_i (1‚àíD_i)√ó Y_i(0)}{‚àë_i (1‚àíD_i)}\\). En l‚Äôabsence d‚Äôinformations sur la mani√®re dont le traitement a √©t√© assign√©, nous ne pouvons pas dire si cette diff√©rence est un bon estimateur de l‚Äôeffet moyen du traitement, c‚Äôest-√†-dire de la diff√©rence entre les r√©sultats potentiels moyens pour les groupes de traitement et de contr√¥le pour toutes les unit√©s. Ce qui importe est de savoir si \\(\\frac{‚àë_i D_i√óY_i(1)}{‚àë_iD_i}\\) est une bonne estimation de \\(\\frac{‚àë_i 1√óY_i(1)}{‚àë_i1}\\) et si \\(\\frac {‚àë_i (1‚àíD_i)√óY_i(0)}{‚àë_i (1‚àíD_i)}\\) est une bonne estimation de \\(\\frac{‚àë_i 1√óY_i(0)}{‚àë_i1}\\). Cela pourrait √™tre le cas si ceux qui ont re√ßu un traitement sont un √©chantillon repr√©sentatif de toutes les unit√©s, mais sinon il n‚Äôy a aucune raison de s‚Äôattendre √† ce qu‚Äôil le soit.‚Ü©Ô∏é\nInterpr√©tez ‚Äú\\(A\\) cause \\(B\\), en moyenne‚Äù comme ‚Äúl‚Äôeffet moyen de \\(A\\) sur \\(B\\) est positif‚Äù.‚Ü©Ô∏é\nCertains r√©interpr√®tent la question des ‚Äúcauses des effets‚Äù comme suit : quelles sont les causes qui ont des effets sur les r√©sultats. Voir Andrew Gelman and Guido Imbens, ‚ÄúWhy ask why? Forward causal inference and reverse causal questions‚Äù, NBER Working Paper No.¬†19614 (Nov.¬†2013).‚Ü©Ô∏é\nVoir, par exemple, Tian, J., Pearl, J. 2000. ‚ÄúProbabilities of Causation: Bounds and Identification.‚Äù Annals of Mathematics and Artificial Intelligence 28:287‚Äì313.‚Ü©Ô∏é"
  },
  {
    "objectID": "guides/getting-started/covariates_en.html",
    "href": "guides/getting-started/covariates_en.html",
    "title": "10 Things to Know About Covariate Adjustment",
    "section": "",
    "text": "1 What is covariate adjustment?\n‚ÄúCovariates‚Äù are baseline characteristics of your experimental subjects. When you run an experiment, you are primarily interested in collecting data on outcome variables that your intervention may affect, e.g.¬†expenditure decisions, attitudes toward democracy, or contributions for a public good in a lab experiment. But it‚Äôs also a good idea to collect data on baseline characteristics of subjects before treatment assignment occurs, e.g.¬†gender, level of education, or ethnic group. If you do this you can explore how treatment effects vary with these characteristics (see 10 Things to Know About Heterogeneous Treatment Effects). But doing this also lets you perform covariate adjustment.\nCovariate adjustment is another name for controlling for baseline variables when estimating treatment effects. Often this is done to improve precision. Subjects‚Äô outcomes are likely to have some correlation with variables that can be measured before random assignment. Accounting for variables like gender will allow you to set aside the variation in outcomes that is predicted by these baseline variables, so that you can isolate the effect of treatment on outcomes with greater precision and power.\nCovariate adjustment can be a cheaper route to improved precision than increasing the number of subjects in the experiment. Partly for that reason, researchers often collect extensive data on covariates before random assignment. Pre-tests (measures that are analogous to the outcome variable but are restricted to time periods before random assignment) may be especially valuable for predicting outcomes, and baseline surveys can ask subjects about other background characteristics.\n\n\n2 Controlling for covariates at the design stage (blocking)\nThe best way to control for covariates is to use block randomization to do it at the design stage even before you start your experiment. Block randomization enables you to create treatment and control groups that are balanced on certain covariates. For example, you might expect that gender and income help predict the outcome variable. Block randomization can ensure that the treatment and control groups have equal proportions of female/high-income, female/low-income, male/high-income, and male/low-income populations. When the blocking variables help predict outcomes, blocking improves precision by preventing chance correlations between treatment assignment and baseline covariates.\nFor more information on blocking and how to implement it in R, see 10 Things You Need to Know About Randomization. The precision gains from blocking (relative to covariate adjustment without blocking) tend to be greatest when sample sizes are small.2\nWhen blocking is done to improve precision, estimated standard errors should take the blocking into account. (Otherwise, the SEs will tend to be conservative because they won‚Äôt give you credit for the precision improvement that blocking achieved.) One simple and commonly used method is to regress the outcome on the treatment assignment dummy variable as well as block dummies. When the probability of assignment to treatment is constant across blocks, including the block dummies in the regression doesn‚Äôt change the estimated treatment effect, but tends to give a more accurate estimate of the SE.3\nIf the probability of assignment to treatment varies by block, then you need to control for these unequal probabilities in order to get unbiased estimates of average treatment effects. 10 Things You Need to Know About Randomization discusses ways to do this.\n\n\n3 How to do it in a regression\nSometimes you do not have the opportunity to implement a blocked experimental design (for example, if you join a project after random assignment occurs) or you would prefer to simplify your randomization scheme to reduce opportunities for administrative error. You can still adjust for covariates on the back end by using multiple regression. Remember that in a bivariate regression‚Äîwhen you regress your outcome on just your treatment indicator‚Äîthe coefficient on treatment is just a difference-in-means. This simple method gives an unbiased estimate of the average treatment effect (ATE). When we add baseline covariates that are correlated with outcomes to the model, the coefficient on treatment is an approximately unbiased estimate of the ATE that tends to be more precise than bivariate regression.\nTo adjust for covariates through multiple regression, use the model:\n\\[Y_i = \\alpha + \\beta Z_i + \\gamma X_i + \\epsilon_i\\]\nwhere \\(Y_i\\) is the outcome variable, \\(Z_i\\) is the treatment indicator, and \\(X_i\\) is a vector of one or more covariates. The remainder \\(\\epsilon_i\\) is your disturbance term‚Äîthe leftover unexplained noise.\nWhen the treatment and control groups are of unequal size, the precision gains from covariate adjustment may be greater if you include interactions between treatment and the covariates (see this blog post for more discussion). For ease of interpretation, recenter the covariates to have zero mean:\n\\[Y_i = \\alpha + \\beta Z_i + \\gamma W_i + \\delta Z_i*W_i + \\epsilon_i\\]\nwhere \\(W_i = X_i - \\overline{X}\\) and \\(\\overline{X}\\) is the mean value of \\(X_i\\) for the entire sample.\nIf subjects receive different probabilities of assignment to treatment based on their covariates, then our estimation method needs to account for this (again, see 10 Things You Need to Know About Randomization for details).\n\n\n4 Why to do it\nIt isn‚Äôt absolutely necessary to control for covariates when estimating the average treatment effect in an RCT that assigns every subject the same probability of receiving the treatment. The unadjusted treatment‚Äìcontrol difference in mean outcomes is an unbiased estimator of the ATE. However, covariate adjustment tends to improve precision if the covariates are good predictors of the outcome.4\nIn large samples, random assignment tends to produce treatment and control groups with similar baseline characteristics. Still, by the ‚Äúluck of the draw,‚Äù one group may be slightly more educated, or one group may have slightly higher voting rates in previous elections, or one group may be slightly older on average. For this reason, the estimated ATE is subject to ‚Äúsampling variability,‚Äù meaning you‚Äôll get estimates of the ATE that were produced by an unbiased method but happened to miss the mark.5 A high sampling variability contributes to noise (imprecision), not bias.\nControlling for these covariates tends to improve precision if the covariates are predictive of potential outcomes. Take a look at the following example, which is loosely based on the Gin√© and Mansuri experiment on female voting behavior in Pakistan.6 In this experiment, the authors randomized an information campaign to women in Pakistan to study its effects on their turnout behavior, the independence of their candidate choice, and their political knowledge. They carried out a baseline survey which provided them with several covariates.\nThe following code imitates this experiment by creating fake data for four of the covariates they collect: whether the woman owns an identification card, whether the woman has formal schooling, the woman‚Äôs age, and whether the woman has access to TV. It also creates two potential outcomes (the outcomes that would occur if she were assigned to treatment and if not) for a measure of the extent to which a woman‚Äôs choice of candidate was independent of the opinions of the men in her family. The potential outcomes are correlated with all four covariates, and the built-in ‚Äútrue‚Äù treatment effect on the independence measure here is 1. To figure out whether our estimator is biased or not, we simulate 10,000 replications of our experiment. On each replication, we randomly assign treatment and then regress the observed outcome \\(Y\\) on the treatment indicator \\(Z\\), with and without controlling for covariates. Thus, we are simulating two methods (unadjusted and covariate-adjusted) for estimating the ATE. To estimate the bias of each method, we take the difference between the average of the 10,000 simulated estimates and the ‚Äútrue‚Äù treatment effect.\n\nrm(list=ls())\nset.seed(20140714)\nN = 2000\nN.treated = 1000\nReplications = 10000\ntrue.treatment.effect = 1\n# Create pre-treatment covariates\nowns.id.card = rbinom(n = N, size = 1, prob = .18)\nhas.formal.schooling = rbinom(n = N, size = 1, prob = .6)\nage = round(rnorm(n = N, mean = 37, sd = 16))\nage[age<18] = 18\nage[age>65] = 65\nTV.access = rbinom(n = N, size = 1, prob = .7)\nepsilon = rnorm(n = N, mean = 0, sd = 2)\n# Create potential outcomes correlated with pre-treatment covariates\nY0 = round(owns.id.card + 2*has.formal.schooling + 3*TV.access + log(age) + epsilon)\nY1 = Y0 + true.treatment.effect\n# Assign treatment repeatedly\nZ.mat = replicate(Replications, ifelse(1:N %in% sample(1:N, N.treated), 1, 0))\n# Generate observed outcomes\nY.mat = Y1 * Z.mat + Y0 * (1 - Z.mat)\ndiff.in.means = function(Y, Z) {\n  coef(lm(Y ~ Z))[2]\n}\nols.adjust = function(Y, Z) {\n  coef(lm(Y ~ Z + owns.id.card + has.formal.schooling + age + TV.access))[2]\n}\nunadjusted.estimates = rep(NA, Replications)\nadjusted.estimates   = rep(NA, Replications)\nfor (i in 1:Replications) {\n  unadjusted.estimates[i]  =  diff.in.means(Y.mat[,i], Z.mat[,i])\n  adjusted.estimates[i]    =  ols.adjust(Y.mat[,i], Z.mat[,i])\n}\n# Estimated variability (standard deviation) of each estimator\nsd.of.unadj = sd(unadjusted.estimates)\nsd.of.unadj\nsd.of.adj   = sd(adjusted.estimates)\nsd.of.adj\n# Estimated bias of each estimator\nmean(unadjusted.estimates) - true.treatment.effect\nmean(adjusted.estimates) - true.treatment.effect\n# Margin of error (at 95% confidence level) for each estimated bias\n1.96 * sd.of.unadj / sqrt(Replications)\n1.96 * sd.of.adj   / sqrt(Replications)\n\nBoth methods‚Äîwith and without covariates‚Äîyield the true treatment effect of 1 on average. When we ran the regression without covariates, our estimated ATE averaged 1.0008 across the 10,000 replications, and with covariates, it averaged 1.0003. Notice that the regression-adjusted estimate is essentially unbiased even though our regression model is misspecified‚Äîwe control for age linearly when the true data generating process involves the log of age.7\nThe real gains come in the precision of our estimates. The standard error (the standard deviation of the sampling distribution) of our estimated ATE when we ignore covariates is 0.121. When we include covariates in the model, our estimate becomes a bit tighter: the standard error is 0.093. Because our covariates were prognostic of our outcome, including them in the regression explained some noise in our data so that we could tighten our estimate of ATE.\n\n\n5 When will it help?\nWhen is adjusting for covariates most likely to improve precision?\nCovariate adjustment will be most helpful when your covariates are strongly predictive (or ‚Äúprognostic‚Äù) of your outcomes. Covariate adjustment essentially enables you to make use of information about relationships between baseline characteristics and your outcome so that you can better identify the relationship between treatment and the outcome. But if the baseline characteristics are only weakly correlated with the outcome, covariate adjustment won‚Äôt do you much good. The covariates you will want to adjust for are the ones that are strongly correlated with outcomes.\nThe following graph demonstrates the relationship between how prognostic your covariate is and the gains you get from adjusting for it. On the x-axis is the sample size, and on the y-axis is the root mean squared error (RMSE), the square root of the average squared difference between the estimator and the true ATE. We want our RMSE to be small, and covariate adjustment should help us reduce it.\n\nrm(list=ls())\nlibrary(MASS)  # for mvrnorm()\nset.seed(1234567)\nnum.reps = 10000\n# True treatment effect is 0 for every unit\nadj.est = function(n, cov.matrix, treated) {\n    Y.and.X  =  mvrnorm(n, mu = c(0, 0), Sigma = cov.matrix)\n    Y   =  Y.and.X[, 1]  \n    X   =  Y.and.X[, 2]\n    coef(lm(Y ~ treated + X))[2]\n}\nunadj.est = function(n, treated) {\n    Y = rnorm(n)\n    coef(lm(Y ~ treated))[2]\n}\nrmse = function(half.n, rho = 0, control = TRUE) {\n    treated  =  rep(c(0, 1), half.n)\n    n = 2 * half.n\n    if (control) {\n        cov.matrix  =  matrix(c(1, rho, rho, 1), nrow = 2, ncol = 2)\n        return( sqrt(mean(replicate(num.reps, adj.est(n, cov.matrix, treated)) ^ 2)) )\n    }\n    else {\n        return( sqrt(mean(replicate(num.reps, unadj.est(n, treated)) ^ 2)) )\n    }\n}\nhalf.n = c(5, 7, 11, 19, 35, 67, 131)\nn = 2 * half.n \nE  = sapply(half.n, rmse, control = FALSE)\nE0 = sapply(half.n, rmse, rho = 0)\nE1 = sapply(half.n, rmse, rho = 0.5)\nE2 = sapply(half.n, rmse, rho = 0.9)\nplot(n, E, type = \"l\", ylab = \"RMSE\", xlim = c(min(n),max(n)), ylim = c(0,.75))\nlines(n, E0, col = \"yellow\")\nlines(n, E1, col = \"orange\")\nlines(n, E2, col = \"red\")\nlegend(x = 'topright',\n       c(\"No controls\",\n         expression(paste(rho, \"=0\")), expression(paste(rho, \"=0.5\")),\n         expression(paste(rho, \"=0.9\"))),\n         col=c(\"black\", \"yellow\",\"orange\", \"red\"), lty = 1, lwd=2)\n\n\nThe black line shows the RMSE when we don‚Äôt adjust for a covariate. The red line shows the RMSE when we adjust for a highly prognostic covariate (the correlation between the covariate and the outcome is 0.9). You can see that the red line is always below the black line, which is to say that the RMSE is lower when you adjust for a prognostic covariate. The orange line represents the RMSE when we adjust for a moderately prognostic covariate (the correlation between the covariate and the outcome is 0.5). We still are getting gains in precision relative to the black line, but not nearly as much as we did with the red line. Finally, the yellow line shows what happens if you control for a covariate that is not at all predictive of the outcome. The yellow line is almost identical to the black line. You received no improvement in precision by controlling for a non-prognostic covariate; in fact, you paid a slight penalty because you wasted a degree of freedom, which is especially costly when the sample size is small. This exercise demonstrates that you‚Äôll get the most gains in precision by controlling for covariates that strongly predict outcomes.\nHow can you know which covariates are likely to be prognostic before launching your experiment? Prior experiments or even observational studies can offer guidance about which baseline characteristics best predict outcomes.\n\n\n6 Control for prognostic covariates regardless of whether they show imbalances\nCovariates should generally be chosen on the basis of their expected ability to help predict outcomes, regardless of whether they show ‚Äúimbalances‚Äù (i.e., regardless of whether there are any noteworthy differences between the treatment group and control group in average values or other aspects of covariate distributions). There are two reasons for this recommendation:\n\nFrequentist statistical inference (standard errors, confidence intervals, p-values, etc.) assumes that the analysis follows a pre-specified strategy. Choosing covariates on the basis of observed imbalances makes it more difficult to obtain inferences that reflect your actual strategy. For example, suppose you choose not to control for gender because the treatment and control groups have similar gender composition, but you would have controlled for gender if there‚Äôd been a noticeable imbalance. Typical methods for estimating standard errors will incorrectly assume that you‚Äôd never control for gender no matter how much imbalance you saw.\nAdjusting for a highly prognostic covariate tends to improve precision, as we explained above. To receive due credit for this precision improvement, you should adjust for the covariate even if there‚Äôs no imbalance. For example, suppose gender is highly correlated with your outcome, but it happens that the treatment group and control group have exactly the same gender composition. In this case, the unadjusted estimate of the ATE will be exactly the same as the adjusted estimate from a regression of the outcome on treatment and gender, but their standard errors will differ. The SE of the unadjusted estimate tends to be larger because it assumes that even if the treatment and control groups had very different gender compositions, you‚Äôd still use the unadjusted treatment‚Äìcontrol difference in mean outcomes (which would likely be far from the true ATE in that case). If you pre-specify that you‚Äôll adjust for gender regardless of how much or how little imbalance you see, you‚Äôll tend to get smaller SEs, tighter confidence intervals, and more powerful significance tests.\n\nAssuming that random assignment was implemented correctly, should examination of imbalances play any role in choosing which covariates to adjust for? Here‚Äôs a sampling of views:\n\nMutz, Pemantle, and Pham (2016) argue that, unless there is differential attrition, the practice of selecting covariates on the basis of observed imbalances is ‚Äúnot only unnecessary‚Äù but ‚Äúnot even helpful ‚Ä¶ and may in fact be damaging,‚Äù because it invalidates confidence intervals, worsens precision (relative to pre-specified adjustment for prognostic covariates), and opens the door to fishing.8\nPermutt (1990), using theory and simulations to study specific scenarios, finds that when a balance test is used to decide whether to adjust for a covariate, the significance test for the treatment effect is conservative (i.e., it has a true Type I error probability below its nominal level). He writes, ‚ÄúGreater power can be achieved by always adjusting for a covariate that is highly correlated with the response regardless of its distribution between groups.‚Äù However, he doesn‚Äôt completely rule out considering observed imbalances: ‚ÄúChoosing covariates on the basis of the difference between the means in the treatment and control groups is not irrational. After all, some type I errors may be more serious than others. Reporting a significant difference in outcome which can be explained away as the effect of a covariate may be a more embarrassing error than reporting one that happens to go away on replication but without an easy explanation. Similar considerations may apply to type II errors. A positive result that depends on adjustment for a covariate may be seen as less convincing than a positive two-sample test anyway, so that the error of failing to draw such a positive conclusion may be less serious. These justifications, however, come from outside the formal theory of testing hypotheses.‚Äù9\nAltman (2005) writes, ‚ÄúIt seems far preferable to choose which variables to adjust for without regard to the actual data set to hand.‚Äù He recommends controlling for highly prognostic covariates, as well as any that were used in blocking. However, he also discusses a dilemma: ‚ÄúIn practice, imbalance may arise when the possible need for adjustment has not been anticipated. What should the researchers do? They might choose to ignore the imbalance; as noted, this would be entirely proper. The difficulty then is one of credibility. Readers of their paper (including reviewers and editors) may question whether the observed finding has been influenced by the unequal distribution of one or more baseline covariates. It is still possible, and arguably advisable, to carry out an adjusted analysis, but now with the explicit acknowledgment that this is an exploratory rather than definitive analysis, and that the unadjusted analysis should be taken as the primary one. Obviously, if the simple and adjusted analyses yield substantially the same result, then there is no difficulty of interpretation. This will usually be the case. However, if the results of the two analyses differ, then there is a real problem. The existence of such a discrepancy must cast some doubt on the veracity of the overall (unadjusted) result. The situation is similar to the difficulties of interpretation that arise with unplanned subgroup comparisons. One suggestion in such circumstances is to try to mimic what would have been done if the problem had been anticipated, namely to adjust not for variables that are observed to be unbalanced, but for all variables that would have been identified in advance as prognostic. An independent source could be used to identify such variables. Alternatively, the trial data could be used to determine which variables are prognostic. This strategy too could be prespecified in the study protocol. Because this analysis would be performed conditionally on the observed imbalance, it does not remove bias and thus cannot be considered fully satisfactory.‚Äù10\nTukey (1991) notes that observed imbalances may justify adjustment as a robustness check: Although ‚Äúmost statisticians‚Äù would accept an analysis of a randomized clinical trial that doesn‚Äôt adjust for covariates, ‚ÄúSome clinicians, and some statisticians it would seem, would like to be more sceptical, (perhaps as a supplemental analysis) asking for an analysis that takes account of observed imbalances in these recorded covariates. Feeling more secure about the results of such an analysis is indeed appropriate, since the degree of protection against either the consequences of inadequate randomization or the (random) occurrence of an unusual randomization is considerably increased by adjustment. Greater security, rather than increased precision ‚Ä¶ will often be the basic reason for covariance adjustment in a randomized trial. ‚Ä¶ The main purpose of allowing [adjusting] for covariates in a randomized trial is defensive: to make it clear that analysis has met its scientific obligations.‚Äù11\nSome statisticians argue that our inferences should be conditional on a measure of covariate imbalance‚Äîin other words, when assessing the bias, variance, and mean squared error of a point estimate or the coverage probability of a confidence interval, instead of considering all possible randomizations, it may be more relevant to consider only those randomizations that would yield a covariate imbalance similar to the one we observe. From this perspective, observed imbalances may be relevant to the choice of estimator.12\nLin, Green, and Coppock (2016) write: ‚ÄúCovariates should generally be chosen on the basis of their expected ability to help predict outcomes, regardless of whether they appear well-balanced or imbalanced across treatment arms. But there may be occasions when the covariate list specified in the PAP [pre-analysis plan] omitted a potentially important covariate (due to either an oversight or the need to keep the list short when N is small) with a nontrivial imbalance. Protection against ex post bias (conditional on the observed imbalance) is then a legitimate concern.‚Äù However, they recommend that if observed imbalances are allowed to influence the choice of covariates, ‚Äúthe balance checks and decisions about adjustment should be finalized before we see unblinded outcome data,‚Äù ‚Äúthe direction of the observed imbalance (e.g., whether the treatment group or the control group appears more advantaged at baseline) should not be allowed to influence decisions about adjustment,‚Äù and the originally pre-specified estimator should ‚Äúalways be reported and labeled as such, even if alternative estimates are also reported.‚Äù13\n\n\n\n7 When not to do it\nIt is a bad idea to adjust for covariates when you think those covariates could have been influenced by your treatment. This is one of the reasons that many covariates are collected from baseline surveys; sometimes covariates that are collected from surveys after intervention could reflect the effects of the treatment rather than underlying characteristics of the subject. Adjusting for covariates that are affected by the treatment‚Äî‚Äúpost-treatment‚Äù covariates‚Äîcan cause bias.\nSuppose, for example, that Gin√© and Mansuri had collected data on how many political rallies a woman attended after receiving the treatment. In estimating the treatment effect on independence of political choice, you may be tempted to include this variable as a covariate in your regression. But including this variable, even if it strongly predicts the outcome, may distort the estimated effect of the treatment.\nLet‚Äôs create this fake variable, which is correlated (like the outcome measure) with baseline covariates and also with treatment. Here, by construction, the treatment effect on number of political rallies attended is 2. When we included the rallies variable as a covariate, the estimated average treatment effect on independence of candidate choice averaged 0.54 across the 10,000 replications. Recall that the true treatment effect on this outcome is 1. This is severe bias, all because we controlled for a post-treatment covariate!14 This bias results from the fact that the covariate is correlated with treatment.\n\n# Create post-treatment covariate that's correlated with pre-treatment covariates\nrallies0 = round(.5*owns.id.card + has.formal.schooling + 1.5*TV.access + log(age))\nrallies1 = rallies0 + 2\nrallies.mat = rallies1 * Z.mat + rallies0 * (1-Z.mat)\n \n# Estimate ATE with new model that includes the post-treatment covariate\nadjust.for.post = function(Y, Z, X) {\n  coef(lm(Y ~ Z + X + owns.id.card + has.formal.schooling + age + TV.access))[2]\n}\npost.adjusted.estimates = rep(NA, Replications)\nfor (i in 1:Replications) {\n  post.adjusted.estimates[i]  =  adjust.for.post(Y.mat[,i], Z.mat[,i], rallies.mat[,i])\n}\n# Estimated bias of the new estimator\nmean(post.adjusted.estimates) - true.treatment.effect\n# Margin of error (at 95% confidence level) for the estimated bias\n1.96 * sd(post.adjusted.estimates) / sqrt(Replications)\n\nJust because you should not adjust for post-treatment covariates does not mean you cannot collect covariate data post-treatment, but you must exercise caution. Some measures could be collected post-treatment but are unlikely to be affected by treatment (e.g., age and gender). Be careful about measures that may be subject to evaluation-driven effects, though: for example, treated women may be more acutely aware of the expectation of political participation and may retrospectively report that they were more politically active than they actually were several years prior.\n\n\n8 Concerns about small-sample bias\nIn small samples, regression adjustment may produce a biased estimate of the average treatment effect.15 Some simulations have suggested that this bias tends to be negligible when the number of randomly assigned units is greater than twenty.16 If you‚Äôre working with a small sample, you may want to use an unbiased covariate adjustment method such as post-stratification (splitting the sample into subgroups based on the values of one or more baseline covariates, computing the treatment‚Äìcontrol difference in mean outcomes for each subgroup, and taking a weighted average of these subgroup-specific treatment effect estimates, with weights proportional to sample size).17\n\n\n9 How to make your covariate adjustment decisions transparent\nIn the interests of transparency, if you adjust for covariates, pre-specify your models and report both unadjusted and covariate-adjusted estimates.\nThe simulations above have demonstrated that results may change slightly or not-so-slightly depending on which covariates you choose to include in your model. We‚Äôve highlighted some rules of thumb here: include only pre-treatment covariates that are predictive of outcomes. Deciding which covariates to include, though, is often a subjective rather than an objective enterprise, so another rule of thumb is to be totally transparent about your covariate decisions. Always include the simplest model‚Äîthe simple regression of outcome on treatment without controlling for covariates‚Äîin your paper or appendix to supplement the findings of your model including covariates.\nAnother way to minimize your readers‚Äô concern that you went fishing for the particular combination of covariates that gave results favorable to your hypotheses is to pre-specify your models in a pre-analysis plan.18 This gives you the opportunity to explain before you see the findings which pre-treatment covariates you expect to be predictive of the outcome. You can even write these regressions out in R using fake data, as done here, so that when your results from the field arrive, all you need to do is run your code on the real data. These efforts are a useful way of binding your own hands as a researcher and improving your credibility.\n\n\n10 Covariates can help you investigate the integrity of the random assignment\nSometimes it is unclear whether random assignment actually occurred (or whether it occurred using the procedure that the researcher envisions). For example, when scholars analyze naturally occurring random assignments (e.g., those conducted by a government agency), it is useful to assess statistically whether the degree of imbalance between the treatment and control groups is within the expected margin of error. One statistical test is to regress treatment assignment on all of the covariates and calculate the F-statistic. The significance of this statistic can be assessed by simulating a large number of random assignments and for each one calculating the F-statistic; the resulting distribution can be used to calculate the p-value of the observed F-statistic. For example, if 10,000 simulations are conducted, and just 30 simulations generate an F-statistic larger than what one actually obtained from the data, the p-value is 0.003, which suggests that the observed level of imbalance is highly unusual. In such cases, one may wish to investigate the randomization procedure more closely.\n\n\nFor further reading\nAthey, Susan, and Guido W. Imbens (2017). ‚ÄúThe Econometrics of Randomized Experiments.‚Äù In Handbook of Economic Field Experiments, vol.¬†1 (E. Duflo and A. Banerjee, eds.). arXiv DOI\nGerber, Alan S., and Donald P. Green (2012). Field Experiments: Design, Analysis, and Interpretation, chapter 4.\nHennessy, Jonathan, Tirthankar Dasgupta, Luke Miratrix, Cassandra Pattanayak, and Pradipta Sarkar (2016). ‚ÄúA Conditional Randomization Test to Account for Covariate Imbalance in Randomized Experiments.‚Äù Journal of Causal Inference 4: 61‚Äì80.\nJudkins, David R., and Kristin E. Porter (2016). ‚ÄúRobustness of Ordinary Least Squares in Randomized Clinical Trials.‚Äù Statistics in Medicine 35: 1763‚Äì1773.\nLin, Winston (2012). ‚ÄúRegression Adjustment in Randomized Experiments: Is the Cure Really Worse than the Disease?‚Äù Development Impact blog post, part I and part II.\nRaudenbush, Stephen W. (1997). ‚ÄúStatistical Analysis and Optimal Design for Cluster Randomized Trials.‚Äù Psychological Methods 2: 173‚Äì185.\nWager, Stefan, Wenfei Du, Jonathan Taylor, and Robert Tibshirani (2016). ‚ÄúHigh-Dimensional Regression Adjustments in Randomized Experiments.‚Äù Proceedings of the National Academy of Sciences 113: 12673‚Äì12678. arXiv DOI\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Lindsay Dolan. Revisions: Don Green and Winston Lin, 1 Nov 2016. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits. Thanks to Macartan Humphreys and Diana Mutz for helpful discussions.‚Ü©Ô∏é\nMiratrix, Luke W., Jasjeet S. Sekhon, and Bin Yu (2013). ‚ÄúAdjusting Treatment Effect Estimates by Post-Stratification in Randomized Experiments.‚Äù Journal of the Royal Statistical Society, Series B 75: 369‚Äì396.‚Ü©Ô∏é\nSee, e.g., pages 217‚Äì219 of Miriam Bruhn and David McKenzie (2009), ‚ÄúIn Pursuit of Balance: Randomization in Practice in Development Field Experiments,‚Äù American Economic Journal: Applied Economics 1 (4): 200‚Äì232.‚Ü©Ô∏é\nA brief review of bias and precision: Imagine replicating the experiment many times (without changing the experimental sample and conditions, but re-doing random assignment each time). An unbiased estimator may overestimate or underestimate the ATE on any given replication, but its expected value (the average over all possible replications) will equal the true ATE. We usually prefer unbiased or approximately unbiased estimators, but we also value precision (which is formally defined as the inverse of the variance). Imagine you‚Äôre throwing a dart at a dartboard. If you hit the center of the dartboard on average but your shots are often far from the mark, you have an unbiased but imprecise estimator. If you hit close to the center every time, your estimator is more precise. A researcher may choose to accept a small bias in return for a large improvement in precision. One possible criterion for evaluating estimators is the mean squared error, which equals the variance plus the square of the bias. See, e.g., Sharon Lohr (2010), Sampling: Design and Analysis, 2nd ed., pp.¬†31‚Äì32.‚Ü©Ô∏é\n‚ÄúSampling variability‚Äù refers to the spread of estimates that will be produced just because of the different random assignments that could have been drawn. When the luck of the draw of random assignment produces a treatment group with more As and a control group with more Bs, it is more difficult to separate background characteristics (A and B) from treatment assignment as the predictor of the observed outcomes.‚Ü©Ô∏é\nGin√©, Xavier, and Ghazala Mansuri (2012). ‚ÄúTogether We Will: Experimental Evidence on Female Voting Behavior in Pakistan.‚Äù‚Ü©Ô∏é\nThe estimated bias is 0.0003 with a margin of error (at the 95% confidence level) of 0.0018.‚Ü©Ô∏é\nDiana C. Mutz, Robin Pemantle, and Philip Pham (2016), ‚ÄúModel Choice in Experimental Design: Messy Analyses of Clean Data.‚Äù‚Ü©Ô∏é\nThomas Permutt (1990), ‚ÄúTesting for Imbalance of Covariates in Controlled Experiments,‚Äù Statistics in Medicine 9: 1455‚Äì1462.‚Ü©Ô∏é\nDouglas G. Altman (2005), ‚ÄúCovariate Imbalance, Adjustment for,‚Äù in Encyclopedia of Biostatistics.‚Ü©Ô∏é\nJohn W. Tukey (1991), ‚ÄúUse of Many Covariates in Clinical Trials,‚Äù International Statistical Review 59: 123‚Äì137. Italics in the original.‚Ü©Ô∏é\nSee, e.g.: D. R. Cox and N. Reid (2000), The Theory of the Design of Experiments, pp.¬†29‚Äì32; D. Holt and T. M. F. Smith (1979), ‚ÄúPost Stratification,‚Äù Journal of the Royal Statistical Society, Series A (General) 142: 33‚Äì46; Richard M. Royall (1976), ‚ÄúCurrent Advances in Sampling Theory: Implications for Human Observational Studies,‚Äù American Journal of Epidemiology 104: 463‚Äì474. For an introduction to philosophical disagreements about statistical inference, see Bradley Efron (1978), ‚ÄúControversies in the Foundations of Statistics,‚Äù American Mathematical Monthly 85: 231‚Äì246.‚Ü©Ô∏é\nWinston Lin, Donald P. Green, and Alexander Coppock (2016), ‚ÄúStandard Operating Procedures for Don Green‚Äôs Lab at Columbia,‚Äù version 1.05, June 7. Italics in the original.‚Ü©Ô∏é\nThe estimated bias is \\(-\\) 0.459 with a margin of error (at the 95% confidence level) of 0.002.‚Ü©Ô∏é\nDavid A. Freedman (2008), ‚ÄúOn Regression Adjustments in Experiments with Several Treatments,‚Äù Annals of Applied Statistics 2: 176‚Äì196. See also Winston Lin‚Äôs blog posts (part I and part II) discussing his response to Freedman.‚Ü©Ô∏é\nGreen, Donald P. and Aronow, Peter M., Analyzing Experimental Data Using Regression: When Is Bias a Practical Concern? (March 7, 2011). Working paper: http://ssrn.com/abstract=1466886‚Ü©Ô∏é\nMiratrix, Sekhon, and Yu (2013), cited above.‚Ü©Ô∏é\nFor more discussion of pre-analysis plans, see, e.g., Benjamin A. Olken (2015), ‚ÄúPromises and Perils of Pre-Analysis Plans,‚Äù Journal of Economic Perspectives 29 (3): 61‚Äì80.‚Ü©Ô∏é"
  },
  {
    "objectID": "guides/planning/power_en.html",
    "href": "guides/planning/power_en.html",
    "title": "10 Things You Need to Know About Statistical Power",
    "section": "",
    "text": "1 What Power Is\nPower is the ability to distinguish signal from noise.\nThe signal that we are interested in is the impact of a treatment on some outcome. Does education increase incomes? Do public health campaigns decrease the incidence of disease? Can international monitoring decrease government corruption?\nThe noise that we are concerned about comes from the complexity of the world. Outcomes vary across people and places for myriad reasons. In statistical terms, you can think of this variation as the standard deviation of the outcome variable. For example, suppose an experiment uses rates of a rare disease as an outcome. The total number of affected people isn‚Äôt likely to fluctuate wildly day to day, meaning that the background noise in this environment will be low. When noise is low, experiments can detect even small changes in average outcomes. A treatment that decreased the incidence of the disease by 1% percentage points would be easily detected, because the baseline rates are so constant.\nNow suppose an experiment instead used subjects‚Äô income as an outcome variable. Incomes can vary pretty widely ‚Äì in some places, it is not uncommon for people to have neighbors that earn two, ten, or one hundred times their daily wages. When noise is high, experiments have more trouble. A treatment that increased workers‚Äô incomes by 1% would be difficult to detect, because incomes differ by so much in the first place.\nA major concern before embarking on an experiment is the danger of a false negative. Suppose the treatment really does have a causal impact on outcomes. It would be a shame to go to all the trouble and expense of randomizing the treatment, collecting data on both treatment and control groups, and analyzing the results, just to have the effect be overwhelmed by background noise.\nIf our experiments are highly-powered, we can be confident that if there truly is a treatment effect, we‚Äôll be able to see it.\n\n\n2 Why You Need It\nExperimenters often guard against false positives with statistical significance tests. After an experiment has been run, we are concerned about falsely concluding that there is an effect when there really isn‚Äôt.\nPower analysis asks the opposite question: supposing there truly is a treatment effect and you were to run your experiment a huge number of times, how often will you get a statistically significant result?\nAnswering this question requires informed guesswork. You‚Äôll have to supply guesses as to how big your treatment effect can reasonably be, how many subjects will answer your survey, how many subjects your organization can realistically afford to treat.\nWhere do these guesses come from? Before an experiment is run, there is often a wealth of baseline data that are available. How old/rich/educated are subjects like yours going to be? How big was the biggest treatment effect ever established for your dependent variable? With power analysis, you can see how sensitive the probability of getting significant results is to changes in your assumptions.\nMany disciplines have settled on a target power value of 0.80. Researchers will tweak their designs and assumptions until they can be confident that their experiments will return statistically significant results 80% of the time. While this convention is a useful benchmark, be sure that you are comfortable with the risks associated with an 80% expected success rate.\nA note of caution: power matters a lot. Negative results from underpowered studies can be hard to interpret: Is there really no effect? Or is the study just not able to figure it out? Positive results from an underpowered study can also be misleading: conditional upon being statistically significant, an estimate from an underpowered study probably overestimates treatment effects. Under powered studies are sometimes based on overly optimistic assumptions; a convincing power analysis makes these assumptions explicit and should protect you from implementing designs that realistically have no chance of answering the questions you want to answer.\n\n\n3 The Three Ingredients of Statistical Power\nThere are three big categories of things that determine how highly powered your experiment will be. The first two (the strength of the treatment and background noise) are things that you can‚Äôt really control ‚Äì these are the realities of your experimental environment. The last, the experimental design, is the only thing that you have power over ‚Äì use it!\n\nStrength of the treatment. As the strength of your treatment increases, the power of your experiment increases. This makes sense: if your treatment were giving every subject $1,000,000, there is little doubt that we could discern differences in behavior between the treatment and control groups. Many times, however, we are not in control of the strength of our treatments. For example, researchers involved in program evaluation don‚Äôt get to decide what the treatment should be, they are supposed to evaluate the program as it is.\nBackground noise. As the background noise of your outcome variables increases, the power of your experiment decreases. To the extent that it is possible, try to select outcome variables that have low variability. In practical terms, this means comparing the standard deviation of the outcome variable to the expected treatment effect size ‚Äî there is no magic ratio that you should be shooting for, but the closer the two are, the better off your experiment will be. By and large, researchers are not in control of background noise, and picking lower-noise outcome variables is easier said than done. Furthermore, many outcomes we would like to study are inherently quite variable. From this perspective, background noise is something you just have to deal with as best you can.\nExperimental Design. Traditional power analysis focuses on one (albeit very important) element of experimental design: the number of subjects in each experimental group. Put simply, a larger number of subjects increases power. However, there are other elements of the experimental design that can increase power: how is the randomization conducted? Will other factors be statistically controlled for? How many treatment groups will there be, and can they be combined in some analyses?\n\n\n\n4 Key Formulas for Calculating Power\nStatisticians have derived formulas for calculating the power of many experimental designs. They can be useful as a back of the envelope calculation of how large a sample you‚Äôll need. Be careful, though, because the assumptions behind the formulas can sometimes be obscure, and worse, they can be wrong.\nHere is a common formula used to calculate power2\n\\[\\beta = \\Phi \\left(\\frac{|\\mu_t-\\mu_c|\\sqrt{N}}{2\\sigma}-\\Phi^{-1} \\left(1-\\frac{\\alpha}{2}\\right) \\right)\\]\n\n\\(\\beta\\) is our measure of power. Because it‚Äôs the probability of getting a statistically significant result, Œ≤ will be a number between 0 and 1.\n\\(\\Phi\\) is the CDF of the normal distribution, and \\(\\Phi^{-1}\\) is its inverse. Everything else in this formula, we have to plug in:\n\\(\\mu_t\\) is the average outcome in the treatment group. Suppose it‚Äôs 65.\n\\(\\mu_c\\) is the average outcome in the control group. Suppose it‚Äôs 60.\nTogether, assumptions about Œºt and Œºc define our assumption about the size of the treatment effect: 65-60= 5.\n\\(\\sigma\\) is the standard deviation of outcomes. This is how we make assumptions about how noisy our experiment will be ‚Äî one of the assumptions we‚Äôre making is that sigma is the same for both the treatment and control groups. Suppose \\(\\sigma=20\\)\n\\(\\alpha\\) is our significance level ‚Äì the convention in many disciplines is that Œ± should be equal to 0.05. \\(N\\) is the total number of subjects. This is the only variable that is under the direct control of the researcher. This formula assumes that every subject had a 50/50 chance of being in control. Suppose that \\(N=500\\).\n\nWorking through the formula, we find that under this set of assumptions, \\(Œ≤ = 0.80\\), meaning that we have an 80% chance of recovering a statistically significant result with this design. Click here for a google spreadsheet that includes this formula. You can copy these formulas directly into Excel. If you‚Äôre comfortable in R, here is code that will accomplish the same calculation.\n\npower_calculator <- function(mu_t, mu_c, sigma, alpha=0.05, N){ \n  lowertail <- (abs(mu_t - mu_c)*sqrt(N))/(2*sigma) \n  uppertail <- -1*lowertail \n  beta <- pnorm(lowertail- qnorm(1-alpha/2), lower.tail=TRUE) + 1- pnorm(uppertail- qnorm(1-alpha/2), lower.tail=FALSE) \n  return(beta) \n  } \n\n\n\n5 When to Believe Your Power Analysis\nFrom some perspectives the whole idea of power analysis makes no sense. You want to figure out the size of some treatment effect but first you need to do a power analysis which requires that you already know your treatment effect and a lot more besides.\nSo in most power analyses you are in fact seeing what happens with numbers that are to some extent made up. The good news is that it is easy to find out how much your conclusions depend on your assumptions: simply vary your assumptions and see how the conclusions on power vary.\nThis is most easily seen by thinking about how power varies with the number of subjects. A power analysis that looks at power for different study sizes simply plugs in a range of values in for N and seeing how Œ≤ changes.\nUsing the formula in section 4, you can see how sensitive power is to all of the assumptions: Power will be higher if you assume the treatment effect will be larger, or if you‚Äôre willing to accept a higher alpha level, or if you have more or less confidence in the noisiness of your measures.3\n\n\n\n\n6 How to Use Simulation to Estimate Power\nPower is a measure of how often, given assumptions, we would obtain statistically significant results, if we were to conduct our experiment thousands of times. The power calculation formula takes assumptions and return an analytic solution. However, due to advances in modern computing, we don‚Äôt have to rely on analytic solutions for power analysis. We can tell our computers to literally run the experiment thousands of times and simply count how frequently our experiment comes up significant.\nThe code block below shows how to conduct this simulation in R.\n\npossible.ns <- seq(from=100, to=2000, by=40) # The sample sizes we'll be considering\nstopifnot(all( (possible.ns %% 2)==0 )) ## require even number of experimental pool\npowers <- rep(NA, length(possible.ns)) # Empty object to collect simulation estimates \nalpha <- 0.05 # Standard significance level \nsims <- 500 # Number of simulations to conduct for each N \n#### Outer loop to vary the number of subjects #### \nfor (j in 1:length(possible.ns)){ N <- possible.ns[j] # Pick the jth value for N \n  Y0 <- rnorm(n=N, mean=60, sd=20) # control potential outcome \n  tau <- 5 # Hypothesize treatment effect \n  Y1 <- Y0 + tau # treatment potential outcome                                   \n  significant.experiments <- rep(NA, sims) # Empty object to count significant experiments \n                                  \n  #### Inner loop to conduct experiments \"sims\" times over for each N #### \n        Y0 <- rnorm(n=N, mean=60, sd=20) # control potential outcome \n        tau <- 5 # Hypothesize treatment effect \n        Y1 <- Y0 + tau # treatment potential outcome \n  for (i in 1:sims){ \n        ## Z.sim <- rbinom(n=N, size=1, prob=.5) # Do a random assignment  by coin flip\n        Z.sim <- sample(rep(c(0,1),N/2)) ## Do a random assignment ensuring equal sized groups\n        Y.sim <- Y1*Z.sim + Y0*(1-Z.sim) # Reveal outcomes according to assignment \n        fit.sim <- lm(Y.sim ~ Z.sim) # Do analysis (Simple regression) \n        p.value <- summary(fit.sim)$coefficients[2,4] # Extract p-values \n        significant.experiments[i] <- (p.value <= alpha) # Determine significance according to p <= 0.05\n        }\n  powers[j] <- mean(significant.experiments) # store average success rate (power) for each N \n  } \npowers \n\n [1] 0.250 0.330 0.406 0.404 0.472 0.588 0.734 0.680 0.718 0.788 0.802 0.862\n[13] 0.882 0.938 0.914 0.918 0.932 0.932 0.944 0.954 0.974 0.972 0.976 0.980\n[25] 0.978 0.982 0.982 0.988 0.988 0.994 0.990 0.996 0.996 0.998 0.994 0.996\n[37] 0.998 1.000 1.000 1.000 1.000 0.998 0.998 1.000 1.000 1.000 1.000 1.000\n\n\nThe code for this simulation and others is available here. Simulation is a far more flexible, and far more intuitive way to think about power analysis. Even the smallest tweaks to an experimental design are difficult to capture in a formula (adding a second treatment group, for example), but are relatively straightforward to include in a simulation.\nIn addition to counting up how often your experiments come up statistically significant, you can directly observe the distribution of p-values you‚Äôre likely to get. The graph below shows that under these assumptions, you can get expect to get quite a few p-values in the 0.01 range, but that 80% will be below 0.05.\n\n\n\n7 How to Change your Design to Improve Your Power\nWhen it comes to statistical power, the only thing that that‚Äôs under your control is the design of the experiment. As we‚Äôve seen above, an obvious design choice is the number of subjects to include in the experiment. The more subjects, the higher the power.\nHowever, the number of subjects is not the only design choice that has consequences for power. There are two broad classes of design choices that are especially important in this regard.\n\nChoice of estimator. Are you using difference-in-means? Will you be doing some transformation, such as a logit or a probit? Will you be controlling for covariates? Will you be using some kind of robust standard error estimator? All of these choices will make a difference for the statistical significance of your results, and therefore for the power of your experiment. One easy way to think about this is to imagine what command you‚Äôll be running in R or Stata after the experiment has come back; that‚Äôs your estimator!\nRandomization Protocol. What kind of randomization will you be employing? Simple randomization gives all subjects an equal probability of being in the treatment group, and then performs a (possibly weighted) coin flip for each. Complete randomization is similar, but it ensures that exactly a certain number will be assigned to treatment. Block randomization is even more powerful ‚Äî it ensures that a certain number within a subgroup will be assigned to treatment. A restricted random assignment rejects some random assignments based on some set of criteria ‚Äî lack of balance perhaps. These various types of random assignment can dramatically increase the power of an experiment at no extra cost. Read up on randomization protocols here.\n\nThere are too many choices to cover in this short article, but check out the Simulation for Power Analysis code page for some ways to get started. But to give a flavor of the simulation approach, consider how you would conduct a power analysis if you wanted to include covariates in your analysis.\nIf the covariates you include as control variables are strongly related to the outcome, then you‚Äôve dramatically increased the power of your experiment.Unfortunately, the extra power that comes with including control variables is very hard to capture in a compact formula. Almost none of the power formulas found in textbooks or floating around on the internet can provide guidance on what the inclusion of covariates will do for your power.\nThe answer is simulation.\n\nSuppose we‚Äôre studying the effect of an educational intervention on income\nSuppose we have good data on the relationship between two covariates and income: age and gender. In this economy, men earn more than women, and older people earn more than younger people.\nRun a regression of income on age and gender and record the coefficients, using pre-existing survey data (better yet: use baseline data from future participants in your experiment!) *Generate fake covariate data ‚Äî N total subjects, but broken up by age and gender in a way that reflects your experimental subject pool.\nGenerate fake control data ‚Äî where the outcome is a function of age and gender according to your regression estimates\nHypothesize a treatment effect to generate fake treatment data\nRun the experiment 10,000 times, and record how often, using a regression with controls, your experiment turns up significant.\n\nHere‚Äôs a graph that compares the power of an experiment that does control for background attributes to one that does not. The R-square of the regression relating income to age and gender is pretty high ‚Äî around .66 ‚Äî meaning that the covariates that we have gathered (generated) are highly predictive. For a rough comparison, sigma, the level of background noise that the unadjusted model is dealing with, is around 33. This graph shows that at any N, the covariate-adjusted model has more power ‚Äî so much so that the unadjusted model would need 1500 subjects to achieve what the covariate-adjusted model can do with 500.\n\nThis approach doesn‚Äôt rely on a formula to come up with the probability of getting a statistically significant result: it relies on brute force! And because simulation lets you specify every step of the experimental design, you do a far more nuanced power analysis than simply considering the number of subjects.\n\n\n8 Power Analysis for Multiple Treatments\nMany experiments employ multiple treatments which are compared both to each other and to a control group. This added complication changes what we mean when we say the ‚Äúpower‚Äù of an experiment. In the single treatment group case, power is just the probability of getting a statistically significant result. In the multiple treatment case, it can mean a variety of things: A) the probability of at least one of the treatments turning up significant, B) the probability of all the treatments turning up significant (versus control) or C) the probability that the treatments will be ranked in the hypothesized order, and that those ranks will be statistically significant.\nThis question of multiple treatment arms is related to the problem of multiple comparisons. (See our guide on this topic for more details.) Standard significance testing is based on the premise that you‚Äôre conducting a single test for statistical significance, and the p-values derived from these tests reflect the probability under the null of seeing such a larger (or larger) treatment effect. If, however, you are conducting multiple tests, this probability is no longer correct. Within a suite of tests, the probability that at least one of the tests will turn up significant even when the true effect is zero is higher, essentially because you have more attempts. A commonly cited (if not commonly used) solution is to use the Bonferroni correction: specify the number of comparisons you will be making in advance, then divide your significance level (alpha) by that number.\nIf you are going to be using a Bonferroni correction, then standard power calculators will be more complicated to use: you‚Äôll have to specify your Bonferroni-corrected alpha levels and calculate the power of each separate comparison. To calculate the probability that all the tests are significant, multiply all the separate powers together. To calculate the probability that at least one of the tests is significant, calculate the probability that none are, then subtract from one.\nOr you can use simulation. An example of a power calculation done in R is available on the simulations page.\n\n\n9 How to Think About Power for Clustered Designs\nWhen an experiment has to assign whole groups of people to treatment rather than individually, we say that the experiment is clustered. This is common in educational experiments, where whole classrooms of children are assigned to treatment or control, or in development economics, where whole villages of individuals are assigned to treatment or control. (See our guide on cluster randomization for more details.)\nAs a general rule, clustering decreases your power. If you can avoid clustering your treatments, that is preferable for power. Unless you face concerns related to spillover, logistics, or ethics, take the variation down to the lowest level that you can.\nThe best case scenario for a cluster-level design is when which cluster a subject is in provides very little information about their outcomes. Suppose subjects were randomly assigned to clusters ‚Äî the cluster wouldn‚Äôt help to predict outcomes at all. If the cluster is not predictive of the outcome, then we haven‚Äôt lost too much power to clustering.\nWhere clustering really causes trouble is when there is a strong relationship between the cluster and the outcome. To take the villages example, suppose that some villages are, as a whole, much richer than others. Then the clusters might be quite predictive of educational attainment. Clustering can reduce your effective sample size from the total number of individuals to the total number of clusters.\nThere are formulas that can help you understand the consequences of clustering ‚Äî see Gelman/Hill page 447-449 for an extended discussion. While these formulas can be useful, they can also be quite cumbersome to work with. The core insight however is a simple one: you generally get more power from increasing the number of clusters than you do from increasing the number of subjects within clusters. Better to have 100 clusters with 10 subjects in each than 10 clusters with 100 subjects in each.\nAgain, a more flexible approach to power analysis when dealing with clusters is simulation. See the (Declare Design library for block and cluster randomized experiments)[https://declaredesign.org/r/designlibrary/reference/block_cluster_two_arm_designer.html] for some starter code. The (DeclareDesign)[https://declaredesign.org] software aims to make simulations for power analysis (among many other tasks) easier. See also Gelman/Hill page 450-453 for another simulation approach.\n\n\n10 Good Power Analysis Makes Preregistration Easy\nWhen you deal with power you focus on what you cannot control (noise) and what you can control (design). If you use the simulation approach to power analysis then you will be forced to imagine how your data will look and how you will handle it when it comes in. You will get a chance to specify all of your hunches and best guesses in advance, so that you can launch your experiments with clear expectations of what they can and cannot show. That‚Äôs some work but the good news is that if you really do it you are most of the way to putting together a comprehensive and registerable pre-analysis plan.\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Alex Coppock, 20 Nov 2013. The guide is a live document and subject to updating by EGAP members at any time. Coppock is not responsible for subsequent edits to this guide‚Ü©Ô∏é\nReproduced from Gerber and Green 2012, page 93‚Ü©Ô∏é\nFor an additional online power visualization tool, see Kristoffer Magnusson‚Äôs R Psychologist blog.‚Ü©Ô∏é"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  }
]