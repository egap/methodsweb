---
title: "10 Types of Treatment Effect You Should Know About"
author: 
  - name: "Paul Testa"
    url: https://paultesta.org/
image: effect-types.png
bibliography: effect-types.bib
---

I am leaving off with section 8 and 10 still needing writing or extensive edits. The other sections have a good start and have had (I believe) all estimation removed from them.

This guide describes estimands, theoretical parameters of interest, of researchers might want to identify. This guide should be used to help researchers choose an estimand of interest to address their specific research question.

1. Effects as contrasts between outcomes
==
Effects are, at their core, a comparison of potential outcomes. Researchers in every field are interested in the effect of X on Y, how does some intervention change the outcome for person i? For people on average? Effects need not be a difference between two outcomes, instead they could be, for example, ratios of two values.

2. Individual treatment effects
==
A first quantity of interest is the individual treatment effect. For this estimand a researcher would be interested in the effect of a treatment on each individual. Individual, in this context, is referencing the level at which analysis is done. This could be a person, a household, a city, or any other level at which analysis is conducted. In order to find this effect, one would want to observe the potential outcome under treatment $Y_i(1)$ and the potential outcome under control $Y_i(0)$. Taking the difference between these quantities would give the individual treatment effect for subject i. $$τ_{i}=Y_{i}(1)−Y_{i}(0)$$ Since we can only observe either $Y_{i}(1)$ or $Y_{i}(0)$ the individual treatment effect is unknowable. 

3. Average treatment effects
==

A quantity that we can learn about, however, is the average treatment effect (ATE) across all observations in our experiment:

$$ATE≡\frac{1}{N}∑^{N}_{i=1}τ_{i}=\frac{∑^{N}_{1}Y_{i}(1)}{N}−\frac{∑^{N}_{1}Y_{i}(0)}{N}$$
Importantly, the average treatment effect gives the mean of the treatment effects for *all* units.

See [10 Strategies for Figuring out if X Causes Y](https://methods.egap.org/guides/causal-inference/x-cause-y_en.html) for information on how we can estimate the ATE (and other estimands).

4. Population and sample average treatment effects
==
When defining the average treatment effect, it isn't immediately clear who is included in the *all* part of all subjects. Often we want to generalize from our sample to make statements about some broader population of interest.[^1] Let $S_i$ be an indicator for whether an subject is in our sample. The sample average treatment effect (SATE) is defined simply as $SATE = E(Y_i(1)−Y_i(0)|S_i=1)$ and the population $PATE = E(Y_i(1)−Y_i(0))$. If we are interested in the effect of the treatment within our sample, we would be interested in the sample average treatment effect. For generalizing our results, we would instead be interested in the population average treatment effect. With a large random sample from a well-defined population with full compliance with treatment, our SATE and PATE are equal in expectation.[^2]

[^1]: See @imai_king_stuart_2008 for a more detailed review of the issues discussed in this section.

[^2]: See @imbens_wooldridge_2007.

5. Conditional average treatment effects
==
The problem with looking at average treatment effects only is that it takes attention away from the fact that treatment effects might be very different for different sorts of people. While the “fundamental problem of causal inference” suggests that measuring causal effects for individual units is impossible, making inferences on groups of units is not.

Random assignment ensures that treatment is independent of potential outcomes and any (observed and unobserved) covariates. Sometimes, however, we have additional information about the experimental units as they existed before the experiment was fielded, say $X_{i}$, and this information can can help us understand how treatment effects vary across subgroups. For example, we may suspect that men and women respond differently to treatment, and we can test for this hetorogeneity by estimating conditional ATE for each subgroup separately. We can define the conditional average treatment effect as: $$CATE=E(Y_{i}(1)−Y_{i}(0)∣D_{i},X_{i})$$

For some research questions we often need to know the effects of the treatment not just on the whole population but specifically for those to whom the treatment is administered. We define the average effects of treatment among the treated (ATT) and the control (ATC) as simple counter-factual comparisons:

$$ATT=E(Y_i(1)-Y_i(0)|D_i=1)=E(Y_i(1)|D_i=1)-E(Y_i(0)|D_i=1)$$
$$ATC=E(Y_i(1)-Y_i(0)|D_i=0)=E(Y_i(1)|D_i=0)-E(Y_i(0)|D_i=0)$$

Informally, the ATT is the effect for those that we treated; ATC is what the effect *would* be for those we did not treat.


6. Intent-to-treat effects
==
Outside of a controlled laboratory setting, the subjects we assign to treatment often are not the same as the subjects who actually receive the treatment. We call this issue non-compliance[^3]. The intent-to-treat effect (ITT) is the effect of giving someone the opportunity to receive treatment. In the absence of noncompliance, the ITT is the same as the ATE. We can define ITT as:

$$ITT = E[Y_i(z=1)] - E[Y_i(z=0)]$$

[^3]: See [10 Things You Need to Know About the Local Average Treatment Effect](https://methods.egap.org/guides/research-questions/late_en.html) for more on non-compliance.

Where z is an indicator for whether a subject has been *assigned* to treatment rather than indicating whether they *received* treatment. 

With two-sided non-compliance ITT can be written as:


\begin{align}
ITT =& E[Y_i(d(1)) - Y_i(d(0))|d_i(1)=d_i(0)=0]\pi_{NT} + \nonumber \\
&E[Y_i(d(1)) - Y_i(d(0))|d_i(1)=d_i(0)=1]\pi_{AT} + \nonumber \\
&E[Y_i(d(1)) - Y_i(d(0))|d_i(1)-d_i(0)=1]\pi_{C} + \nonumber \\
&E[Y_i(d(1)) - Y_i(d(0))|d_i(1)-d_i(0)=-1]\pi_{D} \nonumber
\end{align}


Where $d_i(z)$ returns 1 if the subject receives treatment for the given assignment $z$ and 0 if they do not receive treatment for that assignment.

7. Complier average causal effects
==
What if you are interested in figuring out the effects of a treatment on those people who actually took up the treatment and not just those people that were administered the treatment? In this case, you would be interested in the complier average causal effect (CACE).


$$CACE= E[Y_i(1)-Y_i(0)|d_i(1)-d_i(0) = 1]$$

Which is the average effect conditional on the subject being a complier, a type that takes the treatment when assigned to treatment and does not take the treatment when assigned to control.


8. Direct and indirect effects
==

9. Average marginal component effect
==

For a conjoint experiment (see [10 Things to Know About Survey Experiments](https://methods.egap.org/guides/data-strategies/survey-experiments_en.html)), one might be interested in the marginal effect of changing one attribute. The average marginal component effect (AMCE) gives  the average causal effect of changing an attribute from one value to another, while holding equal the joint distribution of the other attributes in the design, averaged over this distribution.

The probabilities associated with each factor are also informed by the choice of estimand. For the uniform AMCE (uAMCE),  each factor is independently and uniformly marginalized. In contrast, the population AMCE (pAMCE) is marginalized over the target population distribution of profiles. The AMCE is always defined with respect to the distribution used for the random assignment; so if you change the randomization distribution, the interpretation changes.

10. Eliminated effect (was Mediation Effects section)
==
Sometimes we want to describe not just the magnitude and significance of an observed causal effect, but also the [mechanism](https://methods.egap.org/guides/research-questions/mechanisms_en.html) (or mechanisms) that produced it. Did our intervention raise turnout in the treatment group, in part, by increasing these subjects’ sense of political efficacy? If so, how much of that total effect can be attributed to the mediated effects of our treatment on efficacy and efficacy on turnout?

@baron_kenny_1986 offer a general framework for thinking about mediation by decomposing the total effect of treatment into its indirect effect on a mediator that then effects the outcome, called an average causal mediation effect (ACME), and the remaining average direct effect (ADE) of the treatment. Unbiased estimation of these effects, however, requires a set of strong assumptions about the relationship between treatment, mediators, outcomes, and potential confounders, collectively called sequential ignorability (@imai_keele_yamamoto_2010, @bullock_green_ha_2010).[^19]


[^19]:  Formally, @imai_keele_yamamoto_2010 define the necessary conditions of sequential ignorability as: ${Y_i(d',m),M_i(d)}⊥D_i|X_i=x, Y_i(d',m)⊥M_i(d)|D_i=d,X_i=x$. That is, first, given pre-treatment covariates, the potential outcomes of Y and M are independent of treatment D, and, second, that conditional on pre-treatment covariates and treatment status, potential outcomes are also independent of the mediator.

Most causal effects likely operate through multiple channels, and so an assumption of sequential ignorability for your experiment can be hard to justify. For example, the top row in the figure below illustrates situations in which sequential ignorability holds, while the bottom row depicts two (of many possible) cases in which sequential ignorability is violated, and mediation analysis is biased. In essence, specifying the effects of a particular mediator requires strong assumptions about the role of all the other mediators in the causal chain. While some experimental designs can, in theory, provide additional leverage (such as running a second, parallel experiment in which the mediator is also manipulated), in practice these designs are hard to implement and still sensitive to unobserved bias. In some cases, the insights we hope to gain from mediation analysis may be more easily acquired from subgroup analysis and experiments designed to test for moderation.

Imai and colleagues propose an approach to mediation analysis that allows researchers to test the sensitivity of their estimates to violations of sequential ignorability.[^20] In the code we demonstrate some of the features of their approach, implemented in the mediation package in R [@tingley_et_al_2014]. We model the relationships with OLS, but the package is capable of handling other outcome processes, such as generalized linear models or general additive models, that may be more appropriate for your data. Most importantly, the package allows us to produce bounds that reflect the sensitivity of our point estimates to some violations of sequential ignorability. In our simulated data, just over 20 percent of the total effect is mediated by our proposed mediator, M and the bias from an unobserved pre-treatment confounder would have to be quite large (ρ=.7) before we would reject the finding of a positive ACME. These bounds are only valid, however, if we believe there are no unobserved post-treatment confounders (as in panel 4). Sensitivity analysis is still possible, but more complicated in such settings [@imai_yamamoto_2013].

[^20]:  See for example @imai_keele_yamamoto_2010, @imai_et_al_2011, @imai_tingley_yamamoto_2013, and @imai_yamamoto_2013. Also see the discussion of @imai_tingley_yamamoto_2013 for different perspectives on the desirability of addressing mediation-type claims with sensitivity or bounds-style analyses.

![](https://raw.githubusercontent.com/egap/methods-guides/master/effect-types/effect-types_fig2.png)


# References
