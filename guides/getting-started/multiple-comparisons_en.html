<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alexander Coppock">

<title>Methods - 10 Things You Need to Know About Multiple Comparisons</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../img/egap-logo.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Methods</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../guides.html">
 <span class="menu-text">Guides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../coursebook/index.html">
 <span class="menu-text">Coursebook</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#almost-every-social-science-experiment-faces-a-multiple-comparisons-problem" id="toc-almost-every-social-science-experiment-faces-a-multiple-comparisons-problem" class="nav-link" data-scroll-target="#almost-every-social-science-experiment-faces-a-multiple-comparisons-problem">1: Almost every social science experiment faces a multiple comparisons problem</a></li>
  <li><a href="#why-multiple-comparisons-are-a-problem" id="toc-why-multiple-comparisons-are-a-problem" class="nav-link" data-scroll-target="#why-multiple-comparisons-are-a-problem">2: Why multiple comparisons are a problem</a></li>
  <li><a href="#dont-mix-up-the-fwer-and-fdr" id="toc-dont-mix-up-the-fwer-and-fdr" class="nav-link" data-scroll-target="#dont-mix-up-the-fwer-and-fdr">3: Don’t mix up the FWER and FDR!</a></li>
  <li><a href="#control-the-fwer-with-bonferroni-style-corrections-including-the-holm-correction" id="toc-control-the-fwer-with-bonferroni-style-corrections-including-the-holm-correction" class="nav-link" data-scroll-target="#control-the-fwer-with-bonferroni-style-corrections-including-the-holm-correction">4: Control the FWER with Bonferroni-style corrections (including the Holm correction)</a></li>
  <li><a href="#control-the-fdr-with-benjamini-hochberg" id="toc-control-the-fdr-with-benjamini-hochberg" class="nav-link" data-scroll-target="#control-the-fdr-with-benjamini-hochberg">5: Control the FDR with Benjamini-Hochberg</a></li>
  <li><a href="#its-easy-to-implement-these-procedures" id="toc-its-easy-to-implement-these-procedures" class="nav-link" data-scroll-target="#its-easy-to-implement-these-procedures">6: It’s easy to implement these procedures</a></li>
  <li><a href="#a-better-way-to-control-the-fwer-is-simulation" id="toc-a-better-way-to-control-the-fwer-is-simulation" class="nav-link" data-scroll-target="#a-better-way-to-control-the-fwer-is-simulation">7: A better way to control the FWER is simulation</a></li>
  <li><a href="#alternative-ways-to-control-fdr-and-variants-of-fdr" id="toc-alternative-ways-to-control-fdr-and-variants-of-fdr" class="nav-link" data-scroll-target="#alternative-ways-to-control-fdr-and-variants-of-fdr">8: Alternative ways to control FDR and variants of FDR</a></li>
  <li><a href="#creating-an-index-is-a-way-to-get-a-single-comparison-out-of-many" id="toc-creating-an-index-is-a-way-to-get-a-single-comparison-out-of-many" class="nav-link" data-scroll-target="#creating-an-index-is-a-way-to-get-a-single-comparison-out-of-many">9: Creating an index is a way to get a single comparison out of many</a>
  <ul class="collapse">
  <li><a href="#mean-effects-index" id="toc-mean-effects-index" class="nav-link" data-scroll-target="#mean-effects-index">Mean Effects Index</a></li>
  <li><a href="#inverse-covariance-weighted-index" id="toc-inverse-covariance-weighted-index" class="nav-link" data-scroll-target="#inverse-covariance-weighted-index">Inverse Covariance Weighted Index</a></li>
  </ul></li>
  <li><a href="#use-design-based-approaches" id="toc-use-design-based-approaches" class="nav-link" data-scroll-target="#use-design-based-approaches">10: Use Design Based approaches</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">10 Things You Need to Know About Multiple Comparisons</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Alexander Coppock </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>The “Multiple Comparisons Problem” is the problem that standard statistical procedures can be misleading when researchers conduct a large group of hypothesis tests. When a researcher does more than one test of a hypothesis (or set of closely related hypotheses), the chances are that some finding will appear “significant” even when there’s nothing going on.</p>
<p><a href="https://egap.org/resource/10-things-to-know-about-hypothesis-testing/">Classical hypothesis tests</a> assess statistical significance by calculating the probability under a null hypothesis of obtaining estimates as large or larger as the observed estimate. When multiple tests are conducted, however, classical p-values can mislead — they no longer reflect the true probability under the null.</p>
<p>This guide <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> will help you guard against drawing false conclusions from your experiments. We focus on the big ideas and provide examples and tools that you can use in R.</p>
</section>
<section id="almost-every-social-science-experiment-faces-a-multiple-comparisons-problem" class="level1">
<h1>1: Almost every social science experiment faces a multiple comparisons problem</h1>
<p>Typically, researchers are not interested in just one treatment versus control comparison per experiment. There are three main ways that comparisons proliferate:</p>
<ol type="1">
<li><strong>Multiple treatment arms.</strong> When an experiment has <span class="math inline">\(n\)</span> treatment arms, there are <span class="math inline">\(n(n-1)/2\)</span> possible comparisons between the arms.</li>
<li><strong>Heterogeneous treatment effects.</strong> Often, we are interested in whether the treatment has different impacts on different subgroups. For example, a treatment might be more effective for women than for men.</li>
<li><strong>Multiple estimators.</strong> Often, experimenters will apply multiple estimators to the same dataset: for example, difference-in-means and covariate adjustment. There is of course nothing wrong with employing multiple treatment arms, exploring treatment effect heterogeneity, or using multiple estimators of the treatment effect. However, these design and analysis choices sometimes require that researchers correct their statistical tests to account for multiple comparisons.</li>
<li><strong>Multiple outcomes.</strong> Researchers often assess the effects of an intervention on multiple distinct outcomes or multiple operationalizations of the outcome variable.</li>
</ol>
<p>These concerns are especially problematic when making a “family claim,” that is, when you are summarizing a series of results. For example, a family claim might be that treatments A, B, C, and D had no effect, but treatment E did. Or, similarly, the treatment had no effect among group 1, group 2, or group 3, but had a strong effect among group 4.</p>
<p>The multiple comparisons problem is related to, but different from, the problem of “fishing.” Fishing occurs when an unscrupulous analyst conducts many tests but only reports the “interesting” ones. In essence, fishing withholds the necessary information we would need in order to correct for multiple comparisons.</p>
</section>
<section id="why-multiple-comparisons-are-a-problem" class="level1">
<h1>2: Why multiple comparisons are a problem</h1>
<p>Let’s set up 1 test: we have 1 coin and we will flip it 10 times. We don’t know if the coin is fair but decide that if we flip over 9 heads and 1 tails, we will say that the coin is unfair. Let’s suppose that this is a fair coin; a coin that has a 50% chance of showing a head in a single flip. We are therefore not likely to flip over 9 heads and 1 tails and will most likely find that the coin is fair.</p>
<p>Now, let’s set up 5 tests: we have 5 coins and we will flip each of them 10 times. Again, we decide that the coin is unfair if we flip 9 heads and 1 tails; again, let’s suppose that all 5 coins are fair. The chance that we see 9 heads and 1 tails for a single coin is still very low. However, after doing 5 tests, it is much more likely that at least 1 of the coins will show 9 heads and 1 tails purely by chance. This result may then lead us to think that some or all of the coins are unfair, even though in reality all the coins are fair.</p>
<p>We can see from the coin flipping example that the more tests we run, the more likely we are to see an effect or relationship and the more likely we are to mistakenly claim to have detected an effect when in reality there is no effect and what we observe occurred by chance; this is the multiple comparisons problem.</p>
<p>In this guide, we will describe three main approaches for addressing the multiple comparisons problem:</p>
<ol type="1">
<li>p-value adjustments. Statisticians have derived a number of corrections that can guard against multiple comparisons mistakes. As described in the next section, these corrections control either the <em>Family-Wise Error Rate</em> (FWER) or the <em>False Discovery Rate</em> (FDR). Most of these adjustments apply a simple formula to a series of “raw” p-values; we will also describe a simulation method that can take account of features of a specific research setting.</li>
<li>Pre-analysis plans. These plans are a powerful design-based tool that enables an analyst to pro-actively manage the multiple comparisons problem.</li>
<li>Replication. If we are concerned that a finding is simply an artifact of sampling variability that we happened to discover because of a naive repeated application of classical hypothesis testing, then the best way to resolve the question is to conduct the experiment again.</li>
</ol>
</section>
<section id="dont-mix-up-the-fwer-and-fdr" class="level1">
<h1>3: Don’t mix up the FWER and FDR!</h1>
<p>In classical hypothesis testing, the “<span class="math inline">\(\alpha\)</span> level” describes how willing the researcher is to make a certain kind of mistake: a false positive or a “Type I error” where a researcher falsely concludes that an observed difference is “real,” when in fact there is no difference. From the coin flipping example, concluding that we have an unfair coin because we flipped 9 heads and 1 tails when in reality we have fair coins is an example of a Type I error or false positive error. After setting the <span class="math inline">\(\alpha\)</span> level, the researcher conducts a hypothesis test and if the p-value <span class="math inline">\(\leq \alpha\)</span>, we call the result “statistically significant”. In many social science applications, the alpha level, or Type I error rate, is set to 0.05. This means that the researcher is willing to commit a Type I error 5% of the time.</p>
<p>In the world of multiple testing, the Type I error rate is associated with one of two things: the Family-Wise Error Rate (FWER) or the False Discovery Rate (FDR). To explain their differences, let’s first consider Table 1 which shows different types of errors. After conducting our hypothesis tests, we observe <span class="math inline">\(m\)</span> (the total number of hypothesis tests), <span class="math inline">\(R\)</span> (the total number of hypothesis tests that are statistically significant), <span class="math inline">\(m-R\)</span>, (the total number of hypothesis tests that are not statistically significant). However, we do not know how many tests from <span class="math inline">\(R\)</span> are false positives (FP, Type I error) or true positives (TP).</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 45%">
<col style="width: 40%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th>&nbsp;</th>
<th style="text-align: center;">Fail to reject null hypothesis <br>(p &gt; 0.05)</th>
<th style="text-align: center;">Reject null hypothesis <br>(p <span class="math inline">\(\leq\)</span> 0.05)</th>
<th style="text-align: center;">Total Hypotheses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Null hypothesis is true</strong></td>
<td style="text-align: center;">TN <br> (True Negative)</td>
<td style="text-align: center;">FP <br> (Type I error, False Positive)</td>
<td style="text-align: center;"><span class="math inline">\(m_0\)</span></td>
</tr>
<tr class="even">
<td><strong>Null hypothesis is false</strong></td>
<td style="text-align: center;">FN <br> (Type II error, False Negative)</td>
<td style="text-align: center;">TP <br> (True Positive)</td>
<td style="text-align: center;"><span class="math inline">\(m - m_0\)</span></td>
</tr>
<tr class="odd">
<td><strong>Total Hypotheses</strong></td>
<td style="text-align: center;"><span class="math inline">\(m - R\)</span></td>
<td style="text-align: center;"><span class="math inline">\(R\)</span></td>
<td style="text-align: center;"><span class="math inline">\(m\)</span></td>
</tr>
</tbody>
</table>
<p>The FWER is the probability of incorrectly rejecting even one null hypothesis, or <span class="math inline">\(P(FP \geq 1)\)</span> across all of our tests. Suppose we have three null hypotheses, all of which are true. When the null hypothesis is true, but we nevertheless reject it in favor of some alternative, we commit a Type I error. If we set <span class="math inline">\(\alpha\)</span> (the Type I error rate) to be 0.05, we have a [<span class="math inline">\(1−(1−0.05)^3=0.142\)</span>] chance of rejecting at least one of them. In order to control the FWER (i.e., reduce it from 14.2% back down to 5%), we need to employ a correction. We’ll explore three ways to control the FWER (Bonferroni, Holm, and simulation) in the sections below.</p>
<p>The FDR is subtly different. It is the expected proportion of false discoveries among all discoveries, or <span class="math inline">\(E[FP/R]\)</span><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. In the case where no discoveries are found (<span class="math inline">\(R=0\)</span>), then the “share” of false discoveries is taken to be zero. There are some connections to the FWER. For example, if in fact all null hypotheses are true then the FWER and FDR are the same. To see this, note that in this case if no significant rejections of the null are found, then the share that are false discoveries is zero. But if some are found (no matter how many), then the share that are false is 100% (since all null hypotheses are true). So the false discovery rate in this case is just the probability that some true null hypothesis is falsely rejected—the FWER. Beyond this case however the FDR is less stringent than the FWER. We’ll also explore some ways to control FDR in the sections below.</p>
</section>
<section id="control-the-fwer-with-bonferroni-style-corrections-including-the-holm-correction" class="level1">
<h1>4: Control the FWER with Bonferroni-style corrections (including the Holm correction)</h1>
<p>The Bonferroni correction is a simple and commonly-used approach for addressing the multiple comparisons problem although it usually understates how much information is available to detect an effect. If you conduct <span class="math inline">\(m\)</span> tests but want to make sure that you make no more than <span class="math inline">\(\alpha\)</span> errors out of the total <span class="math inline">\(m\)</span> tests, the target significance level should be <span class="math inline">\(\alpha/m\)</span>, or, equivalently, you multiply your p-values by <span class="math inline">\(m\)</span>, and apply the standard <span class="math inline">\(\alpha\)</span> level. (The trouble with multiplying the p-values is sometimes you end up with values over one, rendering the interpretation of the p-values incoherent so software just replaces those p-values with the number 1.)</p>
<p>For example, suppose you conduct an experiment that has 3 dependent variables. You conduct three difference-in-means tests that yield the following classical p-values: 0.004, 0.020, and 0.122. If your <span class="math inline">\(\alpha\)</span> level is the standard 0.05 threshold, then you would usually declare the first two tests statistically significant and the last test insignificant. The Bonferroni correction, however, adjusts the target p-value to <span class="math inline">\(0.05/3 = 0.016\)</span>. We then declare only the first test to be statistically significant.</p>
<p>The Bonferroni correction works under the most extreme circumstances, that is, when all <span class="math inline">\(m\)</span> tests are independent from one another. To see how this works, imagine we are testing three true null hypotheses using a classical <span class="math inline">\(\alpha\)</span> level of 0.05. Each test, therefore has a 5% chance of yielding the wrong answer that the null hypothesis is false.</p>
<p>But our chances of making at least one mistake are much greater than 5% because we have three chances to get it wrong. As above, this probability is in fact [<span class="math inline">\(1 - (1 - 0.05)^3 = 0.142\)</span>]. If we use the Bonferroni correction, however, our chances of getting it wrong fall back to our target <span class="math inline">\(\alpha\)</span> value: [<span class="math inline">\(1 - (1 - 0.05/3)^3 \approx 0.05\)</span>] .</p>
<p>This correction works in the worst-case scenario that all tests are independent. But in most cases, tests are not independent. That is, if your treatment moves outcome A, it probably moves outcome B too, at least a little. So what tends to happen is, researchers report that their results “withstand” Bonferroni when they are extremely strong, but decry Bonferroni as too extreme when the results are weaker.</p>
<p>Instead of using the Bonferroni correction, you can use the <strong>Holm correction</strong>. It is strictly more powerful than Bonferroni, and is valid under the same assumptions. It also controls the FWER. Suppose you have <span class="math inline">\(m\)</span> p-values. Order them from smallest to largest. Find the smallest p-value that satisfies this condition: <span class="math inline">\(p_{k}&gt;\frac{\alpha}{m+1−k}\)</span>, where <span class="math inline">\(k\)</span> is the p-value’s index. This and all larger p-values are insignificant; all smaller p-values are significant.</p>
<p>Taking our three p-values from above: 0.004, 0.020, and 0.122: <span class="math display">\[0.004&lt;\frac{0.05}{3+1−1}=0.017\]</span> <span class="math display">\[0.020&lt;\frac{0.05}{3+1−2}=0.025\]</span> <span class="math display">\[0.122&gt;\frac{0.05}{3+1−3}=0.050\]</span></p>
<p>Under the Holm correction, the first two tests are significant, but the last test is not.</p>
</section>
<section id="control-the-fdr-with-benjamini-hochberg" class="level1">
<h1>5: Control the FDR with Benjamini-Hochberg</h1>
<p>The Benjamini–Hochberg (B-H) procedure controls the FDR. Like the Holm correction, you also begin by ordering <span class="math inline">\(m\)</span> p-values. Then you find the largest p-value that satisfies: <span class="math inline">\(p_{k}≤\frac{k}{m}\alpha\)</span>. This test, and all tests with smaller p-values are declared significant.</p>
<p><span class="math display">\[0.004&lt;\frac{1}{3}0.05=0.017\]</span> <span class="math display">\[0.020&lt;\frac{2}{3}0.05=0.033\]</span> <span class="math display">\[0.122&gt;\frac{3}{3}0.05=0.050\]</span></p>
<p>Using the Benjamini–Hochberg procedure, the first two tests are significant, but the third is not. Notice that the FDR does not control the same error rate as the FWER. It is common for those controlling the FDR error rate to take “significant tests” to indicate places to direct more attention for confirmatory tests (which, would then be analyzed using the stricter FWER control). The idea that one uses the FDR to explore and FWER to confirm is also common in genetics and other applications of large scale hypothesis testing.</p>
</section>
<section id="its-easy-to-implement-these-procedures" class="level1">
<h1>6: It’s easy to implement these procedures</h1>
<p>In R, the <code>p.adjust()</code> function contains many of the corrections devised by statisticians to address the multiple comparisons problem. The <code>p.adjust()</code> function is in base R, so no additional packages are required. The <code>p.adjust()</code> function gives adjusted p-values after implementing a correction.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">343</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate 50 test statistics</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Half are drawn from a normal with mean 0</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The other half are drawn from a normal with mean 3</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="at">mean =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">25</span>), <span class="fu">rep</span>(<span class="dv">3</span>, <span class="dv">25</span>)))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain 50 p-values</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">pnorm</span>(<span class="fu">sort</span>(<span class="sc">-</span><span class="fu">abs</span>(x))), <span class="dv">3</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose alpha level</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Without any corrections</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>sig <span class="ot">&lt;-</span> p <span class="sc">&lt;</span> alpha</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct three corrections</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># and compare to target alpha</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>bonferroni_sig <span class="ot">&lt;-</span> <span class="fu">p.adjust</span>(p, <span class="st">"bonferroni"</span>) <span class="sc">&lt;</span> alpha</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>holm_sig <span class="ot">&lt;-</span> <span class="fu">p.adjust</span>(p, <span class="st">"holm"</span>) <span class="sc">&lt;</span> alpha</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>BH_sig <span class="ot">&lt;-</span> <span class="fu">p.adjust</span>(p, <span class="st">"BH"</span>) <span class="sc">&lt;</span>alpha</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The results of this simulation are presented in the table and figure below.</p>
<table class="table">
<colgroup>
<col style="width: 35%">
<col style="width: 17%">
<col style="width: 23%">
<col style="width: 7%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Correction Type</th>
<th>No Correction</th>
<th>Benjamini-Hochberg</th>
<th>Holm</th>
<th>Bonferroni</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Statistically Significant</td>
<td>25</td>
<td>22</td>
<td>11</td>
<td>8</td>
</tr>
<tr class="even">
<td>Not Statistically Significant</td>
<td>25</td>
<td>28</td>
<td>39</td>
<td>42</td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="cell-output-display">
<p><img src="multiple-comparisons_en_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Of the 25 null hypotheses that would be rejected if no correction were made, the Bonferroni correction only rejects 8, the Holm procedure rejects 11, and the Benjamini–Hochberg procedure rejects 22 (or tags 22 hypotheses as promising for future exploration). Of these three corrections, Bonferroni is the most stringent while Benjamini–Hochberg is the most lenient.</p>
<p>Instead of R, you can also use this calculator to adjust your p-values.</p>
<p>This calculator works best in Firefox. To use full-screen, go <a href="https://egap.shinyapps.io/multiple-comparisons-app/">here</a>.</p>
<iframe height="500" src="https://egap.shinyapps.io/multiple-comparisons-app/" width="850">
</iframe>
</section>
<section id="a-better-way-to-control-the-fwer-is-simulation" class="level1">
<h1>7: A better way to control the FWER is simulation</h1>
<p>The trouble with the corrections above is that they struggle to address the extent to which the multiple comparisons are correlated with one another. A straightforward method of addressing this problem is simulation under the sharp null hypothesis of no effect for any unit on any dependent variable. Note that this is a <strong>family-wise</strong> sharp null.</p>
<p>If the treatment has no effect at all on any outcome, then we observe all potential outcomes for all subjects. We can re-randomize the experiment 1000 or more times and conduct all <span class="math inline">\(m\)</span> hypothesis tests each time. We know for sure that all <span class="math inline">\(m\)</span> null hypotheses are true, because the treatment has no effect by construction.</p>
<p>The next step is picking the right threshold value below which results are deemed statistically significant. If <span class="math inline">\(\alpha\)</span> is 0.05, we need to find the target p-value that, across all simulations under the sharp null, yields 5% significant hypothesis tests.</p>
<p>Once we have the right threshold value, it’s as easy as comparing the uncorrected p-values to the threshold value — those below the threshold are deemed significant.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Control the FWER through simulation</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list=</span><span class="fu">ls</span>())</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomizr)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper functions</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>do_t_test <span class="ot">&lt;-</span> <span class="cf">function</span>(Y, Z){</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(Y[Z<span class="sc">==</span><span class="dv">1</span>], Y[Z<span class="sc">==</span><span class="dv">0</span>])<span class="sc">$</span>p.value</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>permute_treat <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  treatment_sim <span class="ot">&lt;-</span> <span class="fu">complete_ra</span>(n, <span class="at">m=</span>n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  ps_sim <span class="ot">&lt;-</span> <span class="fu">apply</span>(outcomes, <span class="dv">2</span>, do_t_test, <span class="at">Z =</span> treatment_sim)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ps_sim)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>threshold_finder<span class="ot">&lt;-</span> <span class="cf">function</span>(threshold){</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(<span class="fu">apply</span>(many_ps, <span class="dv">2</span>, x <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">sum</span>(x <span class="sc">&lt;=</span> threshold) <span class="sc">&gt;</span> <span class="dv">0</span> ))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">343</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate correlated outcomes</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Outcomes are unrelated to treatment</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># All null hypotheses are true</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">100</span>; r <span class="ot">&lt;-</span> .<span class="dv">7</span>; s <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(s<span class="sc">*</span>r, k,k)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(sigma) <span class="ot">&lt;-</span> s</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>outcomes <span class="ot">&lt;-</span> <span class="fu">rmvnorm</span>(<span class="at">n=</span>n, <span class="at">mean=</span><span class="fu">rep</span>(<span class="dv">0</span>, k), <span class="at">sigma=</span>sigma)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Complete Random Assignment</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>treatment <span class="ot">&lt;-</span> <span class="fu">complete_ra</span>(n, <span class="at">m=</span>n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Conduct k hypothesis tests</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>p_obs <span class="ot">&lt;-</span> <span class="fu">apply</span>(outcomes, <span class="dv">2</span>, do_t_test, <span class="at">Z =</span> treatment)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate under the sharp null</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>many_ps <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">1000</span>, <span class="fu">permute_treat</span>(), <span class="at">simplify =</span> <span class="cn">TRUE</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain the Type I error rate for a series of thresholds</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>thresholds <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">0.05</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>type_I_rate <span class="ot">&lt;-</span> <span class="fu">sapply</span>(thresholds, threshold_finder)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the largest threshold that yields an alpha type I error rate</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>target_p_value <span class="ot">&lt;-</span> thresholds[<span class="fu">max</span>(<span class="fu">which</span>(type_I_rate <span class="sc">&lt;=</span><span class="fl">0.05</span>))]</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply target p_value to observed p_values</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>sig_simulated <span class="ot">&lt;-</span> p_obs <span class="sc">&lt;=</span> target_p_value</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to raw p-values</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>sig <span class="ot">&lt;-</span> p_obs <span class="sc">&lt;=</span> <span class="fl">0.05</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The target p-value obtained by the simulation is 0.002 — hypothesis tests with raw p-values below 0.002 are deemed significant. Compare this with the Bonferroni method, which would require a p-value below 0.05/100 = 0.0005, an order of magnitude smaller. The closer the correlation of the tests (the parameter “r” in the code above) is to zero, the closer the two methods will be.</p>
<p>The flexibility of the simulation method is both an advantage and a disadvantage. The advantage is that it can accommodate any set of testing procedures, returning a study-specific correction that will generally be more powerful than other methods to control the FWER. The disadvantage is that it requires the researcher to code up a simulation — there are no prewritten functions that will apply across research contexts.</p>
<p>Here are some guidelines and tips for writing your own simulation.</p>
<ol type="1">
<li>Follow the original random assignment procedure as exactly as possible. For example, if you block-randomized your experiment, make sure your simulations permute the treatment assignment according to the same blocks.</li>
<li>Each simulation should return a set of p-values. (this was accomplished in the permute_treat() function above.)</li>
<li>Be sure to count up the number of simulations in which at least one test was deemed significant, not the average number of tests across all simulations deemed significant.</li>
</ol>
</section>
<section id="alternative-ways-to-control-fdr-and-variants-of-fdr" class="level1">
<h1>8: Alternative ways to control FDR and variants of FDR</h1>
<p>Recall from earlier that the Benjamini-Hochberg procedure to control FDR can also be too conservative when all null hypotheses are true. There are a number of different variants of the FDR and with each variant, their own procedures for control. In general, these are more powerful than the B-H procedure. Below is a table of a few types:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">FDR Variants</th>
<th style="text-align: left;">Methods for Control</th>
<th style="text-align: left;">Software</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>pFDR</strong>: positive FDR, <span class="math inline">\(E[V/R|R&gt;0]\)</span></td>
<td style="text-align: left;">The Storey-BH procedure sets a rejection area and estimates the corresponding error rate. This contrasts the B-H procedure sets an error rate <span class="math inline">\(\alpha\)</span> and estimates its rejection area with the adjustments <a href="http://genomics.princeton.edu/storeylab/papers/directfdr.pdf">(Storey, 2002)</a>.</td>
<td style="text-align: left;">See R package <a href="http://www.bioconductor.org/packages/release/bioc/html/qvalue.html"><code>qvalue</code></a></td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>mFDR</strong> or Fdr: marginal FDR, <span class="math inline">\(E[FP]/E[R]\)</span>.</td>
<td style="text-align: left;"><span class="math inline">\(\alpha\)</span>-investing, a procedure where, after rejecting a null hypothesis, the researcher can “invest” in the <span class="math inline">\(\alpha\)</span> threshold by increasing the threshold for subsequent tests <a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2007.00643.x">(Foster and Stine, 2008)</a>.</td>
<td style="text-align: left;">See R package <a href="https://rdrr.io/bioc/onlineFDR/"> <code>onlineFDR</code> </a></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>fdr</strong>: Local false discovery rate, <span class="math inline">\(fdr(z)\)</span></td>
<td style="text-align: left;">An empirical Bayes approach to estimate local false discovery rate as a function of the size of the test statistic <span class="math inline">\(z\)</span> <a href="https://www.tandfonline.com/doi/abs/10.1198/016214504000000089?casa_token=K-0KnZVJTswAAAAA:hZEwReG-eqPWKLEC-2IiRzzwBfakFyGY-E8vzYlk5BKvkjI8R8W7wUn0GkbVvDeYEACbsvomg37H">(Efron, 2004)</a>.</td>
<td style="text-align: left;">See R pacakge <a href="https://cran.r-project.org/web/packages/locfdr/locfdr.pdf"> <code>locfdr</code> </a></td>
</tr>
</tbody>
</table>
<p>There is the increased chance of accepting more false discoveries with these other methods over the basic B-H approach. However, in cases with many, many tests, where the researcher might be willing to accept a few more false discoveries along with making more true discoveries, these methods for controlling FDR are good alternatives.</p>
</section>
<section id="creating-an-index-is-a-way-to-get-a-single-comparison-out-of-many" class="level1">
<h1>9: Creating an index is a way to get a single comparison out of many</h1>
<p>Suppose<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> a researcher measures <span class="math inline">\(k&gt;1\)</span> dependent variables. Indexing allows the researcher to reduce these <span class="math inline">\(k\)</span> outcomes into a single measure (or several thematically-grouped measures). These indexing methods effectively condense the number of dependent variables that investigators test in order to address the multiple comparisons problem. There are a number of ancillary benefits of these indexing methods:</p>
<ul>
<li>Unlike the other methods of addressing the multiple comparisons problem, the indexing approach may reward researchers for <em>increasing</em> the number of dependent variables. Imagine that a researcher collects <span class="math inline">\(k=50\)</span> outcome variables and that the treatment does not cause significant differences for any of them, but all the point estimates are in the same direction. If we were to apply a multiple comparisons correction to our 50 tests, our results would get even murkier. However, if we combine all 50 dependent variables into a single index, the resulting dependent variable may in fact exhibit significant differences.</li>
<li>In the presence of limited amounts of attrition across outcomes, these methods <em>may</em> provide some leverage for dealing with missingness on some dependent variables (but not for units for which outcome variables are entirely unobserved).</li>
</ul>
<p>There are two principal indexing methods in the literature:</p>
<section id="mean-effects-index" class="level3">
<h3 class="anchored" data-anchor-id="mean-effects-index">Mean Effects Index</h3>
<p><a href="(http://www.nber.org/mtopublic/483.pdf)">Kling, Liebman, and Katz (2004)</a> employ a mean effects index, constructed as follows:</p>
<ol type="1">
<li>If necessary, reorient some outcomes so that beneficial effects are consistently scored higher across all outcomes.</li>
<li>Calculate a <span class="math inline">\(z\)</span>-score, <span class="math inline">\(\tilde{y}_{ik}\)</span> by subtracting off the <em>control</em> group mean and dividing by the <em>control</em> group standard deviation, as follows, where <span class="math inline">\(i\)</span> indexes individuals and <span class="math inline">\(k\)</span> indexes outcomes:</li>
</ol>
<p><span class="math display">\[\tilde{y}_{ik}= \frac{y_{ik}- \bar{y}_k^{Z=0}}{\sigma_{k}^{y,Z=0}}\]</span></p>
<ol start="3" type="1">
<li><p>Sum the <span class="math inline">\(z\)</span>-scores, <span class="math inline">\(\sum_{i=1}^K \tilde{y}_{ik}\)</span> (optionally) divide by <span class="math inline">\(K\)</span> to generate the index.</p></li>
<li><p>Optional: It may be desirable to normalize the final index by the control group mean and standard deviation.</p></li>
</ol>
<p>In the presence of missing outcomes, one of two approaches could be employed:</p>
<ol type="1">
<li><strong>Imputation</strong>: Kling, Liebman, and Katz advocate a imputation approach for missing values on individual outcomes. Specifically, prior to constructing the index, compute the mean of each outcome variable for each experimental group, <span class="math inline">\(\bar{y}_{ik}^{Z=1}\)</span> and <span class="math inline">\(\bar{y}_{ik}^{Z=0}\)</span> using the above notation. Then, impute the mean corresponding to a unit’s assignment status (treatment or control) prior to constructing the index.</li>
<li><strong>“Greedy” Indexing</strong>: Instead of imputing values of missing outcome variables ex-ante as in method 1, calculate the <span class="math inline">\(z\)</span>-scores as above. Where there are missing values for the “raw” outcome variables, there will be missing <span class="math inline">\(z\)</span>-scores. For each unit, sum the non-missing <span class="math inline">\(z\)</span>-scores and then divide by the number of non-missing outcomes. Hence, instead of dividing <span class="math inline">\(\sum_{i=1}^K \tilde{y}_{ik}\)</span> by <span class="math inline">\(K\)</span> as above, we calculate <span class="math inline">\(K_{i}\)</span>, the number of non-missing outcomes, for each unit.</li>
</ol>
</section>
<section id="inverse-covariance-weighted-index" class="level3">
<h3 class="anchored" data-anchor-id="inverse-covariance-weighted-index">Inverse Covariance Weighted Index</h3>
<p><a href="https://are.berkeley.edu/~mlanderson/pdf/Anderson%202008a.pdf">Anderson (2008)</a> provides a similar approach that constructs an index that employs inverse covariance weighting. This weighting scheme improves efficiency relative to the mean effects index above by affording less weight to highly correlated outcomes. The Anderson index can be constructed through the following procedure:</p>
<ol type="1">
<li>If necessary, reorient some outcomes so that beneficial effects are consistently scored higher across all outcomes.</li>
<li>Calculate a <span class="math inline">\(z\)</span>-score, <span class="math inline">\(\tilde{y}_{ik}\)</span> by subtracting off the <em>control</em> group mean and dividing by the <em>control</em> group standard deviation, as follows, where <span class="math inline">\(i\)</span> indexes individuals and <span class="math inline">\(k\)</span> indexes outcomes:</li>
</ol>
<p><span class="math display">\[\tilde{y}_{ik}= \frac{y_{ik}- \bar{y}_k^{Z=0}}{\sigma_{k}^{y,Z=0}}\]</span></p>
<ol start="3" type="1">
<li><p>Construct and invert the (variance)-covariance matrix of the resultant matrix of <span class="math inline">\(z\)</span>-scores calculated in step 2. Call this <span class="math inline">\(k \times k\)</span> inverted (variance)-covariance matrix <span class="math inline">\(\hat{\boldsymbol{\Sigma}}^{-1}\)</span>.</p></li>
<li><p>The weighted indexed outcome, <span class="math inline">\(\bar{s}_i\)</span> can be estimated via the following procedure, where <span class="math inline">\(\textbf{1}\)</span> is a <span class="math inline">\(k \times 1\)</span> vector of ones and <span class="math inline">\(\textbf{y}_{ik}\)</span> is the <span class="math inline">\(n \times k\)</span> matrix of <span class="math inline">\(z\)</span>-scores calculated in step 2.</p></li>
</ol>
<p><span class="math display">\[\bar{s}_i = (\textbf{1}^T \hat{\boldsymbol{\Sigma}}^{-1} \textbf{1})^{-1}(\textbf{1}^T \hat{\boldsymbol{\Sigma}}^{-1} \textbf{y}_{ik})\]</span></p>
<ol start="5" type="1">
<li>Optional: As above, it may be desirable to normalize the final index by the control group mean and standard deviation.</li>
</ol>
<p>As with the mean effects index, this varible <span class="math inline">\(\bar{s}_i\)</span> the serves as the dependent variable in your analysis. One potential drawback to the inverse covariance weighting index is that there is no guarantee that elements in the inverted covariance matrix (<span class="math inline">\(\boldsymbol{\Sigma}^{-1}\)</span>) are positive. As such, it is possible to generate negative weights using this indexing method. Given that outcomes are oriented in the same direction, a negative weight effectively reverses the direction of the effect on negatively-weighted outcomes in the construction of the index.</p>
<p>The following functions implement both the mean effects and inverse covariance weighted index methods and evaluate both functions on a DGP with 50 outcome measures:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">require</span>(mvtnorm))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">require</span>(dplyr))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">require</span>(randomizr))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">require</span>(ggplot2))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>calculate_mean_effects_index <span class="ot">&lt;-</span> <span class="cf">function</span>(Z, outcome_mat, to_reorient, <span class="at">reorient =</span> <span class="cn">FALSE</span>, <span class="at">greedy =</span> <span class="cn">TRUE</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>                                <span class="at">impute =</span> <span class="cn">FALSE</span>){</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">length</span>(Z) <span class="sc">!=</span> <span class="fu">nrow</span>(outcome_mat)) <span class="fu">stop</span>(<span class="st">"Error: Treatment assignment, outcome matrix require same n!"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(impute <span class="sc">==</span> <span class="cn">TRUE</span>){</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    R <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">*</span> <span class="fu">is.na</span>(outcome_mat)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    means_for_imputation <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">apply</span>(outcome_mat[Z<span class="sc">==</span><span class="dv">0</span>,], <span class="at">MAR =</span> <span class="dv">2</span>, <span class="at">FUN =</span> mean, <span class="at">na.rm =</span> T),</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>                                  <span class="fu">apply</span>(outcome_mat[Z<span class="sc">==</span><span class="dv">1</span>,], <span class="at">MAR =</span> <span class="dv">2</span>, <span class="at">FUN =</span> mean, <span class="at">na.rm =</span> T))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    to_impute <span class="ot">&lt;-</span> R <span class="sc">*</span> means_for_imputation[Z<span class="sc">+</span><span class="dv">1</span>,]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    outcome_mat[<span class="fu">is.na</span>(outcome_mat)] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    outcome_mat <span class="ot">&lt;-</span> outcome_mat <span class="sc">+</span> to_impute</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  c_mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="at">X =</span> outcome_mat[Z<span class="sc">==</span><span class="dv">0</span>,], <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> mean, <span class="at">na.rm =</span> T)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  c_sd <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="at">X =</span> outcome_mat[Z<span class="sc">==</span><span class="dv">0</span>,], <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> sd, <span class="at">na.rm =</span> T)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  z_score <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">t</span>(<span class="fu">sweep</span>(outcome_mat, <span class="dv">2</span>, c_mean))<span class="sc">/</span> c_sd)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  index_numerator <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(z_score)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(greedy <span class="sc">==</span> <span class="cn">TRUE</span>){</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    n_outcomes <span class="ot">&lt;-</span> <span class="fu">rowSums</span>(<span class="sc">!</span><span class="fu">is.na</span>(z_score))</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span> <span class="cf">if</span>(greedy <span class="sc">==</span> <span class="cn">FALSE</span>){</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    n_outcomes <span class="ot">&lt;-</span> <span class="fu">ncol</span>(outcome_mat)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>  index <span class="ot">&lt;-</span> index_numerator<span class="sc">/</span>n_outcomes</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  index <span class="ot">&lt;-</span>  (index <span class="sc">-</span> <span class="fu">mean</span>(index[Z<span class="sc">==</span><span class="dv">0</span>], <span class="at">na.rm =</span>T))<span class="sc">/</span><span class="fu">sd</span>(index[Z<span class="sc">==</span><span class="dv">0</span>], <span class="at">na.rm =</span>T)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(index)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>calculate_inverse_covariance_weighted_index <span class="ot">&lt;-</span> <span class="cf">function</span>(Z, outcome_mat, to_reorient, <span class="at">reorient =</span> <span class="cn">FALSE</span>){</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">length</span>(Z) <span class="sc">!=</span> <span class="fu">nrow</span>(outcome_mat)) <span class="fu">stop</span>(<span class="st">"Error: Treatment assignment, outcome matrix require same n!"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(reorient <span class="sc">==</span> <span class="cn">TRUE</span>){</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    outcome_mat[, <span class="fu">c</span>(to_reorient)] <span class="ot">&lt;-</span> <span class="sc">-</span>outcome_mat[, <span class="fu">c</span>(to_reorient)] </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  c_mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="at">X =</span> outcome_mat[Z<span class="sc">==</span><span class="dv">0</span>,], <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> mean, <span class="at">na.rm =</span> T)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>  c_sd <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="at">X =</span> outcome_mat[Z<span class="sc">==</span><span class="dv">0</span>,], <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> sd, <span class="at">na.rm =</span> T)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>  z_score <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">t</span>(<span class="fu">sweep</span>(outcome_mat, <span class="dv">2</span>, c_mean))<span class="sc">/</span> c_sd)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>  Sigma_hat <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">cov</span>(z_score, <span class="at">y =</span> z_score, <span class="at">use =</span> <span class="st">"complete.obs"</span>))</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>  one_vec <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(<span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">ncol</span>(outcome_mat)))</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">sum</span>(<span class="fu">is.na</span>(outcome_mat))<span class="sc">&gt;</span><span class="dv">0</span>){</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    z_score[<span class="fu">is.na</span>(z_score)] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>  w_ij <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">solve</span>(<span class="fu">t</span>(one_vec) <span class="sc">%*%</span> Sigma_hat <span class="sc">%*%</span> one_vec) <span class="sc">%*%</span> (<span class="fu">t</span>(one_vec) <span class="sc">%*%</span> Sigma_hat))</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">sum</span>(w_ij <span class="sc">&lt;</span> <span class="dv">0</span>) <span class="sc">&gt;</span> <span class="dv">0</span>){<span class="fu">warning</span>(<span class="st">'Warning, at least one weight is negative!'</span>)}</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>  s_ij <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">solve</span>(<span class="fu">t</span>(one_vec) <span class="sc">%*%</span> Sigma_hat <span class="sc">%*%</span> one_vec) <span class="sc">%*%</span> (<span class="fu">t</span>(one_vec) <span class="sc">%*%</span> Sigma_hat <span class="sc">%*%</span> <span class="fu">t</span>(z_score)))</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>  index <span class="ot">&lt;-</span> (s_ij <span class="sc">-</span> <span class="fu">mean</span>(s_ij[Z<span class="sc">==</span><span class="dv">0</span>], <span class="at">na.rm =</span> T))<span class="sc">/</span><span class="fu">sd</span>(s_ij[Z<span class="sc">==</span><span class="dv">0</span>], <span class="at">na.rm =</span> T)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(s_ij)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We can see how these indices perform in a setting with <span class="math inline">\(k = 5\)</span> outcome variables.</p>
<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>
<div class="hidecode" onclick="doclick(this);">
[Click to show code]
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># A DGP with K outcome variables</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Untreated potential outcomes drawn from multivariate normal distribution</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="at">n =</span> K, <span class="at">min =</span> <span class="sc">-</span>.<span class="dv">9</span>, <span class="at">max =</span> .<span class="dv">9</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">outer</span>(r, r, <span class="at">FUN =</span> <span class="st">"*"</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(sigma) <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>mat <span class="ot">&lt;-</span> <span class="fu">rmvnorm</span>(<span class="at">n =</span> <span class="dv">200</span>, <span class="at">mean =</span> <span class="fu">rep</span>(<span class="dv">0</span>, K), <span class="at">sigma =</span> sigma)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Treatment assignment</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> <span class="fu">complete_ra</span>(<span class="dv">200</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Created observed potential outcomes</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume that ATEs are all oriented in the same direction for the time being</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>ATEs <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(K, <span class="at">mean =</span> .<span class="dv">25</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>K){</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  mat[,i] <span class="ot">&lt;-</span> mat[,i] <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">200</span>, <span class="at">mean =</span> Z <span class="sc">*</span> ATEs[i], <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>mean_effects_index <span class="ot">&lt;-</span> <span class="fu">calculate_mean_effects_index</span>(<span class="at">Z =</span> Z, <span class="at">outcome_mat =</span> mat, <span class="at">reorient =</span> F)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>inv_cov_weighted_index <span class="ot">&lt;-</span> <span class="fu">calculate_inverse_covariance_weighted_index</span>(<span class="at">Z =</span> Z, <span class="at">outcome_mat =</span> mat,<span class="at">reorient =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>First, we can examine the properties of the indices alongside our five outcome variables by looking at the covariance matrix.</p>
<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>
<div class="hidecode" onclick="doclick(this);">
[Click to show code]
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="fu">cov</span>(<span class="fu">data.frame</span>(mat, mean_effects_index, inv_cov_weighted_index)), <span class="at">digits =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 23%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 19%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">X1</th>
<th style="text-align: right;">X2</th>
<th style="text-align: right;">X3</th>
<th style="text-align: right;">X4</th>
<th style="text-align: right;">X5</th>
<th style="text-align: right;">mean_effects_index</th>
<th style="text-align: right;">inv_cov_weighted_index</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">X1</td>
<td style="text-align: right;">2.096</td>
<td style="text-align: right;">0.247</td>
<td style="text-align: right;">-0.330</td>
<td style="text-align: right;">-0.394</td>
<td style="text-align: right;">-0.443</td>
<td style="text-align: right;">0.448</td>
<td style="text-align: right;">0.249</td>
</tr>
<tr class="even">
<td style="text-align: left;">X2</td>
<td style="text-align: right;">0.247</td>
<td style="text-align: right;">2.059</td>
<td style="text-align: right;">-0.195</td>
<td style="text-align: right;">0.057</td>
<td style="text-align: right;">-0.054</td>
<td style="text-align: right;">0.747</td>
<td style="text-align: right;">0.247</td>
</tr>
<tr class="odd">
<td style="text-align: left;">X3</td>
<td style="text-align: right;">-0.330</td>
<td style="text-align: right;">-0.195</td>
<td style="text-align: right;">2.614</td>
<td style="text-align: right;">-0.172</td>
<td style="text-align: right;">0.450</td>
<td style="text-align: right;">0.641</td>
<td style="text-align: right;">0.295</td>
</tr>
<tr class="even">
<td style="text-align: left;">X4</td>
<td style="text-align: right;">-0.394</td>
<td style="text-align: right;">0.057</td>
<td style="text-align: right;">-0.172</td>
<td style="text-align: right;">1.784</td>
<td style="text-align: right;">0.249</td>
<td style="text-align: right;">0.534</td>
<td style="text-align: right;">0.242</td>
</tr>
<tr class="odd">
<td style="text-align: left;">X5</td>
<td style="text-align: right;">-0.443</td>
<td style="text-align: right;">-0.054</td>
<td style="text-align: right;">0.450</td>
<td style="text-align: right;">0.249</td>
<td style="text-align: right;">2.525</td>
<td style="text-align: right;">0.755</td>
<td style="text-align: right;">0.305</td>
</tr>
<tr class="even">
<td style="text-align: left;">mean_effects_index</td>
<td style="text-align: right;">0.448</td>
<td style="text-align: right;">0.747</td>
<td style="text-align: right;">0.641</td>
<td style="text-align: right;">0.534</td>
<td style="text-align: right;">0.755</td>
<td style="text-align: right;">0.999</td>
<td style="text-align: right;">0.428</td>
</tr>
<tr class="odd">
<td style="text-align: left;">inv_cov_weighted_index</td>
<td style="text-align: right;">0.249</td>
<td style="text-align: right;">0.247</td>
<td style="text-align: right;">0.295</td>
<td style="text-align: right;">0.242</td>
<td style="text-align: right;">0.305</td>
<td style="text-align: right;">0.428</td>
<td style="text-align: right;">0.189</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>We can also plot the two indices to show their similarities (or differences). Note that with the final normalization included in the functions above, both indices are on the same scale.</p>
<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>
<div class="hidecode" onclick="doclick(this);">
[Click to show code]
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(Z, mean_effects_index, inv_cov_weighted_index) <span class="sc">%&gt;%</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Group =</span> <span class="fu">ifelse</span>(Z<span class="sc">==</span><span class="dv">1</span>, <span class="st">"Treatment"</span>, <span class="st">"Control"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mean_effects_index, <span class="at">y =</span> inv_cov_weighted_index, <span class="at">colour =</span> Group)) <span class="sc">+</span> </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">theme_bw</span>() <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">"Mean Effects Index"</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">"Inverse Covariance Weighted Index"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="multiple-comparisons_en_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can estimate the treatment effect on the indexed variable using OLS or a difference-in-means. Note that given the normalization of both indices, the coefficient estimates are on the same scale and thus directly comparable. The p-values here use the standard OLS test-statistic.</p>
<style>
div.hidecode + pre {display: none}
</style>
<script>
doclick=function(e){
e.nextSibling.nextSibling.style.display="block";
}
</script>
<div class="hidecode" onclick="doclick(this);">
[Click to show code]
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>table <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">summary</span>(<span class="fu">lm</span>(mean_effects_index <span class="sc">~</span> Z))<span class="sc">$</span>coef[<span class="st">"Z"</span>, <span class="fu">c</span> (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>)], </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>        <span class="fu">summary</span>(<span class="fu">lm</span>(inv_cov_weighted_index <span class="sc">~</span> Z))<span class="sc">$</span>coef[<span class="st">"Z"</span>, <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>)])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(table) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Mean Effects Index"</span>, <span class="st">"Inverse Covariance Weighted Index"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(table) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Estimate"</span>, <span class="st">"Std. Error"</span>, <span class="st">"p-value"</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(table, <span class="at">digits =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Estimate</th>
<th style="text-align: right;">Std. Error</th>
<th style="text-align: right;">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Mean Effects Index</td>
<td style="text-align: right;">0.304</td>
<td style="text-align: right;">0.140</td>
<td style="text-align: right;">0.031</td>
</tr>
<tr class="even">
<td style="text-align: left;">Inverse Covariance Weighted Index</td>
<td style="text-align: right;">0.155</td>
<td style="text-align: right;">0.061</td>
<td style="text-align: right;">0.011</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</section>
<section id="use-design-based-approaches" class="level1">
<h1>10: Use Design Based approaches</h1>
<p>There are also two design based approaches for thinking about this problem. One is to use pre-analysis plans to describe in advance which comparisons will be made; the number of tests implicated in a Bonferroni or Bonferroni-style correction is specified before any data analysis is conducted. A pre-analysis plan, among its many benefits, helps to clarify the multiple comparisons problem.</p>
<p>A good example is this pre-analysis plan by <a href="https://egap.org/registration/651">Gwyneth McClendon and Rachel Beatty Riedl</a>. The authors specify 24 individual tests they plan to conduct and state ahead of time that they will employ both the Bonferroni and Benjamini-Hochberg corrections. The authors do not state beforehand how they will handle a situation in which the corrections disagree; presumably it will be a matter of judgment for both the authors and the readers of their study.</p>
<p>An additional benefit of pre-analysis plans is the ability to specify beforehand what the primary hypothesis is. There is disagreement among methodologists on this point, but some argue that because the primary hypothesis is not part of a “family claim” that a standardp-value is correct. For example, a researcher might have one primary hypothesis and 10 ancillary hypotheses. The uncertainty surrounding the primary hypothesis should not depend on the number of ancillary hypotheses. The advantage of a preanalysis plan is establishing beforehand which of the many hypotheses is the primary one.</p>
<p>An alternative perspective is to consider, from a theoretical and research design perspective, what is part of the “family claim.” For example, there may be a set of 5 hypotheses that are all used to support the primary hypothesis and the study was designed to focus on these 5 hypotheses. There may also be ancillary hypotheses that are used for exploration; the study was not developed with these ancillary hypotheses in mind, but the researcher thinks that it is interesting to explore these ancillary hypotheses. In a situation like this, the researcher might identify the 5 hypotheses as <em>confirmatory</em> hypotheses that are a family of hypotheses, and thus make adjustments to the p-values of those hypotheses, say controlling the FWER. The ancillary hypotheses would be considered <em>exploratory</em> hypotheses and do not need adjustments or could use more lenient adjustments compared to the confirmatory hypotheses, say controlling the FDR — allowing some false discoveries. Policy or action may be taken according to the confirmatory hypotheses, while future research may be developed to target the exploratory hypotheses.</p>
<p>The advantage of a preanalysis plan is establishing beforehand which of the many hypotheses is the primary one, which hypotheses are part of the same family of hypotheses or confirmatory, and which hypotheses are exploratory.</p>
<p>A second approach is to turn to replication. Replication is the best guard against drawing false conclusions from a noisy experiment. In particular, replication helps to establish whether heterogeneous effects findings are reliable. Researchers have a large degree of freedom in choosing how to search for heterogeneity — they can explore the entire covariate space searching for interesting interactions. Such a procedure is likely to lead to a large number of false positives. Multiple comparisons corrections such as the ones discussed above might help — but researchers also have discretion as to which correction to apply. Replication addresses this problem directly by measuring the same covariates and looking for differential effects according to the previous experiment’s analysis.</p>
<p>A good example comes from Coppock, Guess, and Ternovski (2015), in which the same experiment was conducted twice. The experiments measured the effects of two treatments on two dependent variables among four subgroups. In principle, this leads to 60 possible comparisons per experiment.</p>
<ul>
<li>3 pairwise comparisons between treatment 1, treatment 2, and control.</li>
<li>4 subgroups means 4 comparisons against zero plus 6 pairwise comparisons = 10.</li>
<li>2 dependent variables</li>
<li>3 * 10 * 2 = 60</li>
</ul>
<p>The figure below shows the results of the experiment and replication. Study 1 finds that “organization” accounts have smaller treatment effects than females, males, and unknown accounts on the “signed” DV but not the “tweeted” DV. The uncorrected p-value of the difference between “Organization” and “Male” conditional average treatment effects was 0.00003 for the “follower” treatment and 0.00632 for the “organizer” treatment. The Bonferroni correction would multiply both p-values by 60, suggesting that the “organizer” treatment does not work significantly differently for organizations versus men.</p>
<p>The replication, however, shows the same pattern of treatment effects: smaller effects for Organization accounts than for others on the “Signed” DV, but similar treatment effects on the “Tweeted” DV. Any doubt that the different response on the two different dependent variables was due to sampling variability are assuaged by the replication.</p>
<p><img src="https://raw.githubusercontent.com/egap/methods-guides/master/multiple-comparisons/multiple-comparisons_fig2.png" class="img-fluid"></p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Originating author: Alex Coppock, 18 Feb 2015. The guide is a live document and subject to updating by EGAP members at any time. Coppock is not responsible for subsequent edits to this guide. Updated by Lula Chen, 16 Feb 2021.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Formally <span class="math inline">\(E[FP/R|R&gt;0]P(R&gt;0)\)</span> to avoid dividing by 0.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Section 9 updated by Tara Lyn Slough, 4 February 2016<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>