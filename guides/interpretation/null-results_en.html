<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jennifer A. Hamilton">

<title>10 Things Your Null Results Might Mean</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="null-results_en_files/libs/clipboard/clipboard.min.js"></script>
<script src="null-results_en_files/libs/quarto-html/quarto.js"></script>
<script src="null-results_en_files/libs/quarto-html/popper.min.js"></script>
<script src="null-results_en_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="null-results_en_files/libs/quarto-html/anchor.min.js"></script>
<link href="null-results_en_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="null-results_en_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="null-results_en_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="null-results_en_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="null-results_en_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">10 Things Your Null Results Might Mean</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p><a href="https://sites.google.com/view/jennifer-a-hamilton/">Jennifer A. Hamilton</a> </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>A null result is when a <a href="https://methods.egap.org/guides/analysis-procedures/hypothesis-testing_en.html">hypothesis test</a> indicates that there is not enough evidence to say an intervention (treatment) changed outcomes in a study. Null results might occur because the intervention truly has no effect or because there is not enough information to detect an effect that exists.</p>
<section id="a-null-result-indicates-that-a-study-did-not-generate-evidence-to-conclude-that-an-intervention-changed-outcomes." class="level1">
<h1>A null result indicates that a study did not generate evidence to conclude that an intervention changed outcomes.</h1>
<p>There may not be evidence either because the intervention does not, in fact, change outcomes or because the study failed to gather adequate evidence of an effect that actually exists. Null results, like all other findings, are a function of both how the world works and the research design and statistical methods used to learn about the world.<br>
<!-- Among these methods are hypothesis tests.  To learn more about hypothesis testing, see [10 Things to Know About Hypothesis Testing](https://methods.egap.org/guides/analysis-procedures/hypothesis-testing_en.html). --></p>
</section>
<section id="well-designed-studies-with-null-effects-are-important-contributions-to-knowledge-about-the-world." class="level1">
<h1>Well-designed studies with null effects are important contributions to knowledge about the world.</h1>
<p>Researchers sometimes think of null results as neither interesting nor useful, but it is important to make publicly available results from all experiments. Studies with null results are underrepresented in published research.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> When studies with null results are not disseminated, other researchers might conduct similar studies thinking they are exploring new ground instead of directing their time and resources in more fruitful directions. The under-representation of null results also means that impression of effect sizes given by the published literature is too large.</p>
</section>
<section id="sometimes-null-results-are-an-artifact-of-true-zero-effects" class="level1">
<h1>Sometimes null results are an artifact of true zero effects:</h1>
</section>
<section id="a.-null-results-might-reflect-that-an-intervention-in-fact-does-not-move-outcomes." class="level1">
<h1>a. Null results might reflect that an intervention in fact does not move outcomes.</h1>
<p>If the intervention does not work, is too weak, or if the outcomes of interest are resistant to change, an intervention may simply not affect outcomes. For example, <a href="https://egap.org/our-work/the-metaketa-initiative/round1-information-accountability/">Metaketa I</a> theorized that providing citizens with information about incumbent performance would enhance political accountability. In Benin, one research team found that a light-touch information intervention did not change voter behavior <span class="citation" data-cites="adida_2020">(<a href="#ref-adida_2020" role="doc-biblioref">Adida et al. 2020</a>)</span>.</p>
<!-- # Sometimes null results are an artifact of true zero effects:  -->
</section>
<section id="b.-however-the-intervention-may-work-in-other-contexts---the-null-result-might-not-generalize." class="level1">
<h1>b. However, the intervention may work in other contexts - the null result might not generalize.</h1>
<p>The same study carried out in two different places or at two different times can generate different results. Sometimes an intervention that is ineffective in one setting will work in other contexts. Because of this, researchers should not conclude an intervention can never change outcomes on the basis of one study. For example, several studies in Africa tested whether community-based monitoring of health services improve healthcare uptake and outcomes. <span class="citation" data-cites="bjorkman_2009">Björkman and Svensson (<a href="#ref-bjorkman_2009" role="doc-biblioref">2009</a>)</span> initially found promising results in Uganda. Ten years later, a Sierra Leonean study also found promising results <span class="citation" data-cites="christensen_2021">(<a href="#ref-christensen_2021" role="doc-biblioref">Christensen et al. 2021</a>)</span> , but a <a href="https://egap.org/resource/does-bottom-up-accountability-work-evidence-from-uganda/">Ugandan replication study</a> had largely null findings.</p>
<!-- # Sometimes null results are an artifact of true zero effects:  -->
</section>
<section id="c.-null-effects-might-result-from-some-units-reponding-positively-and-other-units-negatively-to-the-intervention." class="level1">
<h1>c.&nbsp;Null effects might result from some units reponding positively and other units negatively to the intervention.</h1>
<!-- flect opposite reactions to the intervention by different units in the study. -->
<p>Randomized experiments generally focus on average treatment effects. However, the average treatment effect might mask important variation in effects across units within the study. Positive effects among some units may cancel out negative effects among other units, producing an average treatment effect indistinguishable from zero. For example, some respondents in an experiment in the United States felt more warmly toward the candidate after learning about a political candidate’s partisanship, while others felt more cold toward the candidate. The direction of the effect depended on the respondent’s own partisanship <span class="citation" data-cites="lelkes_2021">(<a href="#ref-lelkes_2021" role="doc-biblioref">Lelkes 2021</a>)</span>. Studies that fail to take into account how the direction of the effect depends on characteristics of individual subjects may generate null effects overall, even though the treatment shifted outcomes for many units. Even a larger sample size would have produced a null finding. To learn more about heterogeneous treatment effects, see <a href="https://methods.egap.org/guides/research-questions/heterogeneous-effects_en.html">10 Things to Know about Heterogeneous Treatment Effects</a>.</p>
</section>
<section id="sometimes-null-results-are-an-artifact-of-research-design-null-results-might-reflect-an-underpowered-research-design." class="level1">
<h1>Sometimes null results are an artifact of research design: Null results might reflect an underpowered research design.</h1>
<p>A research design is under-powered when design features undermine the ability to reliably detect a true effect. Inadequate power is a ubiquitous problem in social science research. In a recent working paper reviewing 16,000 hypothesis tests from 2,000 political science articles, <span class="citation" data-cites="arel-bundock_2023">Arel-Bundock et al. (<a href="#ref-arel-bundock_2023" role="doc-biblioref">2023</a>)</span> found that even with generous assumptions the median study had only 10% power. In other words, studies of an intervention with a true effect will generate null results nine out of ten times simply because of insufficient sample size. Only 10% of the studies in the review were powered at 80%, a commonly-used threshold for adequate power.</p>
<p>Features of research design may contribute to the lack of statistical power. First, <!-- research designs with imprecise measurement strategies are more likely to yield null results. M --> measurement strategies may not be sensitive enough to capture the changes that occurred. For example, consider whether exercise improves cardiovascular health in 6 months. It will be easier to detect improvements in cardiovascular health through finer measures like resting heart rate than through more blunt measures like whether the individual died. To learn more about measurement, see <a href="https://methods.egap.org/guides/data-strategies/measurement_en.html">10 Things to Know About Measurement in Experiments</a>. <!-- To learn more about indices and see sample code, see [10 Things to Know About Indices](https://methods.egap.org/guides/data-strategies/indices_en.html).  --></p>
<p>Second, research designs with small samples can produce null results even with sensitive measurement strategies. More units are needed to distinguish between a small average effect and a true zero effect than between a large average effect and a true zero effect. To learn more about statistical power, see <a href="https://methods.egap.org/guides/assessing-designs/power_en.html">10 Things to Know about Statistical Power</a>. <!-- An effect may be small on average if an intervention produces small effects among many treated units or if it produces larger effects among only a few treated units. --></p>
</section>
<section id="sometimes-null-results-because-designs-interact-with-the-real-world-in-unexpected-ways" class="level1">
<h1>Sometimes null results because designs interact with the real world in unexpected ways:</h1>
</section>
<section id="a.-null-results-might-result-from-treatments-or-their-effects-spilling-over-from-units-in-one-experimental-condition-to-another." class="level1">
<h1>a. Null results might result from treatments or their effects spilling over from units in one experimental condition to another.</h1>
<p>The intervention or its effects may spill over to units that were not assigned to receive that intervention. For example, if an intervention provides cash transfers to treated units, treated units may share the cash with other units not assigned to that intervention. If an intervention reduces racial prejudice, social connections among units may create shifts in racial attitudes and norms among units assigned to control as well as those assigned to treatment. Although the intervention produces real changes in these situations, the spillovers from the intervention targets to other units makes the changes difficult to detect when comparing study units in one condition to one another. Some research designs anticipate and measure spillovers. To learn more about spillovers, see <a href="https://methods.egap.org/guides/data-strategies/spillovers_en.html">10 Things to Know About Spillovers</a>.</p>
<!-- # Sometimes null results because designs interact with the real world in unexpected ways:  -->
</section>
<section id="b.-null-results-might-reflect-incomplete-implementation-of-the-intervention." class="level1">
<h1>b. Null results might reflect incomplete implementation of the intervention.</h1>
<p>Units randomly assigned to control may inadvertently receive treatment or units assigned to treatment might not receive it. <!-- [^2] --> For example, one <a href="https://www.gsb.stanford.edu/insights/everything-can-go-wrong-field-experiment-what-do-about-it">study</a> aimed to examine the effects of conditional cash transfer programs to improve school attendance. In the control condition, participants should have received unconditional cash transfers regardless of school attendance. However, the government implementing the transfer programs required families to enroll children in school in order to receive the “unconditional” funds, thus making the control group similar to the treatment group. This can bias results toward null findings even if there is actually an effect.</p>
<!-- [^2]: To learn more about *non-compliance* (when whether a unit received treatment does not match whether it was assigned to receive treatment), see [How to design and implement an experiment (life cycle)](https://methods.egap.org/guides/data-strategies/how-to_en.html). -->
<!-- # Sometimes null results because designs interact with the real world in unexpected ways:  -->
</section>
<section id="c.-null-results-might-reflect-differential-attrition." class="level1">
<h1>c.&nbsp;Null results might reflect differential attrition.</h1>
<p>An intervention or its effects may cause treated units to drop out of the study. If units where the treatment was effective are less likely to complete the study, such as when a successful training program might lead a subject to move outside the study area for work, then the study will likely underestimate the treatment’s impacts. Differential attrition may then explain null results. To learn more about attrition and see sample code, see <a href="https://methods.egap.org/guides/data-strategies/missing-data_en.html">10 Things to Know About Missing Data</a>.</p>
</section>
<section id="understanding-why-an-intervention-did-not-work-is-difficult." class="level1">
<h1>Understanding why an intervention did not work is difficult.</h1>
<p>Understanding why an intervention didn’t work as expected can be harder than understanding why it did. Researchers design studies based on their model of how the world works. If a study generates null results, researchers should first investigate whether this may be due to failures in research design, as <span class="citation" data-cites="humphreys_exporting_2019">Humphreys, de la Sierra, and van der Windt (<a href="#ref-humphreys_exporting_2019" role="doc-biblioref">2019</a>)</span> do. Researchers can then engage in theory-building to explain their findings. Talking to implementing partners and study participants or conducting additional statistical analyses like balance tests or tests for heterogeneous treatment effects might help researchers identify or rule out some explanations. After this process, researchers can design additional studies to test new explanations and theories.</p>
</section>
<section id="references" class="level1 unnumbered unlisted">


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-adida_2020" class="csl-entry" role="listitem">
Adida, Claire, Jessica Gottlieb, Eric Kramon, and Gwyneth McClendon. 2020. <span>“When <span>Does Information Influence Voters</span>? <span>The Joint Importance</span> of <span>Salience</span> and <span>Coordination</span>.”</span> <em>Comparative Political Studies</em> 53 (6): 851–91. <a href="https://doi.org/10.1177/0010414019879945">https://doi.org/10.1177/0010414019879945</a>.
</div>
<div id="ref-arel-bundock_2023" class="csl-entry" role="listitem">
Arel-Bundock, Vincent, Ryan Briggs, Hristos Doucouliagos, Marco M. Aviña, and T. D. Stanley. 2023. <span>“Quantitative <span>Political Science Research</span> Is <span>Greatly Underpowered</span>,”</span> December. <a href="https://doi.org/10.31219/osf.io/7vy2f">https://doi.org/10.31219/osf.io/7vy2f</a>.
</div>
<div id="ref-bjorkman_2009" class="csl-entry" role="listitem">
Björkman, Martina, and Jakob Svensson. 2009. <span>“Power to the <span>People</span>: <span>Evidence</span> from a <span>Randomized Field Experiment</span> on <span>Community-Based Monitoring</span> in <span>Uganda</span>.”</span> <em>The Quarterly Journal of Economics</em> 124 (2): 735–69. <a href="http://www.jstor.org/stable/40506242">http://www.jstor.org/stable/40506242</a>.
</div>
<div id="ref-christensen_2021" class="csl-entry" role="listitem">
Christensen, Darin, Oeindrila Dube, Johannes Haushofer, Bilal Siddiqi, and Maarten Voors. 2021. <span>“Building <span>Resilient Health Systems</span>: <span>Experimental Evidence</span> from <span>Sierra Leone</span> and <span>The</span> 2014 <span>Ebola Outbreak</span>*.”</span> <em>The Quarterly Journal of Economics</em> 136 (2): 1145–98. <a href="https://doi.org/10.1093/qje/qjaa039">https://doi.org/10.1093/qje/qjaa039</a>.
</div>
<div id="ref-franco_2014" class="csl-entry" role="listitem">
Franco, Annie, Neil Malhotra, and Gabor Simonovits. 2014. <span>“Publication Bias in the Social Sciences: <span>Unlocking</span> the File Drawer.”</span> <em>Science</em> 345 (6203): 1502–5. <a href="https://doi.org/10.1126/science.1255484">https://doi.org/10.1126/science.1255484</a>.
</div>
<div id="ref-humphreys_exporting_2019" class="csl-entry" role="listitem">
Humphreys, Macartan, Raúl Sánchez de la Sierra, and Peter van der Windt. 2019. <span>“Exporting Democratic Practices: <span>Evidence</span> from a Village Governance Intervention in <span>Eastern Congo</span>.”</span> <em>Journal of Development Economics</em> 140: 279–301. <a href="https://doi.org/10.1016/j.jdeveco.2019.03.011">https://doi.org/10.1016/j.jdeveco.2019.03.011</a>.
</div>
<div id="ref-lelkes_2021" class="csl-entry" role="listitem">
Lelkes, Yphtach. 2021. <span>“Policy over Party: Comparing the Effects of Candidate Ideology and Party on Affective Polarization.”</span> <em>Political Science Research and Methods</em> 9 (1): 189–96. <a href="https://doi.org/10.1017/psrm.2019.18">https://doi.org/10.1017/psrm.2019.18</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>To learn more about <em>publication bias</em> in the social sciences, see <span class="citation" data-cites="franco_2014">Franco, Malhotra, and Simonovits (<a href="#ref-franco_2014" role="doc-biblioref">2014</a>)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>