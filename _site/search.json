[
  {
    "objectID": "guides/getting-started/adaptive_en.html",
    "href": "guides/getting-started/adaptive_en.html",
    "title": "10 Things to Know About Adaptive Experimental Design",
    "section": "",
    "text": "1. What is an “adaptive”1 design?\nA static design applies the same procedures for allocating treatments and measuring outcomes throughout the trial. In contrast, an adaptive design may, based on interim analysis of the trial’s result, change the allocation of subjects to treatment arms or may change the allocation of resources to different outcome measures.\nOrdinarily, mid-course changes in experimental design are viewed with skepticism since they open the door to researcher interference in ways that could favor certain results. In recent years, however, statisticians have developed methods to automate adaptation in ways that either lessen the risk of interference or facilitate bias correction at the analysis stage.\n\n\n2. What are the potential advantages of an adaptive design?\nAdaptive designs have the potential to detect the best-performing experimental arm(s) more quickly than a static design (i.e., with fewer data-collection sessions and fewer subjects). When these efficiencies are realized, resources may be reallocated to achieve other research objectives.\nAdaptive designs also have the potential to lessen the ethical concerns that arise when subjects are allocated to inferior treatment arms. For therapeutic interventions, adaptive designs may reduce subjects’ exposure to inferior treatments; for interventions designed to further broad societal objectives, adaptive designs may hasten the discovery of superior interventions.\nTo illustrate the potential advantages of adaptive design, we simulate an RCT involving a control group and eight treatment arms. We administer treatments and gather 100 outcomes during each “period.” The simulation assumes that each subject’s outcome is binary (e.g., good versus bad). The adaptive allocation of subjects is based on interim analyses conducted at the end of each period. We allocate next period’s subjects according to posterior probabilities that a given treatment arm is best (see below). The simulation assumes that the probability of success is 0.10 for all arms except one, which is 0.20. The stopping rule is that the RCT is halted when one arm is found to have a 95% posterior probability of being best.\nIn the adaptive trial depicted below, the best arm (the red line) is correctly identified, and the trial is halted after 23 periods (total N=2300).\n\n\n\n3. What are the potential disadvantages of adaptive designs?\nThere is no guarantee that adaptive design will be superior in terms of speed or accuracy. For example, adaptive designs may result in a lengthy trial in cases where all of the arms are approximately equally effective. Even when one arm is truly superior, adaptive searches have some probability of resulting in long, circuitous searches (and considerable expense) if by chance they get off to a bad start (i.e., one of the inferior arms appears to be better than the other based on an initial round of results).\nFor instance, consider the following scenario in which all but one of the arms have a 0.10 probability of success, and the superior arm has a 0.12 probability of success (with the same trial design as in the previous example). The design eventually settles on the truly superior arm but only after more than 200 periods (N = 23,810). Even after 50 periods, the results provide no clear sense that any of the arms is superior.\n\nA further disadvantage of adaptive designs is they may produce biased estimates of the average treatment effect of the apparent best arm vis-à-vis the control group. Bias arises because the trial stops when the best arm crosses a threshold suggesting optimality; this stopping rule tends to favor lucky draws that suggest the efficacy of the winning arm. Conversely, when adaptive algorithms associate sampling probability with observed history, under-estimation for inferior arms, including the control group, may persist until stopping time (Nie et al., 2017).\nFor example, in the first scenario described above in which all arms have a 0.10 probability of success except for the best arm, which is 0.20, the average estimated success probability for the truly best arm is 0.202 across 1000 simulated experiments, while the control group average is found to 0.083. The average estimated difference in success probabilities (i.e., the average treatment effect) is 0.119, as compared to the true value of 0.10.\nIn the second scenario, in which the best arm’s success probability is just 0.12, the average estimated success probability for the best arm is 0.121, and the average estimated ATE is 0.027, as compared to the true ATE of 0.02. Bias in this case is relatively small on a percentage point scale due to the very large size of the average experiment.\n\n\n4. What kinds of experiments lend themselves to adaptive design?\nAdaptive designs require multiple periods of treatment and outcome assessment.\nAdaptive designs are well suited to survey, on-line, and lab experiments, where participants are treated and outcomes measured in batches over time.\nSome field experiments are conducted in stages, although the logistics of changing treatment arms may be cumbersome, as discussed below. One possible opportunity for adaptive design in a field context occurs when a given experiment is to be deployed over time in a series of different regions. This allows for adaptation based on region-by-region interim analyses.\nAdaptive designs are ill-suited to one-shot interventions with outcomes measured at a single point in time. For example, experiments designed to increase voter turnout in a given election do not lend themselves to adaptive design because everyone’s outcome is measured at the same time, leaving no opportunity for adaptation.\n\n\n5. What is the connection between adaptive designs and “multi-arm bandit problems”?\nThe multi-arm bandit problem (Scott 2010) is a metaphor for the following optimization problem. Imagine that you could drop a coin in one of several slot machines that may pay off at different rates. (Slot machines are sometimes nicknamed “one-arm bandits,” hence the name.) You would like to make as much money as possible. The optimization problem may be characterized as a trade off between learning about the relative merits of the various slot machines – exploration – and reaping the benefits of employing the best arm – exploitation. A static design may be viewed as an extreme case of allocating subjects solely for exploration.\nAs applied to RCTs, the aim is to explore the merits of the various treatment arms while at the same time reaping the benefits of the best arm or arms. Although the MAB problem is not specifically about estimating treatment effects, one could adjust the optimization objective so that the aim is to find the treatment arm with the greatest apparent superiority over the control group.\n\n\n6. What are some widely used algorithms for automating “adaptation”?\nThe most commonly used methods employ some form of “Thompson sampling” (Thompson 1933). Interim results are assessed periodically, and in the next period subjects are assigned to treatment arms in proportion to the posterior probability that a given arm is best. The more likely an arm is to be “best,” the more subjects it receives.\nMany variations on this basic assignment routine have been proposed, and some are designed to make it less prone to bias. If an adaptive trial is rolled out during a period in which success rates tend to be growing, increasing allocation of subjects to the best arm will tend to exaggerate that arm’s efficacy relative to the other arms, which receive fewer subjects during the high-yield period. In order to assess bias and correct for it, it may be useful to allocate some subjects in every period according to a static design. In this case, inverse probability weights for each period may be used to obtain unbiased estimates of the average treatment effect. (See Gerber and Green 2012 on the use of inverse probability weights for estimation of average treatment effects when the probability of assignment varies from block to block.)\n\n\n7. What are the symptoms of futile search?\nAlthough it is impossible to know for sure whether a drawn out search reflects an unlucky start or an underlying reality in which no arm is superior, the longer an adaptive trial goes, the more cause for concern. The following graphs summarize the distribution of stopping times for three scenarios. Stopping was dictated by at 10% value remaining criterion. Specifically, the trial stopped when the top of the 95% confidence interval showed that no other arm was likely to offer at least a 10 percent (not percentage point) gain in success rate. The first two scenarios were described above; the third scenario considers a case in which there are two superior arms. The graph illustrates how adaptive trials tend to conclude faster when the superiority of the best arm(s) is more clear-cut.\n\n\n\n8. What implications do adaptive designs have for pre-analysis plans?\nThe use of adaptive designs introduces additional decisions, which ideally should be addressed ex ante so as to limit researcher bias. For example, the researcher should specify which algorithms will be used for allocation. It is especially important to specify the stopping rule. Depending on the researcher’s objectives, this rule may focus on achieving a desired posterior probability, or it may use a “value remaining” criterion that considers whether one or more arms have shown themselves to be good enough vis-à-vis the alternative arms. Other hybrid stopping criteria may also be specified. The pre-analysis plan should also describe the analytic steps that will be taken to correct for bias.\n\n\n9. Are multi-arm bandit trials frequently used in social science?\nMany of the applications to date have taken place in commercial settings, such as website design for high-volume e-commerce, or in settings such as on-line fundraising. Relatively few applications have been written up in detail for a scholarly audience. Surprisingly rare are applications in biomedical research. As Villar et al. (2015, p.200) note, “Despite this apparent near-perfect fit between a real-world problem and a mathematical theory, the MABP has yet to be applied to an actual clinical trial.”\nPutting aside the use of multi-arm bandit approaches, the use of adaptive trials is gradually winning acceptance in biomedical research. For details, see Chin (2016).\n\n\n10. What other considerations should inform the decision to use adaptive design?\nAs noted above, adaptive designs add to the complexity of the research design and analysis. They also may increase the challenges of implementation, particularly in field settings where the logistical or training costs associated with different arms vary markedly. Even when one arm is clearly superior (inferior), the lead-time necessary to staff or outfit this arm may make it difficult to scale it up (down). Adaptive designs are only practical if adaptation is feasible.\nOn the other hand, funders and implementation partners may welcome the idea of an experimental design that responds to on-the-ground conditions such that problematic arms are scaled back. A middle ground between static designs and designs that envision adaptation over many periods are adaptive designs involving only two or three interim analyses and adjustments. Such trials are winning increased acceptance in biomedical research (Chow and Chang 2008) and are likely to become more widely used in the social sciences too. The growing interest in replication and design-based extensions of existing experiments to aid generalization are likely to create opportunities for adaptive design.\n\n\nReferences\nChin, Richard. 2016. Adaptive and flexible clinical trials. New York: CRC Press.\nChow, Shein-Chung, and Mark Chang. 2008. “Adaptive design methods in clinical trials – a review.” Orphanet Journal of Rare Diseases 3:11.  Link to article \nNie, Xinkun, Xiaoying Tian, Jonathan Taylor, and James Zou. 2017. “Why Adaptively Collected Data Have Negative Bias and How to Correct for It.” arXiv:1708.01977\nScott, Steven L. 2010. “A modern Bayesian look at the multi-armed bandit.” Applied Stochastic Models in Business and Industry 26:639–658.\nThompson, William R. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika 25:285–294.\nVillar, Sofía S., Jack Bowden, and James Wason. “Multi-Armed Bandit Models for the Optimal Design of Clinical Trials: Benefits and Challenges.” Statistical science: a review journal of the Institute of Mathematical Statistics 30.2 (2015): 199–215.\n\n\n\n\n\n\nFootnotes\n\n\nThis guide originally authored by Donald Green (Columbia University) and Molly Offer-Westort (Yale University) and published on February 23, 2018.↩︎"
  },
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Methods guides",
    "section": "",
    "text": "Jake Bowers & Rebecca Wolfe\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nMacartan Humphreys\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nRenard Sexton\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeter van der Windt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDonald Green & Molly Offer-Westort\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLindsay Dolan\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nAlbert Fang\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nGabriella Sacramone-Lutz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGabriella Sacramone-Lutz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaul Testa\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides.html#planning-research-and-evaluations",
    "href": "guides.html#planning-research-and-evaluations",
    "title": "Methods guides",
    "section": "Planning research and evaluations",
    "text": "Planning research and evaluations\n\n\n\n\n\n\n\n\n\n\n10 Things You Need to Know About Statistical Power\n\n\n\n\n\n\nAlexander Coppock\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides/planning/power_en.html",
    "href": "guides/planning/power_en.html",
    "title": "10 Things You Need to Know About Statistical Power",
    "section": "",
    "text": "Abstract\nThis guide1 will help you assess and improve the power of your experiments. We focus on the big ideas and provide examples and tools that you can use in R and Google Spreadsheets.\n\n\n1 What Power Is\nPower is the ability to distinguish signal from noise.\nThe signal that we are interested in is the impact of a treatment on some outcome. Does education increase incomes? Do public health campaigns decrease the incidence of disease? Can international monitoring decrease government corruption?\nThe noise that we are concerned about comes from the complexity of the world. Outcomes vary across people and places for myriad reasons. In statistical terms, you can think of this variation as the standard deviation of the outcome variable. For example, suppose an experiment uses rates of a rare disease as an outcome. The total number of affected people isn’t likely to fluctuate wildly day to day, meaning that the background noise in this environment will be low. When noise is low, experiments can detect even small changes in average outcomes. A treatment that decreased the incidence of the disease by 1% percentage points would be easily detected, because the baseline rates are so constant.\nNow suppose an experiment instead used subjects’ income as an outcome variable. Incomes can vary pretty widely – in some places, it is not uncommon for people to have neighbors that earn two, ten, or one hundred times their daily wages. When noise is high, experiments have more trouble. A treatment that increased workers’ incomes by 1% would be difficult to detect, because incomes differ by so much in the first place.\nA major concern before embarking on an experiment is the danger of a false negative. Suppose the treatment really does have a causal impact on outcomes. It would be a shame to go to all the trouble and expense of randomizing the treatment, collecting data on both treatment and control groups, and analyzing the results, just to have the effect be overwhelmed by background noise.\nIf our experiments are highly-powered, we can be confident that if there truly is a treatment effect, we’ll be able to see it.\n\n\n2 Why You Need It\nExperimenters often guard against false positives with statistical significance tests. After an experiment has been run, we are concerned about falsely concluding that there is an effect when there really isn’t.\nPower analysis asks the opposite question: supposing there truly is a treatment effect and you were to run your experiment a huge number of times, how often will you get a statistically significant result?\nAnswering this question requires informed guesswork. You’ll have to supply guesses as to how big your treatment effect can reasonably be, how many subjects will answer your survey, how many subjects your organization can realistically afford to treat.\nWhere do these guesses come from? Before an experiment is run, there is often a wealth of baseline data that are available. How old/rich/educated are subjects like yours going to be? How big was the biggest treatment effect ever established for your dependent variable? With power analysis, you can see how sensitive the probability of getting significant results is to changes in your assumptions.\nMany disciplines have settled on a target power value of 0.80. Researchers will tweak their designs and assumptions until they can be confident that their experiments will return statistically significant results 80% of the time. While this convention is a useful benchmark, be sure that you are comfortable with the risks associated with an 80% expected success rate.\nA note of caution: power matters a lot. Negative results from underpowered studies can be hard to interpret: Is there really no effect? Or is the study just not able to figure it out? Positive results from an underpowered study can also be misleading: conditional upon being statistically significant, an estimate from an underpowered study probably overestimates treatment effects. Under powered studies are sometimes based on overly optimistic assumptions; a convincing power analysis makes these assumptions explicit and should protect you from implementing designs that realistically have no chance of answering the questions you want to answer.\n\n\n3 The Three Ingredients of Statistical Power\nThere are three big categories of things that determine how highly powered your experiment will be. The first two (the strength of the treatment and background noise) are things that you can’t really control – these are the realities of your experimental environment. The last, the experimental design, is the only thing that you have power over – use it!\n\nStrength of the treatment. As the strength of your treatment increases, the power of your experiment increases. This makes sense: if your treatment were giving every subject $1,000,000, there is little doubt that we could discern differences in behavior between the treatment and control groups. Many times, however, we are not in control of the strength of our treatments. For example, researchers involved in program evaluation don’t get to decide what the treatment should be, they are supposed to evaluate the program as it is.\nBackground noise. As the background noise of your outcome variables increases, the power of your experiment decreases. To the extent that it is possible, try to select outcome variables that have low variability. In practical terms, this means comparing the standard deviation of the outcome variable to the expected treatment effect size — there is no magic ratio that you should be shooting for, but the closer the two are, the better off your experiment will be. By and large, researchers are not in control of background noise, and picking lower-noise outcome variables is easier said than done. Furthermore, many outcomes we would like to study are inherently quite variable. From this perspective, background noise is something you just have to deal with as best you can.\nExperimental Design. Traditional power analysis focuses on one (albeit very important) element of experimental design: the number of subjects in each experimental group. Put simply, a larger number of subjects increases power. However, there are other elements of the experimental design that can increase power: how is the randomization conducted? Will other factors be statistically controlled for? How many treatment groups will there be, and can they be combined in some analyses?\n\n\n\n4 Key Formulas for Calculating Power\nStatisticians have derived formulas for calculating the power of many experimental designs. They can be useful as a back of the envelope calculation of how large a sample you’ll need. Be careful, though, because the assumptions behind the formulas can sometimes be obscure, and worse, they can be wrong.\nHere is a common formula used to calculate power2\n\\[\\beta = \\Phi \\left(\\frac{|\\mu_t-\\mu_c|\\sqrt{N}}{2\\sigma}-\\Phi^{-1} \\left(1-\\frac{\\alpha}{2}\\right) \\right)\\]\n\n\\(\\beta\\) is our measure of power. Because it’s the probability of getting a statistically significant result, β will be a number between 0 and 1.\n\\(\\Phi\\) is the CDF of the normal distribution, and \\(\\Phi^{-1}\\) is its inverse. Everything else in this formula, we have to plug in:\n\\(\\mu_t\\) is the average outcome in the treatment group. Suppose it’s 65.\n\\(\\mu_c\\) is the average outcome in the control group. Suppose it’s 60.\nTogether, assumptions about μt and μc define our assumption about the size of the treatment effect: 65-60= 5.\n\\(\\sigma\\) is the standard deviation of outcomes. This is how we make assumptions about how noisy our experiment will be — one of the assumptions we’re making is that sigma is the same for both the treatment and control groups. Suppose \\(\\sigma=20\\)\n\\(\\alpha\\) is our significance level – the convention in many disciplines is that α should be equal to 0.05. \\(N\\) is the total number of subjects. This is the only variable that is under the direct control of the researcher. This formula assumes that every subject had a 50/50 chance of being in control. Suppose that \\(N=500\\).\n\nWorking through the formula, we find that under this set of assumptions, \\(β = 0.80\\), meaning that we have an 80% chance of recovering a statistically significant result with this design. Click here for a google spreadsheet that includes this formula. You can copy these formulas directly into Excel. If you’re comfortable in R, here is code that will accomplish the same calculation.\n\npower_calculator <- function(mu_t, mu_c, sigma, alpha=0.05, N){ \n  lowertail <- (abs(mu_t - mu_c)*sqrt(N))/(2*sigma) \n  uppertail <- -1*lowertail \n  beta <- pnorm(lowertail- qnorm(1-alpha/2), lower.tail=TRUE) + 1- pnorm(uppertail- qnorm(1-alpha/2), lower.tail=FALSE) \n  return(beta) \n  } \n\n\n\n5 When to Believe Your Power Analysis\nFrom some perspectives the whole idea of power analysis makes no sense. You want to figure out the size of some treatment effect but first you need to do a power analysis which requires that you already know your treatment effect and a lot more besides.\nSo in most power analyses you are in fact seeing what happens with numbers that are to some extent made up. The good news is that it is easy to find out how much your conclusions depend on your assumptions: simply vary your assumptions and see how the conclusions on power vary.\nThis is most easily seen by thinking about how power varies with the number of subjects. A power analysis that looks at power for different study sizes simply plugs in a range of values in for N and seeing how β changes.\nUsing the formula in section 4, you can see how sensitive power is to all of the assumptions: Power will be higher if you assume the treatment effect will be larger, or if you’re willing to accept a higher alpha level, or if you have more or less confidence in the noisiness of your measures.3\n\n\n\n\n6 How to Use Simulation to Estimate Power\nPower is a measure of how often, given assumptions, we would obtain statistically significant results, if we were to conduct our experiment thousands of times. The power calculation formula takes assumptions and return an analytic solution. However, due to advances in modern computing, we don’t have to rely on analytic solutions for power analysis. We can tell our computers to literally run the experiment thousands of times and simply count how frequently our experiment comes up significant.\nThe code block below shows how to conduct this simulation in R.\n\npossible.ns <- seq(from=100, to=2000, by=40) # The sample sizes we'll be considering\nstopifnot(all( (possible.ns %% 2)==0 )) ## require even number of experimental pool\npowers <- rep(NA, length(possible.ns)) # Empty object to collect simulation estimates \nalpha <- 0.05 # Standard significance level \nsims <- 500 # Number of simulations to conduct for each N \n#### Outer loop to vary the number of subjects #### \nfor (j in 1:length(possible.ns)){ N <- possible.ns[j] # Pick the jth value for N \n  Y0 <- rnorm(n=N, mean=60, sd=20) # control potential outcome \n  tau <- 5 # Hypothesize treatment effect \n  Y1 <- Y0 + tau # treatment potential outcome                                   \n  significant.experiments <- rep(NA, sims) # Empty object to count significant experiments \n                                  \n  #### Inner loop to conduct experiments \"sims\" times over for each N #### \n        Y0 <- rnorm(n=N, mean=60, sd=20) # control potential outcome \n        tau <- 5 # Hypothesize treatment effect \n        Y1 <- Y0 + tau # treatment potential outcome \n  for (i in 1:sims){ \n        ## Z.sim <- rbinom(n=N, size=1, prob=.5) # Do a random assignment  by coin flip\n        Z.sim <- sample(rep(c(0,1),N/2)) ## Do a random assignment ensuring equal sized groups\n        Y.sim <- Y1*Z.sim + Y0*(1-Z.sim) # Reveal outcomes according to assignment \n        fit.sim <- lm(Y.sim ~ Z.sim) # Do analysis (Simple regression) \n        p.value <- summary(fit.sim)$coefficients[2,4] # Extract p-values \n        significant.experiments[i] <- (p.value <= alpha) # Determine significance according to p <= 0.05\n        }\n  powers[j] <- mean(significant.experiments) # store average success rate (power) for each N \n  } \npowers \n\n [1] 0.236 0.330 0.410 0.534 0.566 0.560 0.688 0.678 0.728 0.790 0.818 0.852\n[13] 0.864 0.886 0.918 0.888 0.900 0.896 0.944 0.976 0.944 0.964 0.980 0.974\n[25] 0.988 0.986 0.996 0.992 0.996 0.992 0.998 0.990 0.996 1.000 0.998 0.998\n[37] 1.000 1.000 0.998 0.996 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n\n\nThe code for this simulation and others is available here. Simulation is a far more flexible, and far more intuitive way to think about power analysis. Even the smallest tweaks to an experimental design are difficult to capture in a formula (adding a second treatment group, for example), but are relatively straightforward to include in a simulation.\nIn addition to counting up how often your experiments come up statistically significant, you can directly observe the distribution of p-values you’re likely to get. The graph below shows that under these assumptions, you can get expect to get quite a few p-values in the 0.01 range, but that 80% will be below 0.05.\n\n\n\n7 How to Change your Design to Improve Your Power\nWhen it comes to statistical power, the only thing that that’s under your control is the design of the experiment. As we’ve seen above, an obvious design choice is the number of subjects to include in the experiment. The more subjects, the higher the power.\nHowever, the number of subjects is not the only design choice that has consequences for power. There are two broad classes of design choices that are especially important in this regard.\n\nChoice of estimator. Are you using difference-in-means? Will you be doing some transformation, such as a logit or a probit? Will you be controlling for covariates? Will you be using some kind of robust standard error estimator? All of these choices will make a difference for the statistical significance of your results, and therefore for the power of your experiment. One easy way to think about this is to imagine what command you’ll be running in R or Stata after the experiment has come back; that’s your estimator!\nRandomization Protocol. What kind of randomization will you be employing? Simple randomization gives all subjects an equal probability of being in the treatment group, and then performs a (possibly weighted) coin flip for each. Complete randomization is similar, but it ensures that exactly a certain number will be assigned to treatment. Block randomization is even more powerful — it ensures that a certain number within a subgroup will be assigned to treatment. A restricted random assignment rejects some random assignments based on some set of criteria — lack of balance perhaps. These various types of random assignment can dramatically increase the power of an experiment at no extra cost. Read up on randomization protocols here.\n\nThere are too many choices to cover in this short article, but check out the Simulation for Power Analysis code page for some ways to get started. But to give a flavor of the simulation approach, consider how you would conduct a power analysis if you wanted to include covariates in your analysis.\nIf the covariates you include as control variables are strongly related to the outcome, then you’ve dramatically increased the power of your experiment.Unfortunately, the extra power that comes with including control variables is very hard to capture in a compact formula. Almost none of the power formulas found in textbooks or floating around on the internet can provide guidance on what the inclusion of covariates will do for your power.\nThe answer is simulation.\n\nSuppose we’re studying the effect of an educational intervention on income\nSuppose we have good data on the relationship between two covariates and income: age and gender. In this economy, men earn more than women, and older people earn more than younger people.\nRun a regression of income on age and gender and record the coefficients, using pre-existing survey data (better yet: use baseline data from future participants in your experiment!) *Generate fake covariate data — N total subjects, but broken up by age and gender in a way that reflects your experimental subject pool.\nGenerate fake control data — where the outcome is a function of age and gender according to your regression estimates\nHypothesize a treatment effect to generate fake treatment data\nRun the experiment 10,000 times, and record how often, using a regression with controls, your experiment turns up significant.\n\nHere’s a graph that compares the power of an experiment that does control for background attributes to one that does not. The R-square of the regression relating income to age and gender is pretty high — around .66 — meaning that the covariates that we have gathered (generated) are highly predictive. For a rough comparison, sigma, the level of background noise that the unadjusted model is dealing with, is around 33. This graph shows that at any N, the covariate-adjusted model has more power — so much so that the unadjusted model would need 1500 subjects to achieve what the covariate-adjusted model can do with 500.\n\nThis approach doesn’t rely on a formula to come up with the probability of getting a statistically significant result: it relies on brute force! And because simulation lets you specify every step of the experimental design, you do a far more nuanced power analysis than simply considering the number of subjects.\n\n\n8 Power Analysis for Multiple Treatments\nMany experiments employ multiple treatments which are compared both to each other and to a control group. This added complication changes what we mean when we say the “power” of an experiment. In the single treatment group case, power is just the probability of getting a statistically significant result. In the multiple treatment case, it can mean a variety of things: A) the probability of at least one of the treatments turning up significant, B) the probability of all the treatments turning up significant (versus control) or C) the probability that the treatments will be ranked in the hypothesized order, and that those ranks will be statistically significant.\nThis question of multiple treatment arms is related to the problem of multiple comparisons. (See our guide on this topic for more details.) Standard significance testing is based on the premise that you’re conducting a single test for statistical significance, and the p-values derived from these tests reflect the probability under the null of seeing such a larger (or larger) treatment effect. If, however, you are conducting multiple tests, this probability is no longer correct. Within a suite of tests, the probability that at least one of the tests will turn up significant even when the true effect is zero is higher, essentially because you have more attempts. A commonly cited (if not commonly used) solution is to use the Bonferroni correction: specify the number of comparisons you will be making in advance, then divide your significance level (alpha) by that number.\nIf you are going to be using a Bonferroni correction, then standard power calculators will be more complicated to use: you’ll have to specify your Bonferroni-corrected alpha levels and calculate the power of each separate comparison. To calculate the probability that all the tests are significant, multiply all the separate powers together. To calculate the probability that at least one of the tests is significant, calculate the probability that none are, then subtract from one.\nOr you can use simulation. An example of a power calculation done in R is available on the simulations page.\n\n\n9 How to Think About Power for Clustered Designs\nWhen an experiment has to assign whole groups of people to treatment rather than individually, we say that the experiment is clustered. This is common in educational experiments, where whole classrooms of children are assigned to treatment or control, or in development economics, where whole villages of individuals are assigned to treatment or control. (See our guide on cluster randomization for more details.)\nAs a general rule, clustering decreases your power. If you can avoid clustering your treatments, that is preferable for power. Unless you face concerns related to spillover, logistics, or ethics, take the variation down to the lowest level that you can.\nThe best case scenario for a cluster-level design is when which cluster a subject is in provides very little information about their outcomes. Suppose subjects were randomly assigned to clusters — the cluster wouldn’t help to predict outcomes at all. If the cluster is not predictive of the outcome, then we haven’t lost too much power to clustering.\nWhere clustering really causes trouble is when there is a strong relationship between the cluster and the outcome. To take the villages example, suppose that some villages are, as a whole, much richer than others. Then the clusters might be quite predictive of educational attainment. Clustering can reduce your effective sample size from the total number of individuals to the total number of clusters.\nThere are formulas that can help you understand the consequences of clustering — see Gelman/Hill page 447-449 for an extended discussion. While these formulas can be useful, they can also be quite cumbersome to work with. The core insight however is a simple one: you generally get more power from increasing the number of clusters than you do from increasing the number of subjects within clusters. Better to have 100 clusters with 10 subjects in each than 10 clusters with 100 subjects in each.\nAgain, a more flexible approach to power analysis when dealing with clusters is simulation. See the (Declare Design library for block and cluster randomized experiments)[https://declaredesign.org/r/designlibrary/reference/block_cluster_two_arm_designer.html] for some starter code. The (DeclareDesign)[https://declaredesign.org] software aims to make simulations for power analysis (among many other tasks) easier. See also Gelman/Hill page 450-453 for another simulation approach.\n\n\n10 Good Power Analysis Makes Preregistration Easy\nWhen you deal with power you focus on what you cannot control (noise) and what you can control (design). If you use the simulation approach to power analysis then you will be forced to imagine how your data will look and how you will handle it when it comes in. You will get a chance to specify all of your hunches and best guesses in advance, so that you can launch your experiments with clear expectations of what they can and cannot show. That’s some work but the good news is that if you really do it you are most of the way to putting together a comprehensive and registerable pre-analysis plan.\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Alex Coppock, 20 Nov 2013. The guide is a live document and subject to updating by EGAP members at any time. Coppock is not responsible for subsequent edits to this guide↩︎\nReproduced from Gerber and Green 2012, page 93↩︎\nFor an additional online power visualization tool, see Kristoffer Magnusson’s R Psychologist blog.↩︎"
  },
  {
    "objectID": "guides/getting-started/causal-inference_en.html",
    "href": "guides/getting-started/causal-inference_en.html",
    "title": "10 Things You Need to Know About Causal Inference",
    "section": "",
    "text": "Abstract\nThe philosopher David Lewis described causation as “something that makes a difference, and the difference it makes must be a difference from what would have happened without it.”[^1] This is the interpretation given to causality by most experimentalists. Even though the definition seems simple, it has many subtle implications. Here are ten ideas implied by this notion of causality that matter for research design.1\n\n\n1. A causal claim is a statement about what didn’t happen.\nFor most experimentalists, the statement “\\(X\\) caused \\(Y\\)” means that \\(Y\\) is present and \\(Y\\) would not have been present if \\(X\\) were not present. This definition requires a notion of what could have happened, but did not happen.2 Similarly, the “effect” of \\(X\\) on \\(Y\\) is thought of as the difference between the value that \\(Y\\) would have taken given one value of \\(X\\) and the value that \\(Y\\) would have taken given another value of \\(X\\). Because of the focus on differences in outcomes, this approach is sometimes called the “difference making” or “counterfactual” approach to causation.\nTechnical Note: Statisticians employ the “potential outcomes” framework to describe counterfactual relations. In this framework, we let \\(Y_i(1)\\) denote the outcome for unit \\(i\\) that would be observed under one condition (e.g., if unit \\(i\\) received a treatment) and \\(Y_i(0)\\) the outcome that would be observed in another condition (e.g., if unit \\(i\\) did not receive the treatment). One causal effect of the treatment for unit \\(i\\) might be a simple difference of the potential outcomes \\(τ_i=Y_i(1)−Y_i(0)\\). A treatment has a (positive or negative) causal effect on \\(Y\\) for unit \\(i\\) if \\(Y_i(1)≠Y_i(0)\\).\n\n\n2. There is no causation without manipulation.\nThe “counterfactual” definition of causality requires one to be able to think through what outcomes may result in different conditions. How would things look if one party as opposed to another was elected? Everyday causal statements often fall short of this requirement in one of two ways.\n\nFirst, some statements do not specify clear counterfactual conditions. For example the claim that “the recession was caused by Wall Street” does not point to an obvious counterfactual— are we to consider whether there would have been a recession if Wall Street did not exist? Or is the statement really a statement about particular actions that Wall Street could have taken but did not. If so, which actions? The validity of such statements is hard to assess, and can depend on which counterfactual conditions are implied by a statement.\nSecond, some statements involve counterfactual conditions that cannot be imagined. For example, the claim that Peter got the job because he is Peter implies a consideration of what would have happened if Peter was not Peter. Alternatively, the claim that Peter got the job because he is a man requires considering Peter as other than a man. The problem is that the counterfactuals in these cases imply a change not just in the condition facing an individual but in the individual themselves.\n\nTo avoid such problems, some statisticians urge a restriction of causal claims to treatments that can conceivably (not necessarily practically) be manipulated.3 For example, while we might have difficulties with the claim that Peter got the job because he was a man, we have no such difficulties with the claim that Peter got the job because the hiring agency thought he was a man.\n\n\n3. Causes are non-rival.\nEven though we may focus on the effect of a single cause \\(X\\) on an outcome \\(Y\\), we generally do not expect that there is ever only a single cause of \\(Y\\).4 Moreover, if you add up the causal effects of different causes, there is no reason to expect them to add up to 100%. Hence, there is not much point trying to “apportion” outcomes to different causal factors. In other words, causes are not rival. The National Rifle Association argues, for example, that guns don’t kill people, people kill people. That statement does not make much sense in the counterfactual framework. Take away guns and you have no deaths from gunshot wounds. So guns are a cause. Take away people and you also have no deaths from gunshot wounds, so people are also a cause. Put differently, these two factors are simultaneously causes of the same outcomes.\n\n\n4. \\(X\\) can cause \\(Y\\) even if \\(X\\) is not a necessary condition or a sufficient condition for \\(Y\\).\nWe often talk about causal relations in deterministic terms. Even the Lewis quote at the top of this page seems to suggest a deterministic relation between causes and effects. Sometimes causal relations are thought to entail necessary conditions (for \\(Y\\) to occur, \\(X\\) has to happen); sometimes such relations are thought to entail sufficient conditions (if \\(X\\) occurs, then \\(Y\\) occurs). But once we are talking about multiple units, there are at least two ways in which we can think of \\(X\\) causing \\(Y\\) even if \\(X\\) is neither a necessary nor a sufficient condition for \\(Y\\). The first is to reinterpret everything in probabilistic terms: by \\(X\\) causes \\(Y\\), we simply mean that the probability of \\(Y\\) is higher when \\(X\\) is present. Another is to allow for contingencies — for example, \\(X\\) may cause \\(Y\\) if condition \\(Z\\) is present, but not otherwise.5\n\n\n5. There is a fundamental problem of causal inference.\nIf causal effects are statements about the difference between what happened and what could have happened, then causal effects cannot be measured. That’s bad news. Prospectively, you can arrange things so that you can observe either what happens if someone gets a treatment or what happens if they do not get the treatment. Yet, for the same person, you will never be able to observe both of these outcomes and hence also not the difference between them. This inability to observe unit-level causal effects is often called the “fundamental problem of causal inference.”\n\n\n6. You can estimate average causal effects even though you cannot observe any individual causal effects.\nEven though you cannot observe whether \\(X\\) causes \\(Y\\) for any given unit, it can still be possible to figure out whether \\(X\\) causes \\(Y\\) on average. The key insight here is that the average causal effect equals the difference between the average outcome across all units if all units were in the control condition and the average outcome across all units if all units were in the treatment condition. Many strategies for causal identification (see 10 Strategies for Figuring Out If X Caused Y) focus on ways to learn about these average potential outcomes.6\n10 Things to Know About Hypothesis Testing describes how one can learn about individual causal effects rather than average causal effects given the fundamental problem of causal inference.\n\n\n7. Estimating average causal effects does not require that treatment and control groups are identical.\nOne strategy that people use to learn about average causal effects is to create treatment and control groups through randomization (see 10 Strategies for Figuring Out If X Caused Y). When doing so, researchers sometimes worry if they find that the resulting treatment and control groups do not look the same along relevant dimensions.\nThe good news is that the argument for why differences in average outcomes across randomly assigned treatment and control groups capture average treatment effects (in expectation across repeated randomizations within the same pool of units) does not rely on treatment and control groups being similar in their observed characteristics. It relies only on the idea that, on average, the outcomes in the treated and control groups will capture the average outcomes for all units in the experimental pool if they were, respectively, in treatment or in control. In practice actual treatment and control groups will not be identical.7\n\n\n8. Correlation is not causation.\nA correlation between \\(X\\) and \\(Y\\) is a statement about relations between actual outcomes in the world, not about the relation between actual outcomes and counterfactual outcomes. So statements about causes and correlations don’t have much to do with each other. Positive correlations can be consistent with positive causal effects, no causal effects, or even negative causal effects. For example taking cough medication is positively correlated with coughing but hopefully has a negative causal effect on coughing.8\n\n\n9. If you know that, on average, \\(A\\) causes \\(B\\) and \\(B\\) causes \\(C\\), this does not mean that, on average, \\(A\\) causes \\(C\\).\nYou might expect that if \\(A\\) causes \\(B\\) and \\(B\\) causes \\(C\\) that therefore \\(A\\) causes \\(C\\).9 But there is no reason to believe that average causal relations are transitive in this way. To see why, imagine \\(A\\) caused \\(B\\) for men but not women and \\(B\\) caused \\(C\\) for women but not men. Then on average \\(A\\) causes \\(B\\) and \\(B\\) causes \\(C\\) but there may still be no one for whom \\(A\\) causes \\(C\\) through \\(B\\).\n\n\n10. It’s easier to learn about the “effects of causes” than to learn about the “causes of effects.”\nThough it might sound like two ways of saying the same thing, there is a difference between understanding what the effect of \\(X\\) on \\(Y\\) is (the “effects of a cause”) and whether an outcome \\(Y\\) was due to cause \\(X\\) (the “cause of an effect”).10 Consider the following example. Suppose we run an experiment with a sample that contains an equal number of men and women. The experiment randomly assigns men and women to a binary treatment \\(X\\) and measures a binary outcome \\(Y\\). Further, suppose that \\(X\\) has a positive effect of 1 for all men, i.e. men’s control potential outcome is zero (\\(Y_i(0) = 0\\)) and their treated potential outcome is one (\\(Y_i(1) = 1\\)). For all women, \\(X\\) has a negative effect of \\(-1\\), i.e., women’s control potential outcome is one (\\(Y_i(0) = 1\\)) and their treated potential outcome is zero (\\(Y_i(1) = 0\\)). In this example, the average effect of \\(X\\) on \\(Y\\) is zero. But for all participants in the treatment group with \\(Y=1\\), it is the case that \\(Y=1\\) because \\(X=1\\). Similarly, for all participants in the treatment group with \\(Y=0\\), it is the case that \\(Y=0\\) because \\(X=1\\). Experimentation can get an exact answer to the question about the “effects of a cause”, but generally it is not possible to get an exact answer to the question about the “cause of an effect”.11\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Macartan Humphreys. Minor revisions: Winston Lin and Donald P. Green, 24 Jun 2016. Revisions MH 6 Jan 2020. Revisions Anna Wilke May 2021. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits.↩︎\nHolland, Paul W. “Statistics and causal inference.” Journal of the American Statistical Association 81.396 (1986): 945-960.↩︎\nHolland, Paul W. “Statistics and causal inference.” Journal of the American Statistical Association 81.396 (1986): 945-960.↩︎\nIn some accounts this has been called the “Problem of Profligate Causes”.↩︎\nFollowing Mackie, sometimes the idea of “INUS” conditions is invoked to capture the dependency of causes on other causes. Under this account, a cause may be an Insufficient but Necessary part of a condition which is itself Unnecessary but Sufficient. For example dialing a phone number is a cause of contacting someone since having a connection and dialing a number is sufficient (S) for making a phone call, whereas dialing alone without a connection alone would not be enough (I), nor would having a connection (N). There are of course other ways to contact someone without making phone calls (U). Mackie, John L. “The cement of the universe.” London: Oxford Uni (1974).↩︎\nTechnical Note: The key technical insight is that the difference of averages is the same as the average of differences. That is, using the “expectations operator,” \\(𝔼(τ_i)=𝔼(Y_i(1)−Y_i(0))=𝔼(Y_i(1))−𝔼(Y_i(0))\\). The terms inside the expectations operator in the second quantity cannot be estimated, but the terms inside the expectations operators in the third quantity can be.6 See illustration here.↩︎\nFor this reason \\(t\\)-tests to check whether “randomization worked” do not make much sense, at least if you know that a randomized procedure was followed — just by chance 1 in 20 such tests will show statistically detectable differences between treated and control groups. If there are doubts about whether a randomized procedure was correctly implemented these tests can be used to test the hypothesis that the data was indeed generated by a randomized procedure. This later reason for randomization tests can be especially important in field experiments where chains of communication from the person creating random numbers and the person implementing treatment assignment may be long and complex.↩︎\nTechnical Note: Let \\(D_i\\) be an indicator for whether unit \\(i\\) has received a treatment or not. Then the difference in average outcomes between those that receive the treatment and those that do not can be written as \\(\\frac{∑_i D_i×Y_i(1)}{∑_iD_i}−\\frac{∑_i (1−D_i)×Y_i(0)}{∑_i (1−D_i)}\\). In the absence of information about how treatment was assigned, we can say little about whether this difference is a good estimator of the average treatment effect, i.e., of the difference in average treated and control potential outcomes across all units. What matters is whether \\(\\frac{∑_i D_i×Y_i(1)}{∑_iD_i}\\) is a good estimate of \\(\\frac{∑_i 1×Y_i(1)}{∑_i1}\\) and whether \\(\\frac{∑_i (1−D_i)×Y_i(0)}{∑_i (1−D_i)}\\) is a good estimate of \\(\\frac{∑_i 1×Y_i(0)}{∑_i1}\\). This might be the case if those who received treatment are a representative sample of all units, but otherwise there is no reason to expect that it would be.↩︎\nInterpret “\\(A\\) causes \\(B\\), on average” as “the average effect of \\(A\\) on \\(B\\) is positive.”↩︎\nSome reinterpret the “causes of effects” question to mean: what are the causes that have effects on outcomes. See Andrew Gelman and Guido Imbens, “Why ask why? Forward causal inference and reverse causal questions”, NBER Working Paper No. 19614 (Nov. 2013).↩︎\nSee, for example, Tian, J., Pearl, J. 2000. “Probabilities of Causation: Bounds and Identification.” Annals of Mathematics and Artificial Intelligence 28:287–313.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EGAP Learning",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "guides/getting-started/causal-inference_esp.html",
    "href": "guides/getting-started/causal-inference_esp.html",
    "title": "10 cosas que debe saber sobre la inferencia causal",
    "section": "",
    "text": "Resumen\nEl filósofo David Lewis describió la causalidad como “algo que marca la diferencia, y esa diferencia que hace, debe ser la diferencia entre lo que fue y lo que hubiera sido sin ese algo”.1 Esta es la interpretación que dan a la causalidad la mayoría de los experimentalistas. Aunque la definición parece simple, tiene muchas implicaciones sutiles. Aquí les presentamos diez ideas implícitas en esta noción de causalidad que son importantes para el diseño de investigación.2\n\n\n1. Una afirmación causal es un enunciado sobre lo que no sucedió\nPara la mayoría de investigadores que realizan experimentos, el enunciado “\\(X\\) causó \\(Y\\)” significa que \\(Y\\) ocurrió y que no habría ocurrido si \\(X\\) no hubiera estado presente. Esta definición requiere que tengamos una noción de lo que podría haber sucedido, pero no sucedió.3 De manera similar, el “efecto” de \\(X\\) en \\(Y\\) se considera la diferencia entre el valor que \\(Y\\) habría tomado dado un valor de \\(X\\) y el valor que \\(Y\\) habría tomado dado otro valor de \\(X\\). Debido al enfoque en la diferencia de los resultados, este enfoque a veces se conoce como el enfoque de causalidad basado en “hacer diferencias” o en lo “contrafactual”.\nNota técnica: Los estadísticos emplean el marco de “resultados potenciales” para describir las relaciones contrafactuales. En este marco, dejamos que \\(Y_i(1)\\) denote el valor que la unidad \\(i\\) tomaría bajo la condición uno (por ejemplo, si la unidad \\(i\\) recibió un tratamiento) y \\(Y_i(0)\\) el valor que habría sido observado en otra condición (por ejemplo, si la unidad \\(i\\) no recibió el tratamiento). Un efecto causal del tratamiento para la unidad \\(i\\) puede ser una simple diferencia de los resultados potenciales \\(\\tau_i = Y_i(1)-Y_(0)\\). Un tratamiento tiene un efecto causal (positivo o negativo) en \\(Y\\) para la unidad \\(i\\) si \\(Y_i (1) \\neq Y_i (0)\\).\n\n\n2. No hay relación causal sin manipulación.\nLa definición “contrafactual” de causalidad requiere que uno sea capaz de pensar qué valores podemos observar en diferentes condiciones. ¿Cómo serían las cosas si se eligiera un partido en lugar de otro? Las declaraciones causales cotidianas a menudo no cumplen con este requisito en alguna de estas dos formas:\n\nPrimero, algunas declaraciones no especifican condiciones contrafactuales claras. Por ejemplo, la afirmación de que “la recesión fue causada por Wall Street” no apunta a un contrafactual obvio: ¿debemos considerar si habría habido una recesión si Wall Street no existiera? ¿O es la afirmación realmente una afirmación sobre acciones particulares que Wall Street podría haber tomado pero no lo hizo? Si es así, ¿qué acciones? Es difícil evaluar la validez de tales declaraciones. Además, puede depender de qué condiciones contrafactuales estén implícitas en una afirmación.\nEn segundo lugar, algunos enunciados implican condiciones contrafactuales que no son posibles de imaginar. Por ejemplo, la afirmación de que Peter consiguió el trabajo porque es Peter implica una consideración de lo que habría sucedido si Peter no fuera Peter. Alternativamente, la afirmación de que Peter consiguió el trabajo porque es un hombre requiere considerar a Peter como algo diferente de un hombre. El problema es que los contrafactuales en estos casos implican un cambio no solo en la condición que enfrenta un individuo sino en el propio individuo.\n\nPara evitar estos problemas, algunos estadísticos instan a restringir las afirmaciones causales a los tratamientos que pueden manipularse, al menos en la imaginación, y no necesariamente en la práctica.4 Por ejemplo, si bien podríamos tener dificultades con la afirmación de que Peter consiguió el trabajo porque es hombre, no tendríamos las mismas dificultades con la afirmación de que Peter consiguió el trabajo porque la agencia de contratación pensó que era hombre\n\n\n3. Las causas no tienen por qué ser rivales.\nAunque nos podemos centrar en el efecto de una sola causa \\(X\\) en un variable de resultado \\(Y\\), generalmente no esperamos que \\(Y\\) tenga solo una causa.5 Además, si sumamos los efectos causales de diferentes causas, no hay razón para esperar que sumen el 100%. Por lo tanto, no tiene mucho sentido tratar de “distribuir” los resultados entre diferentes factores causales. En otras palabras, las causas no tienen por qué ser rivales. La Asociación Nacional del Rifle de Estados Unidos sostiene, por ejemplo, que las armas no matan a la gente, la gente mata a la gente. Esa afirmación no tiene mucho sentido en el marco hipotético. Quita las armas y no tendrás muertes por heridas de bala. Entonces las armas son una causa. Quita a la gente y tampoco tendrás muertes por heridas de bala, por lo que las personas también son una causa. Dicho de otra manera, estos dos factores son simultáneamente causas de los mismos resultados.\n\n\n4. \\(X\\) puede causar \\(Y\\) incluso si \\(X\\) no es una condición necesaria o una condición suficiente para que \\(Y\\) ocurra.\nA menudo hablamos de relaciones causales en términos deterministas. Incluso la cita de Lewis en la parte superior de esta página parece sugerir una relación determinista entre causas y efectos. A veces se piensa que las relaciones causales implican condiciones necesarias (para \\(Y\\) que ocurra, \\(X\\) tiene que suceder ); a veces se piensa que tales relaciones implican condiciones suficientes (si ocurre \\(X\\), entonces ocurre \\(Y\\)). Pero una vez que hablamos de múltiples unidades, hay al menos dos formas en las que podemos pensar en que \\(X\\) causa \\(Y\\) incluso si \\(X\\) no es una condición necesaria ni suficiente para \\(Y.\\) La primera es reinterpretar todo en términos probabilísticos: que \\(X\\) cause \\(Y\\), simplemente quiere decir que la probabilidad de \\(Y\\) es mayor cuando \\(X\\) está presente. Otra forma es permitir contingencias. Por ejemplo, \\(X\\) puede causar \\(Y\\) si la condición \\(Z\\) está presente, pero no de otra manera.6\n\n\n5. Existe un problema fundamental de la inferencia causal\nSi los efectos causales son enunciados sobre la diferencia entre lo que sucedió y lo que podría haber sucedido, entonces no los podemos medir. Malas noticias. De manera prospectiva, puede organizar las cosas para que pueda observar lo que sucede si alguien recibe un tratamiento o lo que sucede si no recibe el tratamiento. Sin embargo, para la misma persona nunca podrá observar ambos resultados y, por lo tanto, tampoco la diferencia entre ellos. Esta incapacidad para observar efectos causales a nivel de la unidad de estudio a menudo se denomina “problema fundamental de la inferencia causal”.\n\n\n6. Usted puede estimar el efecto causal promedio aun cuando no pueda observar ningún efecto causal individual.\nAunque no pueda observar si \\(X\\) causa \\(Y\\) para una unidad determinada, sí es posible determinar si \\(X\\) causa \\(Y\\) en promedio. La idea clave aquí es que el efecto causal promedio es igual a la diferencia entre la variable de resultado promedio para todas las unidades, si todas están en la condición de control y la variable de resultado promedio para todas las unidades si todas están en la condición de tratamiento. Muchas estrategias para la identificación causal (ver 10 estrategias para determinar si X causó Y) se enfocan en formas de aprender acerca de estas resultados potenciales promedio.7\n10 cosas que debe saber sobre las pruebas de hipótesis nos muestra cómo podemos aprender acerca de efectos causales individuales en vez de efectos promediodato el problema fundamental de la inferencia causal.\n\n\n7. La estimación del efecto causal promedio no requiere que los grupos de tratamiento y control sean idénticos.\nUna estrategia que la gente usa para aprender acerca del efecto causal promedio es crear grupos de tratamiento y control a través de la aleatorización (ver 10 estrategias para determinar si X causó Y). Es común que algunos investigadores se preocupen por que los grupos de tratamiento y control resultantes no sean similares en dimensiones relevantes.\nLa buena noticia es que la razón por la cual las diferencias en los resultados promedio entre los grupos de control y tratamiento asignados aleatoriamente capturan los efectos promedio del tratamiento (en valor esperado a través de aleatorizaciones repetidas dentro del mismo grupo de unidades) no se basa en que los grupos de tratamiento y control sean similares en las características observadas. Sino que se basa únicamente en la idea de que, en promedio, los resultados en los grupos tratados y de control capturarán los resultados promedio para todas las unidades en el grupo experimental si estuvieran, respectivamente, en tratamiento o en control. En la práctica, los grupos de tratamiento y de control no serán idénticos.8\n\n\n8. Correlación no es igual a causalidad.\nUna correlación entre \\(X\\) y \\(Y\\) es un enunciado sobre las relaciones entre los valores reales de estas variables y no sobre la relación entre los valores reales y los valores contrafactuales. Entonces las afirmaciones sobre causas y correlaciones no tienen mucho que ver entre sí. Las correlaciones positivas pueden ser consistentes con efectos causales positivos, efectos causales nulos o incluso con efectos causales negativos. Por ejemplo, tomar medicamentos para la tos se correlaciona positivamente con la tos, pero es de esperar que tenga un efecto causal negativo sobre la tos.9\n\nSi usted sabe que, en promedio, \\(A\\) causa $ B $ y \\(B\\) causa \\(C\\), esto no significa que, en promedio, \\(A\\) cause \\(C\\).\n\n== Se podría esperar que si \\(A\\) causa \\(B\\) y \\(B\\) causa \\(C\\), entonces \\(A\\) causa \\(C\\).10 Pero no hay razón para creer que las relaciones causales promedio sean transitivas. Para entender por qué, imagine que \\(A\\) causó \\(B\\) en los hombres pero no en las mujeres y \\(B\\) causó \\(C\\) en las mujeres pero no en los hombres. Entonces, en promedio, \\(A\\) causa \\(B\\) y \\(B\\) causa \\(C\\), pero es posible que no haya nadie para quien \\(A\\) tenga un efecto en \\(C\\) mediado por \\(B\\).\n\n\n10. Es más fácil aprender sobre los “efectos de las causas” que aprender sobre las “causas de los efectos”.\nAunque puedan parecer dos formas de decir exactamente lo mismo, existe una diferencia entre comprender cuál es el efecto de \\(X\\) en \\(Y\\) (los “efectos de una causa”) y si el valor que tomó \\(Y\\) se debió a \\(X\\) (la “causa de un efecto”).11 Considere el siguiente ejemplo. Supongamos que realizamos un experimento con una muestra que contiene el mismo número de hombres y mujeres. El experimento asigna aleatoriamente a hombres y mujeres a un tratamiento binario \\(X\\) y mide una variable de resultado binaria \\(Y\\). Además suponga que \\(X\\) tiene un efecto positivo de 1 para todos los hombres, es decir, el resultado potencial del control de los hombres es cero (\\(Y_i(0) = 0\\)) y la salida potencial cuando son tratados es uno (\\(Y_i(1) = 1\\)). Para todas las mujeres, \\(X\\) tiene un efecto negativo de \\(-1\\), es decir, la salida potencial de las mujeres bajo el control es uno (\\(Y_i (0) = 1\\)) y su salida potencial cuando son tratadas es cero (\\(Y_i (1) = 0\\)) En este ejemplo, el efecto promedio de \\(X\\) en $ Y $ es cero. Pero la razón para que los participantes en el grupo de tratamiento tengan \\(Y= 1\\), es porque \\(X = 1\\). De manera similar, todos los participantes en el grupo de tratamiento con \\(Y = 0\\), tienen \\(Y = 0\\) porque \\(X = 1\\). Los experimentos nos permiten obtener una respuesta exacta a la pregunta sobre los “efectos de una causa”, pero en general no es posible obtener una respuesta exacta a la pregunta sobre la “causa de un efecto”.12\n\n\n\n\n\nFootnotes\n\n\nLewis, David. “Causation.” The journal of philosophy (1973): 556-567.↩︎\nAutor: Macartan Humphreys. Revisiones menores: Winston Lin y Donald P. Green, 24 de junio de 2016. Revisiones MH 6 de enero de 2020. Revisiones Anna Wilke de mayo de 2021. Esta guía es un documento dinámico y está sujeta a actualización por parte de los miembros de EGAP; los colaboradores enumerados no son responsables de las ediciones posteriores.↩︎\nHolland, Paul W. “Statistics and causal inference.” Journal of the American Statistical Association 81.396 (1986): 945-960.↩︎\nHolland, Paul W. “Statistics and causal inference.” Journal of the American Statistical Association 81.396 (1986): 945-960.↩︎\nEsto se conoce a veces como el “Problema de las causas excesivas”.↩︎\nDe acuerdo a Mackie, a veces se invoca la idea de condiciones “INUS” para capturar la dependencia de las causas de otras causas. Según esta explicación, una causa puede ser parte Insuficiente pero Necesaria de una condición que en sí misma es Innecesaria pero Suficiente. Por ejemplo, marcar un número de teléfono es una causa de contacto con alguien, ya que tener una conexión y marcar un número es suficiente (S) para hacer una llamada telefónica, mientras que marcar solo sin una conexión no sería suficiente (I), ni tener una conexión (N). Por supuesto, hay otras formas de contactar a alguien sin hacer llamadas telefónicas (U). Mackie, John L. “El cemento del universo”. Londres: Oxford Uni (1974).↩︎\nNota técnica: La idea técnica clave es que la diferencia de promedios es la misma que el promedio de diferencias. Es decir, usando el “operador de expectativas”, \\(\\text{E}(\\tau_i) = \\text{E}(Y_i (1) -Y_i (0)) = \\text{E}(Y_i (1)) - \\text{E}(Y_i (0))\\). Los términos dentro del operador de esperanzas en la segunda cantidad no se pueden estimar, pero los términos dentro de los operadores de expectativas en la tercera cantidad si se pueden ser estimados7 Vea la ilustración [aquí] (https://raw.githubusercontent.com/egap/ guías-métodos / maestro / inferencia-causal / PO.jpg).↩︎\nPor esta razón usar las pruebas \\(t\\) para verificar si “la asignación aleatoria funcionó bien” no tiene mucho sentido, al menos si se sabe que se siguió una procedimiento aleatorio: por simple chance, 1 de cada 20 de esas pruebas mostrará diferencias estadísticamente detectables entre los grupos tratados y de control. Si existen dudas sobre si la asignación aleatoria se realizó correctamente, estas pruebas se pueden utilizar para probar la hipótesis de que los datos se generaron efectivamente mediante un procedimiento aleatorio. Esta última razón para las pruebas de aleatorización puede ser especialmente importante en experimentos de campo donde las cadenas de comunicación entre la persona que crea los números aleatorios y la persona que implementa la asignación del tratamiento son largas y complejas.↩︎\nNota técnica: Sea \\(D_i\\) un indicador de si la unidad \\(i\\) ha recibido un tratamiento o no. Entonces la diferencia en los resultados promedio entre los que reciben el tratamiento y los que no lo reciben se puede escribir como \\(\\frac{\\sum_i D_i × Y_i (1)} {\\sum_iD_i} - \\frac {\\sum_i(1 - D_i) \\times Y_i (0)}{\\sum_i (1 - D_i)}\\). Sin información sobre cómo se asignó el tratamiento, no hay mucho por decir sobre si esta diferencia es un buen estimador del efecto promedio del tratamiento. Es decir, de la diferencia en los resultados potenciales promedio de las unidades en el grupo de tratamiento y control para todas las unidades. Lo que importa es si \\(\\frac{\\sum_i D_i × Y_i (1)} {\\sum_iD_i}\\) es una buena estimación de \\(\\frac{\\sum_i 1 × Y_i (1)} {\\sum_i1}\\) y si \\(\\frac{\\sum_i (1 - D_i) × Y_i (0)}{\\sum_i(1 - D_i)}\\) es una buena estimación de \\(\\frac{\\sum_i 1 × Y_i (0)} {\\sum_i1}\\). Este puede ser el caso si los que recibieron tratamiento son una muestra representativa de todas las unidades, pero de lo contrario no hay razón para esperar que así sea.↩︎\nEntiéndase la expresión “\\(A\\) causa \\(B\\), en promedio” como “el efecto promedio de \\(A\\) sobre \\(B\\) es positivo”.↩︎\nA veces se reinterpreta la pregunta “causas de los efectos” en el sentido de: ¿cuáles son las causas que tienen efectos sobre las variable de resultado? Véase Andrew Gelman and Guido Imbens, “Why ask why? Forward causal inference and reverse causal questions”, NBER Working Paper No. 19614 (Nov. 2013).↩︎\nVer, por ejemplo, Tian, J., Pearl, J. 2000. “Probabilities of Causation: Bounds and Identification.” Annals of Mathematics and Artificial Intelligence 28:287–313.↩︎"
  },
  {
    "objectID": "guides/getting-started/causal-inference_fr.html",
    "href": "guides/getting-started/causal-inference_fr.html",
    "title": "10 choses à savoir sur l’inférence causale",
    "section": "",
    "text": "Résumé\nLe philosophe David Lewis a décrit la causalité comme “quelque chose qui fait une différence, et cette différence doit être une différence par rapport à ce qui se serait passé sans elle”.1 Ceci est l’interprétation de la causalité pour la plupart des expérimentalistes. Même si la définition semble simple, elle a de nombreuses implications subtiles. Voici dix idées impliquées par cette notion de causalité qui importent pour la conception de recherche. 2\n\n\n1. Une assertion causale est une déclaration sur ce qui ne s’est pas produit.\nPour la plupart des expérimentalistes, la déclaration “\\(X\\) a causé \\(Y\\)” signifie que \\(Y\\) est présent et \\(Y\\) n’aurait pas été présent si \\(X\\) n’avait pas été présent. Cette définition requiert une notion de ce qui aurait pu arriver, mais ne s’est pas produit.3 De même, “l’effet” de \\(X\\) sur \\(Y\\) est la différence entre la valeur que \\(Y\\) aurait prise étant donné une valeur de \\(X\\) et la valeur que \\(Y\\) aurait prise étant donné une autre valeur de \\(X\\). En raison de l’accent mis sur les différences entre les résultats, cette approche est parfois appelée approche “des différences” ou “contrefactuelle” de la causalité.\nNote technique: Les statisticiens emploient le cadre des “résultats potentiels” pour décrire les relations contrefactuelles. Dans ce cadre, \\(Y_i(1)\\) désigne le résultat pour l’unité \\(i\\) qui serait observé sous une condition (par exemple, si l’unité \\(i\\) a reçu un traitement) et \\(Y_i(0)\\) désigne le résultat qui serait observé dans une autre condition (par exemple, si l’unité \\(i\\) n’a pas reçu le traitement). Un effet causal du traitement pour l’unité \\(i\\) pourrait être une simple différence des résultats potentiels \\(τ_i=Y_i(1)−Y_i(0)\\). Un traitement a un effet causal (positif ou négatif) sur \\(Y\\) pour l’unité \\(i\\) si \\(Y_i(1)≠Y_i(0)\\).\n\n\n2. Pas de causalité sans manipulation.\nLa définition “contrefactuelle” de la causalité exige que l’on soit capable de réfléchir aux résultats qui peuvent entraîner des conditions différentes. Quelle serait la situation si un parti plutôt qu’un autre était élu ? Les déclarations causales de tous les jours ne répondent souvent pas à cette exigence de l’une des deux manières suivantes.\n\nPremièrement, certaines déclarations ne précisent pas de conditions contrefactuelles claires. Par exemple, l’affirmation selon laquelle “la récession a été causée par Wall Street” n’indique pas de contrefactuel évident — devons-nous examiner s’il y aurait eu une récession si Wall Street n’avait pas existé ? Ou est-ce une déclaration sur des décisions particulières que Wall Street aurait pu prendre mais n’a pas prises ? Si oui, quelles décisions ? La validité de telles déclarations est difficile à évaluer et peut dépendre des conditions contrefactuelles impliquées par une déclaration.\nDeuxièmement, certaines déclarations impliquent des conditions contrefactuelles qui ne peuvent être imaginées. Par exemple, l’affirmation selon laquelle Peter a obtenu le poste parce qu’il est Peter implique une considération de ce qui se serait passé si Peter n’était pas Peter. Alternativement, l’affirmation selon laquelle Peter a obtenu le poste parce qu’il est un homme nécessite de considérer Peter comme autre qu’un homme. Le problème est que les contrefactuels dans ces cas impliquent un changement non seulement de la condition à laquelle fait face un individu, mais de l’individu lui-même.\n\nPour éviter de tels problèmes, certains statisticiens recommandent de restreindre les assertions causales aux traitements qui peuvent en théorie (pas nécessairement en pratique) être manipulés.4 Par exemple, alors que nous pourrions avoir des difficultés avec l’affirmation selon laquelle Peter a obtenu le poste parce qu’il était un homme, nous n’avons pas de telles difficultés avec l’affirmation selon laquelle Peter a obtenu le poste parce que l’agence de recrutement pensait qu’il était un homme.\n\n\n3. Les causes sont non rivales.\nMême si nous pouvons nous concentrer sur l’effet d’une seule cause \\(X\\) sur un résultat \\(Y\\), nous ne nous attendons généralement pas à ce qu’il n’y ait qu’une seule cause de \\(Y\\).5 De plus, si vous additionnez les effets causaux de différentes causes, il n’y a aucune raison de s’attendre à ce qu’ils totalisent 100 %. Par conséquent, il ne sert à rien d’essayer de “répartir” les résultats entre différents facteurs de causalité. En d’autres termes, les causes sont non rivales. La National Rifle Association soutient, par exemple, que les armes à feu ne tuent pas les gens, les gens tuent les gens. Cette déclaration n’a pas beaucoup de sens dans le cadre contrefactuel. Enlevez les armes à feu et vous n’aurez pas de morts par balles. Les armes à feu sont donc une cause. Enlevez les gens et vous n’aurez pas non plus de décès par balle, donc les gens sont aussi une cause. En d’autres termes, ces deux facteurs sont simultanément les causes des mêmes résultats.\n\n\n4. \\(X\\) peut causer \\(Y\\) même si \\(X\\) n’est pas une condition nécessaire ou une condition suffisante pour \\(Y\\).\nOn parle souvent des relations causales en termes déterministes. Même la citation de Lewis en haut de cette page semble suggérer une relation déterministe entre les causes et les effets. On pense parfois que les relations causales impliquent des conditions nécessaires (pour que \\(Y\\) se produise, \\(X\\) doit se produire); on pense parfois que de telles relations impliquent des conditions suffisantes (si \\(X\\) se produit, alors \\(Y\\) se produit). Mais une fois que nous parlons d’unités multiples, il y a au moins deux façons de penser que \\(X\\) cause \\(Y\\) même si \\(X\\) n’est ni une condition nécessaire ni une condition suffisante pour \\(Y\\). La première consiste à tout réinterpréter en termes probabilistes : par \\(X\\) cause \\(Y\\), on entend simplement que la probabilité de \\(Y\\) est plus élevée lorsque \\(X\\) est présent. Une autre consiste à tenir compte des contingences — par exemple, \\(X\\) peut causer \\(Y\\) si la condition \\(Z\\) est présente, mais pas dans le cas contraire.6\n\n\n5. Le problème fondamental de l’inférence causale.\nSi les effets causaux sont des déclarations sur la différence entre ce qui s’est produit et ce qui aurait pu se produire, alors les effets causaux ne peuvent pas être mesurés. Mauvaise nouvelle ! De manière prospective, vous pouvez organiser les choses de manière à observer ce qui se passe si une personne reçoit un traitement ou ce qui se passe si elle ne reçoit pas le traitement. Pourtant, pour la même personne, vous ne pourrez jamais observer ces deux résultats et leur différence. Cette incapacité à observer les effets causaux au niveau de l’unité est souvent appelée le “problème fondamental de l’inférence causale”.\n\n\n6. Vous pouvez estimer l’effet causal moyen même si vous ne pouvez observer aucun effet causal individuel.\nMême si vous ne pouvez pas observer si \\(X\\) cause \\(Y\\) pour une unité donnée, il est peut-être toujours possible de déterminer si \\(X\\) cause \\(Y\\) en moyenne. L’effet causal moyen est égal à la différence entre le résultat moyen pour toutes les unités si elles étaient toutes dans la condition de contrôle et le résultat moyen pour toutes les unités si elles étaient toutes dans la condition de traitement. De nombreuses stratégies d’identification causale (voir 10 stratégies pour déterminer si X a causé Y) se concentrent sur des façons d’en savoir plus sur ces résultats potentiels moyens.7\n10 choses à savoir sur les tests d’hypothèse décrit comment en savoir plus sur les effets causaux individuels plutôt que sur les effets causaux moyens étant donné le problème fondamental de l’inférence causale.\n\n\n7. L’estimation de l’effet causal moyen ne nécessite pas que les groupes de traitement et de contrôle soient identiques.\nUne stratégie que les gens utilisent pour en savoir plus sur l’effet causal moyen consiste à créer des groupes de traitement et de contrôle par randomisation (voir 10 Stratégies pour déterminer si X a causé Y). Ce faisant, les chercheurs s’inquiètent parfois s’ils constatent que les groupes de traitement et de contrôle qui en résultent ne sont pas comparables sur certaines dimensions importantes.\nLa bonne nouvelle est que l’argument expliquant pourquoi les différences dans les résultats moyens entre les groupes de traitement et de contrôle assignés de manière aléatoire capturent l’effet moyen du traitement (en espérance pour des randomisations répétées au sein du même groupe d’unités) ne repose pas sur le fait que les groupes de traitement et de contrôle ont des caractéristiques observées similaires. Il repose uniquement sur l’idée que, en moyenne, les résultats dans les groupes de traitement et de contrôle captureront les résultats moyens pour toutes les unités du groupe expérimental si elles étaient, respectivement, dans le traitement ou dans le contrôle. En pratique, les groupes de traitement et de contrôle réels ne seront pas identiques.8\n\n\n8. La corrélation n’est pas la causalité.\nUne corrélation entre \\(X\\) et \\(Y\\) est une déclaration sur les relations entre les résultats réels, et non sur la relation entre les résultats réels et les résultats contrefactuels. Ainsi, les déclarations sur les causes et les corrélations n’ont pas grand-chose à voir les unes avec les autres. Des corrélations positives peuvent être cohérentes avec des effets causaux positifs, aucun effet causal ou même des effets causaux négatifs. Par exemple, la prise de médicaments contre la toux est positivement corrélée à la toux mais a, espérons-le, un effet causal négatif sur la toux.9\n\n\n9. Si vous savez qu’en moyenne \\(A\\) cause \\(B\\) et \\(B\\) cause \\(C\\), cela ne veut pas dire qu’en moyenne \\(A\\) cause \\(C\\).\nVous pourriez vous attendre à ce que si \\(A\\) cause \\(B\\) et \\(B\\) cause \\(C\\), alors \\(A\\) cause \\(C\\).10 Mais il n’y a aucune raison que les relations causales moyennes soient transitives. Imaginez que \\(A\\) cause \\(B\\) pour les hommes mais pas les femmes et \\(B\\) cause \\(C\\) pour les femmes mais pas les hommes. Ensuite, en moyenne, \\(A\\) cause \\(B\\) et \\(B\\) cause \\(C\\), mais \\(A\\) ne cause pas \\(C\\) à travers \\(B\\).\n\n\n10. Il est plus facile d’en apprendre davantage sur les “effets des causes” que sur les “causes des effets”.\nBien que cela puisse sembler être deux façons de dire la même chose, il y a une différence entre comprendre quel est l’effet de \\(X\\) sur \\(Y\\) (les “effets d’une cause”) et si un résultat \\(Y\\) était dû à une cause \\(X\\) (la “cause d’un effet”).11 Considérez l’exemple suivant. Supposons que nous menions une expérience avec un échantillon qui contient un nombre égal d’hommes et de femmes. L’expérience assigne de manière aléatoire des hommes et des femmes à un traitement binaire \\(X\\) et mesure un résultat binaire \\(Y\\). De plus, supposons que \\(X\\) ait un effet positif de 1 pour tous les hommes, c’est-à-dire le résultat potentiel de contrôle des hommes est de zéro, \\(Y_i(0) = 0\\), et leur résultat potentiel traité est de un, \\(Y_i(1) = 1\\). Pour toutes les femmes, \\(X\\) a un effet négatif de \\(-1\\), c’est-à-dire que le résultat potentiel de contrôle des femmes est de un, \\(Y_i(0) = 1\\), et leur résultat potentiel traité est de zéro, \\(Y_i(1) = 0\\). Dans cet exemple, l’effet moyen de \\(X\\) sur \\(Y\\) est nul. Mais pour tous les participants du groupe de traitement avec \\(Y=1\\), il est vrai que \\(Y=1\\) car \\(X=1\\). De même, pour tous les participants du groupe de traitement avec \\(Y=0\\), il est vrai que \\(Y=0\\) car \\(X=1\\). L’expérimentation peut obtenir une réponse exacte à la question sur les “effets d’une cause”, mais il n’est généralement pas possible d’obtenir une réponse exacte à la question sur la “cause d’un effet”.12\n\n\n\n\n\nFootnotes\n\n\nLewis, David. “Causation.” The journal of philosophy (1973): 556-567.↩︎\nAuteur d’origine : Macartan Humphreys. Révisions mineures : Winston Lin et Donald P. Green, 24 juin 2016. Révisions MH 6 janvier 2020. Révisions Anna Wilke mai 2021. Le guide est un document vivant et peut être mis à jour par les membres de EGAP à tout moment ; les contributeurs répertoriés ne sont pas responsables des modifications ultérieures.↩︎\nHolland, Paul W. “Statistics and causal inference.” Journal of the American Statistical Association 81.396 (1986): 945-960.↩︎\nHolland, Paul W. “Statistics and causal inference.” Journal of the American Statistical Association 81.396 (1986): 945-960.↩︎\nCertains appellent cela le “problème des causes de prodigalité”.↩︎\nMackie a présenté l’idée de conditions dites “INSS” (“INUS” en anglais) pour capturer la dépendance des causes sur d’autres causes. Une cause peut être une partie Insuffisante mais Nécessaire d’une condition qui est elle-même Superflue mais Suffisante. Par exemple, composer un numéro de téléphone est une cause de “contacter quelqu’un” car avoir une connexion et composer un numéro est suffisant (S) pour passer un appel téléphonique, alors que composer seul sans connexion ne suffirait pas (I), ni avoir un connexion (N). Il existe bien sûr d’autres moyens de contacter quelqu’un sans passer d’appels téléphoniques (S). Mackie, John L. “The cement of the universe.” London: Oxford Uni (1974).↩︎\nNote technique : La principale idée technique est que la différence des moyennes est la même que la moyenne des différences. C’est-à-dire, en utilisant “l’opérateur d’espérance”, \\(𝔼(τ_i)=𝔼(Y_i(1)−Y_i(0))=𝔼(Y_i(1))−𝔼(Y_i(0))\\). Les termes à l’intérieur de l’opérateur d’espérance dans la deuxième quantité ne peuvent pas être estimés, mais les termes à l’intérieur de l’opérateur d’espérance dans la troisième quantité peuvent l’être.7Voir l’illustration ici.↩︎\nPour cette raison, les tests-\\(t\\) pour vérifier si “la randomisation a fonctionné” n’ont pas beaucoup de sens, du moins si vous savez qu’une procédure randomisée a été suivie — simplement par hasard, 1 test sur 20 montrera des différences statistiquement détectables entre les groupes de traitement et de contrôle. En cas de doute sur la mise en œuvre correcte d’une procédure randomisée, ces tests peuvent être utilisés pour tester l’hypothèse selon laquelle les données ont bien été générées par une procédure randomisée. Ces tests peuvent alors être particulièrement importants pour des expériences de terrain où les chaînes de communication entre la personne randomisant et la personne mettant en œuvre l’assignation du traitement peuvent être longues et complexes.↩︎\nNote technique: soit \\(D_i\\) un indicateur pour savoir si l’unité \\(i\\) a reçu un traitement ou non. Alors, la différence des résultats moyens entre ceux qui reçoivent le traitement et ceux qui ne le reçoivent pas peut s’écrire \\(\\frac{∑_i D_i×Y_i(1)}{∑_iD_i}−\\frac{∑_i (1−D_i)× Y_i(0)}{∑_i (1−D_i)}\\). En l’absence d’informations sur la manière dont le traitement a été assigné, nous ne pouvons pas dire si cette différence est un bon estimateur de l’effet moyen du traitement, c’est-à-dire de la différence entre les résultats potentiels moyens pour les groupes de traitement et de contrôle pour toutes les unités. Ce qui importe est de savoir si \\(\\frac{∑_i D_i×Y_i(1)}{∑_iD_i}\\) est une bonne estimation de \\(\\frac{∑_i 1×Y_i(1)}{∑_i1}\\) et si \\(\\frac {∑_i (1−D_i)×Y_i(0)}{∑_i (1−D_i)}\\) est une bonne estimation de \\(\\frac{∑_i 1×Y_i(0)}{∑_i1}\\). Cela pourrait être le cas si ceux qui ont reçu un traitement sont un échantillon représentatif de toutes les unités, mais sinon il n’y a aucune raison de s’attendre à ce qu’il le soit.↩︎\nInterprétez “\\(A\\) cause \\(B\\), en moyenne” comme “l’effet moyen de \\(A\\) sur \\(B\\) est positif”.↩︎\nCertains réinterprètent la question des “causes des effets” comme suit : quelles sont les causes qui ont des effets sur les résultats. Voir Andrew Gelman and Guido Imbens, “Why ask why? Forward causal inference and reverse causal questions”, NBER Working Paper No. 19614 (Nov. 2013).↩︎\nVoir, par exemple, Tian, J., Pearl, J. 2000. “Probabilities of Causation: Bounds and Identification.” Annals of Mathematics and Artificial Intelligence 28:287–313.↩︎"
  },
  {
    "objectID": "guides/getting-started/covariates_en.html",
    "href": "guides/getting-started/covariates_en.html",
    "title": "10 Things to Know About Covariate Adjustment",
    "section": "",
    "text": "Abstract\nThis guide1 will help you think through when it makes sense to try to “control for other things” when estimating treatment effects using experimental data. We focus on the big ideas and provide examples in R.\n\n\n1 What is covariate adjustment?\n“Covariates” are baseline characteristics of your experimental subjects. When you run an experiment, you are primarily interested in collecting data on outcome variables that your intervention may affect, e.g. expenditure decisions, attitudes toward democracy, or contributions for a public good in a lab experiment. But it’s also a good idea to collect data on baseline characteristics of subjects before treatment assignment occurs, e.g. gender, level of education, or ethnic group. If you do this you can explore how treatment effects vary with these characteristics (see 10 Things to Know About Heterogeneous Treatment Effects). But doing this also lets you perform covariate adjustment.\nCovariate adjustment is another name for controlling for baseline variables when estimating treatment effects. Often this is done to improve precision. Subjects’ outcomes are likely to have some correlation with variables that can be measured before random assignment. Accounting for variables like gender will allow you to set aside the variation in outcomes that is predicted by these baseline variables, so that you can isolate the effect of treatment on outcomes with greater precision and power.\nCovariate adjustment can be a cheaper route to improved precision than increasing the number of subjects in the experiment. Partly for that reason, researchers often collect extensive data on covariates before random assignment. Pre-tests (measures that are analogous to the outcome variable but are restricted to time periods before random assignment) may be especially valuable for predicting outcomes, and baseline surveys can ask subjects about other background characteristics.\n\n\n2 Controlling for covariates at the design stage (blocking)\nThe best way to control for covariates is to use block randomization to do it at the design stage even before you start your experiment. Block randomization enables you to create treatment and control groups that are balanced on certain covariates. For example, you might expect that gender and income help predict the outcome variable. Block randomization can ensure that the treatment and control groups have equal proportions of female/high-income, female/low-income, male/high-income, and male/low-income populations. When the blocking variables help predict outcomes, blocking improves precision by preventing chance correlations between treatment assignment and baseline covariates.\nFor more information on blocking and how to implement it in R, see 10 Things You Need to Know About Randomization. The precision gains from blocking (relative to covariate adjustment without blocking) tend to be greatest when sample sizes are small.2\nWhen blocking is done to improve precision, estimated standard errors should take the blocking into account. (Otherwise, the SEs will tend to be conservative because they won’t give you credit for the precision improvement that blocking achieved.) One simple and commonly used method is to regress the outcome on the treatment assignment dummy variable as well as block dummies. When the probability of assignment to treatment is constant across blocks, including the block dummies in the regression doesn’t change the estimated treatment effect, but tends to give a more accurate estimate of the SE.3\nIf the probability of assignment to treatment varies by block, then you need to control for these unequal probabilities in order to get unbiased estimates of average treatment effects. 10 Things You Need to Know About Randomization discusses ways to do this.\n\n\n3 How to do it in a regression\nSometimes you do not have the opportunity to implement a blocked experimental design (for example, if you join a project after random assignment occurs) or you would prefer to simplify your randomization scheme to reduce opportunities for administrative error. You can still adjust for covariates on the back end by using multiple regression. Remember that in a bivariate regression—when you regress your outcome on just your treatment indicator—the coefficient on treatment is just a difference-in-means. This simple method gives an unbiased estimate of the average treatment effect (ATE). When we add baseline covariates that are correlated with outcomes to the model, the coefficient on treatment is an approximately unbiased estimate of the ATE that tends to be more precise than bivariate regression.\nTo adjust for covariates through multiple regression, use the model:\n\\[Y_i = \\alpha + \\beta Z_i + \\gamma X_i + \\epsilon_i\\]\nwhere \\(Y_i\\) is the outcome variable, \\(Z_i\\) is the treatment indicator, and \\(X_i\\) is a vector of one or more covariates. The remainder \\(\\epsilon_i\\) is your disturbance term—the leftover unexplained noise.\nWhen the treatment and control groups are of unequal size, the precision gains from covariate adjustment may be greater if you include interactions between treatment and the covariates (see this blog post for more discussion). For ease of interpretation, recenter the covariates to have zero mean:\n\\[Y_i = \\alpha + \\beta Z_i + \\gamma W_i + \\delta Z_i*W_i + \\epsilon_i\\]\nwhere \\(W_i = X_i - \\overline{X}\\) and \\(\\overline{X}\\) is the mean value of \\(X_i\\) for the entire sample.\nIf subjects receive different probabilities of assignment to treatment based on their covariates, then our estimation method needs to account for this (again, see 10 Things You Need to Know About Randomization for details).\n\n\n4 Why to do it\nIt isn’t absolutely necessary to control for covariates when estimating the average treatment effect in an RCT that assigns every subject the same probability of receiving the treatment. The unadjusted treatment–control difference in mean outcomes is an unbiased estimator of the ATE. However, covariate adjustment tends to improve precision if the covariates are good predictors of the outcome.4\nIn large samples, random assignment tends to produce treatment and control groups with similar baseline characteristics. Still, by the “luck of the draw,” one group may be slightly more educated, or one group may have slightly higher voting rates in previous elections, or one group may be slightly older on average. For this reason, the estimated ATE is subject to “sampling variability,” meaning you’ll get estimates of the ATE that were produced by an unbiased method but happened to miss the mark.5 A high sampling variability contributes to noise (imprecision), not bias.\nControlling for these covariates tends to improve precision if the covariates are predictive of potential outcomes. Take a look at the following example, which is loosely based on the Giné and Mansuri experiment on female voting behavior in Pakistan.6 In this experiment, the authors randomized an information campaign to women in Pakistan to study its effects on their turnout behavior, the independence of their candidate choice, and their political knowledge. They carried out a baseline survey which provided them with several covariates.\nThe following code imitates this experiment by creating fake data for four of the covariates they collect: whether the woman owns an identification card, whether the woman has formal schooling, the woman’s age, and whether the woman has access to TV. It also creates two potential outcomes (the outcomes that would occur if she were assigned to treatment and if not) for a measure of the extent to which a woman’s choice of candidate was independent of the opinions of the men in her family. The potential outcomes are correlated with all four covariates, and the built-in “true” treatment effect on the independence measure here is 1. To figure out whether our estimator is biased or not, we simulate 10,000 replications of our experiment. On each replication, we randomly assign treatment and then regress the observed outcome \\(Y\\) on the treatment indicator \\(Z\\), with and without controlling for covariates. Thus, we are simulating two methods (unadjusted and covariate-adjusted) for estimating the ATE. To estimate the bias of each method, we take the difference between the average of the 10,000 simulated estimates and the “true” treatment effect.\n\nrm(list=ls())\nset.seed(20140714)\nN = 2000\nN.treated = 1000\nReplications = 10000\ntrue.treatment.effect = 1\n# Create pre-treatment covariates\nowns.id.card = rbinom(n = N, size = 1, prob = .18)\nhas.formal.schooling = rbinom(n = N, size = 1, prob = .6)\nage = round(rnorm(n = N, mean = 37, sd = 16))\nage[age<18] = 18\nage[age>65] = 65\nTV.access = rbinom(n = N, size = 1, prob = .7)\nepsilon = rnorm(n = N, mean = 0, sd = 2)\n# Create potential outcomes correlated with pre-treatment covariates\nY0 = round(owns.id.card + 2*has.formal.schooling + 3*TV.access + log(age) + epsilon)\nY1 = Y0 + true.treatment.effect\n# Assign treatment repeatedly\nZ.mat = replicate(Replications, ifelse(1:N %in% sample(1:N, N.treated), 1, 0))\n# Generate observed outcomes\nY.mat = Y1 * Z.mat + Y0 * (1 - Z.mat)\ndiff.in.means = function(Y, Z) {\n  coef(lm(Y ~ Z))[2]\n}\nols.adjust = function(Y, Z) {\n  coef(lm(Y ~ Z + owns.id.card + has.formal.schooling + age + TV.access))[2]\n}\nunadjusted.estimates = rep(NA, Replications)\nadjusted.estimates   = rep(NA, Replications)\nfor (i in 1:Replications) {\n  unadjusted.estimates[i]  =  diff.in.means(Y.mat[,i], Z.mat[,i])\n  adjusted.estimates[i]    =  ols.adjust(Y.mat[,i], Z.mat[,i])\n}\n# Estimated variability (standard deviation) of each estimator\nsd.of.unadj = sd(unadjusted.estimates)\nsd.of.unadj\nsd.of.adj   = sd(adjusted.estimates)\nsd.of.adj\n# Estimated bias of each estimator\nmean(unadjusted.estimates) - true.treatment.effect\nmean(adjusted.estimates) - true.treatment.effect\n# Margin of error (at 95% confidence level) for each estimated bias\n1.96 * sd.of.unadj / sqrt(Replications)\n1.96 * sd.of.adj   / sqrt(Replications)\n\nBoth methods—with and without covariates—yield the true treatment effect of 1 on average. When we ran the regression without covariates, our estimated ATE averaged 1.0008 across the 10,000 replications, and with covariates, it averaged 1.0003. Notice that the regression-adjusted estimate is essentially unbiased even though our regression model is misspecified—we control for age linearly when the true data generating process involves the log of age.7\nThe real gains come in the precision of our estimates. The standard error (the standard deviation of the sampling distribution) of our estimated ATE when we ignore covariates is 0.121. When we include covariates in the model, our estimate becomes a bit tighter: the standard error is 0.093. Because our covariates were prognostic of our outcome, including them in the regression explained some noise in our data so that we could tighten our estimate of ATE.\n\n\n5 When will it help?\nWhen is adjusting for covariates most likely to improve precision?\nCovariate adjustment will be most helpful when your covariates are strongly predictive (or “prognostic”) of your outcomes. Covariate adjustment essentially enables you to make use of information about relationships between baseline characteristics and your outcome so that you can better identify the relationship between treatment and the outcome. But if the baseline characteristics are only weakly correlated with the outcome, covariate adjustment won’t do you much good. The covariates you will want to adjust for are the ones that are strongly correlated with outcomes.\nThe following graph demonstrates the relationship between how prognostic your covariate is and the gains you get from adjusting for it. On the x-axis is the sample size, and on the y-axis is the root mean squared error (RMSE), the square root of the average squared difference between the estimator and the true ATE. We want our RMSE to be small, and covariate adjustment should help us reduce it.\n\nrm(list=ls())\nlibrary(MASS)  # for mvrnorm()\nset.seed(1234567)\nnum.reps = 10000\n# True treatment effect is 0 for every unit\nadj.est = function(n, cov.matrix, treated) {\n    Y.and.X  =  mvrnorm(n, mu = c(0, 0), Sigma = cov.matrix)\n    Y   =  Y.and.X[, 1]  \n    X   =  Y.and.X[, 2]\n    coef(lm(Y ~ treated + X))[2]\n}\nunadj.est = function(n, treated) {\n    Y = rnorm(n)\n    coef(lm(Y ~ treated))[2]\n}\nrmse = function(half.n, rho = 0, control = TRUE) {\n    treated  =  rep(c(0, 1), half.n)\n    n = 2 * half.n\n    if (control) {\n        cov.matrix  =  matrix(c(1, rho, rho, 1), nrow = 2, ncol = 2)\n        return( sqrt(mean(replicate(num.reps, adj.est(n, cov.matrix, treated)) ^ 2)) )\n    }\n    else {\n        return( sqrt(mean(replicate(num.reps, unadj.est(n, treated)) ^ 2)) )\n    }\n}\nhalf.n = c(5, 7, 11, 19, 35, 67, 131)\nn = 2 * half.n \nE  = sapply(half.n, rmse, control = FALSE)\nE0 = sapply(half.n, rmse, rho = 0)\nE1 = sapply(half.n, rmse, rho = 0.5)\nE2 = sapply(half.n, rmse, rho = 0.9)\nplot(n, E, type = \"l\", ylab = \"RMSE\", xlim = c(min(n),max(n)), ylim = c(0,.75))\nlines(n, E0, col = \"yellow\")\nlines(n, E1, col = \"orange\")\nlines(n, E2, col = \"red\")\nlegend(x = 'topright',\n       c(\"No controls\",\n         expression(paste(rho, \"=0\")), expression(paste(rho, \"=0.5\")),\n         expression(paste(rho, \"=0.9\"))),\n         col=c(\"black\", \"yellow\",\"orange\", \"red\"), lty = 1, lwd=2)\n\n\nThe black line shows the RMSE when we don’t adjust for a covariate. The red line shows the RMSE when we adjust for a highly prognostic covariate (the correlation between the covariate and the outcome is 0.9). You can see that the red line is always below the black line, which is to say that the RMSE is lower when you adjust for a prognostic covariate. The orange line represents the RMSE when we adjust for a moderately prognostic covariate (the correlation between the covariate and the outcome is 0.5). We still are getting gains in precision relative to the black line, but not nearly as much as we did with the red line. Finally, the yellow line shows what happens if you control for a covariate that is not at all predictive of the outcome. The yellow line is almost identical to the black line. You received no improvement in precision by controlling for a non-prognostic covariate; in fact, you paid a slight penalty because you wasted a degree of freedom, which is especially costly when the sample size is small. This exercise demonstrates that you’ll get the most gains in precision by controlling for covariates that strongly predict outcomes.\nHow can you know which covariates are likely to be prognostic before launching your experiment? Prior experiments or even observational studies can offer guidance about which baseline characteristics best predict outcomes.\n\n\n6 Control for prognostic covariates regardless of whether they show imbalances\nCovariates should generally be chosen on the basis of their expected ability to help predict outcomes, regardless of whether they show “imbalances” (i.e., regardless of whether there are any noteworthy differences between the treatment group and control group in average values or other aspects of covariate distributions). There are two reasons for this recommendation:\n\nFrequentist statistical inference (standard errors, confidence intervals, p-values, etc.) assumes that the analysis follows a pre-specified strategy. Choosing covariates on the basis of observed imbalances makes it more difficult to obtain inferences that reflect your actual strategy. For example, suppose you choose not to control for gender because the treatment and control groups have similar gender composition, but you would have controlled for gender if there’d been a noticeable imbalance. Typical methods for estimating standard errors will incorrectly assume that you’d never control for gender no matter how much imbalance you saw.\nAdjusting for a highly prognostic covariate tends to improve precision, as we explained above. To receive due credit for this precision improvement, you should adjust for the covariate even if there’s no imbalance. For example, suppose gender is highly correlated with your outcome, but it happens that the treatment group and control group have exactly the same gender composition. In this case, the unadjusted estimate of the ATE will be exactly the same as the adjusted estimate from a regression of the outcome on treatment and gender, but their standard errors will differ. The SE of the unadjusted estimate tends to be larger because it assumes that even if the treatment and control groups had very different gender compositions, you’d still use the unadjusted treatment–control difference in mean outcomes (which would likely be far from the true ATE in that case). If you pre-specify that you’ll adjust for gender regardless of how much or how little imbalance you see, you’ll tend to get smaller SEs, tighter confidence intervals, and more powerful significance tests.\n\nAssuming that random assignment was implemented correctly, should examination of imbalances play any role in choosing which covariates to adjust for? Here’s a sampling of views:\n\nMutz, Pemantle, and Pham (2016) argue that, unless there is differential attrition, the practice of selecting covariates on the basis of observed imbalances is “not only unnecessary” but “not even helpful … and may in fact be damaging,” because it invalidates confidence intervals, worsens precision (relative to pre-specified adjustment for prognostic covariates), and opens the door to fishing.8\nPermutt (1990), using theory and simulations to study specific scenarios, finds that when a balance test is used to decide whether to adjust for a covariate, the significance test for the treatment effect is conservative (i.e., it has a true Type I error probability below its nominal level). He writes, “Greater power can be achieved by always adjusting for a covariate that is highly correlated with the response regardless of its distribution between groups.” However, he doesn’t completely rule out considering observed imbalances: “Choosing covariates on the basis of the difference between the means in the treatment and control groups is not irrational. After all, some type I errors may be more serious than others. Reporting a significant difference in outcome which can be explained away as the effect of a covariate may be a more embarrassing error than reporting one that happens to go away on replication but without an easy explanation. Similar considerations may apply to type II errors. A positive result that depends on adjustment for a covariate may be seen as less convincing than a positive two-sample test anyway, so that the error of failing to draw such a positive conclusion may be less serious. These justifications, however, come from outside the formal theory of testing hypotheses.”9\nAltman (2005) writes, “It seems far preferable to choose which variables to adjust for without regard to the actual data set to hand.” He recommends controlling for highly prognostic covariates, as well as any that were used in blocking. However, he also discusses a dilemma: “In practice, imbalance may arise when the possible need for adjustment has not been anticipated. What should the researchers do? They might choose to ignore the imbalance; as noted, this would be entirely proper. The difficulty then is one of credibility. Readers of their paper (including reviewers and editors) may question whether the observed finding has been influenced by the unequal distribution of one or more baseline covariates. It is still possible, and arguably advisable, to carry out an adjusted analysis, but now with the explicit acknowledgment that this is an exploratory rather than definitive analysis, and that the unadjusted analysis should be taken as the primary one. Obviously, if the simple and adjusted analyses yield substantially the same result, then there is no difficulty of interpretation. This will usually be the case. However, if the results of the two analyses differ, then there is a real problem. The existence of such a discrepancy must cast some doubt on the veracity of the overall (unadjusted) result. The situation is similar to the difficulties of interpretation that arise with unplanned subgroup comparisons. One suggestion in such circumstances is to try to mimic what would have been done if the problem had been anticipated, namely to adjust not for variables that are observed to be unbalanced, but for all variables that would have been identified in advance as prognostic. An independent source could be used to identify such variables. Alternatively, the trial data could be used to determine which variables are prognostic. This strategy too could be prespecified in the study protocol. Because this analysis would be performed conditionally on the observed imbalance, it does not remove bias and thus cannot be considered fully satisfactory.”10\nTukey (1991) notes that observed imbalances may justify adjustment as a robustness check: Although “most statisticians” would accept an analysis of a randomized clinical trial that doesn’t adjust for covariates, “Some clinicians, and some statisticians it would seem, would like to be more sceptical, (perhaps as a supplemental analysis) asking for an analysis that takes account of observed imbalances in these recorded covariates. Feeling more secure about the results of such an analysis is indeed appropriate, since the degree of protection against either the consequences of inadequate randomization or the (random) occurrence of an unusual randomization is considerably increased by adjustment. Greater security, rather than increased precision … will often be the basic reason for covariance adjustment in a randomized trial. … The main purpose of allowing [adjusting] for covariates in a randomized trial is defensive: to make it clear that analysis has met its scientific obligations.”11\nSome statisticians argue that our inferences should be conditional on a measure of covariate imbalance—in other words, when assessing the bias, variance, and mean squared error of a point estimate or the coverage probability of a confidence interval, instead of considering all possible randomizations, it may be more relevant to consider only those randomizations that would yield a covariate imbalance similar to the one we observe. From this perspective, observed imbalances may be relevant to the choice of estimator.12\nLin, Green, and Coppock (2016) write: “Covariates should generally be chosen on the basis of their expected ability to help predict outcomes, regardless of whether they appear well-balanced or imbalanced across treatment arms. But there may be occasions when the covariate list specified in the PAP [pre-analysis plan] omitted a potentially important covariate (due to either an oversight or the need to keep the list short when N is small) with a nontrivial imbalance. Protection against ex post bias (conditional on the observed imbalance) is then a legitimate concern.” However, they recommend that if observed imbalances are allowed to influence the choice of covariates, “the balance checks and decisions about adjustment should be finalized before we see unblinded outcome data,” “the direction of the observed imbalance (e.g., whether the treatment group or the control group appears more advantaged at baseline) should not be allowed to influence decisions about adjustment,” and the originally pre-specified estimator should “always be reported and labeled as such, even if alternative estimates are also reported.”13\n\n\n\n7 When not to do it\nIt is a bad idea to adjust for covariates when you think those covariates could have been influenced by your treatment. This is one of the reasons that many covariates are collected from baseline surveys; sometimes covariates that are collected from surveys after intervention could reflect the effects of the treatment rather than underlying characteristics of the subject. Adjusting for covariates that are affected by the treatment—“post-treatment” covariates—can cause bias.\nSuppose, for example, that Giné and Mansuri had collected data on how many political rallies a woman attended after receiving the treatment. In estimating the treatment effect on independence of political choice, you may be tempted to include this variable as a covariate in your regression. But including this variable, even if it strongly predicts the outcome, may distort the estimated effect of the treatment.\nLet’s create this fake variable, which is correlated (like the outcome measure) with baseline covariates and also with treatment. Here, by construction, the treatment effect on number of political rallies attended is 2. When we included the rallies variable as a covariate, the estimated average treatment effect on independence of candidate choice averaged 0.54 across the 10,000 replications. Recall that the true treatment effect on this outcome is 1. This is severe bias, all because we controlled for a post-treatment covariate!14 This bias results from the fact that the covariate is correlated with treatment.\n\n# Create post-treatment covariate that's correlated with pre-treatment covariates\nrallies0 = round(.5*owns.id.card + has.formal.schooling + 1.5*TV.access + log(age))\nrallies1 = rallies0 + 2\nrallies.mat = rallies1 * Z.mat + rallies0 * (1-Z.mat)\n \n# Estimate ATE with new model that includes the post-treatment covariate\nadjust.for.post = function(Y, Z, X) {\n  coef(lm(Y ~ Z + X + owns.id.card + has.formal.schooling + age + TV.access))[2]\n}\npost.adjusted.estimates = rep(NA, Replications)\nfor (i in 1:Replications) {\n  post.adjusted.estimates[i]  =  adjust.for.post(Y.mat[,i], Z.mat[,i], rallies.mat[,i])\n}\n# Estimated bias of the new estimator\nmean(post.adjusted.estimates) - true.treatment.effect\n# Margin of error (at 95% confidence level) for the estimated bias\n1.96 * sd(post.adjusted.estimates) / sqrt(Replications)\n\nJust because you should not adjust for post-treatment covariates does not mean you cannot collect covariate data post-treatment, but you must exercise caution. Some measures could be collected post-treatment but are unlikely to be affected by treatment (e.g., age and gender). Be careful about measures that may be subject to evaluation-driven effects, though: for example, treated women may be more acutely aware of the expectation of political participation and may retrospectively report that they were more politically active than they actually were several years prior.\n\n\n8 Concerns about small-sample bias\nIn small samples, regression adjustment may produce a biased estimate of the average treatment effect.15 Some simulations have suggested that this bias tends to be negligible when the number of randomly assigned units is greater than twenty.16 If you’re working with a small sample, you may want to use an unbiased covariate adjustment method such as post-stratification (splitting the sample into subgroups based on the values of one or more baseline covariates, computing the treatment–control difference in mean outcomes for each subgroup, and taking a weighted average of these subgroup-specific treatment effect estimates, with weights proportional to sample size).17\n\n\n9 How to make your covariate adjustment decisions transparent\nIn the interests of transparency, if you adjust for covariates, pre-specify your models and report both unadjusted and covariate-adjusted estimates.\nThe simulations above have demonstrated that results may change slightly or not-so-slightly depending on which covariates you choose to include in your model. We’ve highlighted some rules of thumb here: include only pre-treatment covariates that are predictive of outcomes. Deciding which covariates to include, though, is often a subjective rather than an objective enterprise, so another rule of thumb is to be totally transparent about your covariate decisions. Always include the simplest model—the simple regression of outcome on treatment without controlling for covariates—in your paper or appendix to supplement the findings of your model including covariates.\nAnother way to minimize your readers’ concern that you went fishing for the particular combination of covariates that gave results favorable to your hypotheses is to pre-specify your models in a pre-analysis plan.18 This gives you the opportunity to explain before you see the findings which pre-treatment covariates you expect to be predictive of the outcome. You can even write these regressions out in R using fake data, as done here, so that when your results from the field arrive, all you need to do is run your code on the real data. These efforts are a useful way of binding your own hands as a researcher and improving your credibility.\n\n\n10 Covariates can help you investigate the integrity of the random assignment\nSometimes it is unclear whether random assignment actually occurred (or whether it occurred using the procedure that the researcher envisions). For example, when scholars analyze naturally occurring random assignments (e.g., those conducted by a government agency), it is useful to assess statistically whether the degree of imbalance between the treatment and control groups is within the expected margin of error. One statistical test is to regress treatment assignment on all of the covariates and calculate the F-statistic. The significance of this statistic can be assessed by simulating a large number of random assignments and for each one calculating the F-statistic; the resulting distribution can be used to calculate the p-value of the observed F-statistic. For example, if 10,000 simulations are conducted, and just 30 simulations generate an F-statistic larger than what one actually obtained from the data, the p-value is 0.003, which suggests that the observed level of imbalance is highly unusual. In such cases, one may wish to investigate the randomization procedure more closely.\n\n\nFor further reading\nAthey, Susan, and Guido W. Imbens (2017). “The Econometrics of Randomized Experiments.” In Handbook of Economic Field Experiments, vol. 1 (E. Duflo and A. Banerjee, eds.). arXiv DOI\nGerber, Alan S., and Donald P. Green (2012). Field Experiments: Design, Analysis, and Interpretation, chapter 4.\nHennessy, Jonathan, Tirthankar Dasgupta, Luke Miratrix, Cassandra Pattanayak, and Pradipta Sarkar (2016). “A Conditional Randomization Test to Account for Covariate Imbalance in Randomized Experiments.” Journal of Causal Inference 4: 61–80.\nJudkins, David R., and Kristin E. Porter (2016). “Robustness of Ordinary Least Squares in Randomized Clinical Trials.” Statistics in Medicine 35: 1763–1773.\nLin, Winston (2012). “Regression Adjustment in Randomized Experiments: Is the Cure Really Worse than the Disease?” Development Impact blog post, part I and part II.\nRaudenbush, Stephen W. (1997). “Statistical Analysis and Optimal Design for Cluster Randomized Trials.” Psychological Methods 2: 173–185.\nWager, Stefan, Wenfei Du, Jonathan Taylor, and Robert Tibshirani (2016). “High-Dimensional Regression Adjustments in Randomized Experiments.” Proceedings of the National Academy of Sciences 113: 12673–12678. arXiv DOI\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Lindsay Dolan. Revisions: Don Green and Winston Lin, 1 Nov 2016. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits. Thanks to Macartan Humphreys and Diana Mutz for helpful discussions.↩︎\nMiratrix, Luke W., Jasjeet S. Sekhon, and Bin Yu (2013). “Adjusting Treatment Effect Estimates by Post-Stratification in Randomized Experiments.” Journal of the Royal Statistical Society, Series B 75: 369–396.↩︎\nSee, e.g., pages 217–219 of Miriam Bruhn and David McKenzie (2009), “In Pursuit of Balance: Randomization in Practice in Development Field Experiments,” American Economic Journal: Applied Economics 1 (4): 200–232.↩︎\nA brief review of bias and precision: Imagine replicating the experiment many times (without changing the experimental sample and conditions, but re-doing random assignment each time). An unbiased estimator may overestimate or underestimate the ATE on any given replication, but its expected value (the average over all possible replications) will equal the true ATE. We usually prefer unbiased or approximately unbiased estimators, but we also value precision (which is formally defined as the inverse of the variance). Imagine you’re throwing a dart at a dartboard. If you hit the center of the dartboard on average but your shots are often far from the mark, you have an unbiased but imprecise estimator. If you hit close to the center every time, your estimator is more precise. A researcher may choose to accept a small bias in return for a large improvement in precision. One possible criterion for evaluating estimators is the mean squared error, which equals the variance plus the square of the bias. See, e.g., Sharon Lohr (2010), Sampling: Design and Analysis, 2nd ed., pp. 31–32.↩︎\n“Sampling variability” refers to the spread of estimates that will be produced just because of the different random assignments that could have been drawn. When the luck of the draw of random assignment produces a treatment group with more As and a control group with more Bs, it is more difficult to separate background characteristics (A and B) from treatment assignment as the predictor of the observed outcomes.↩︎\nGiné, Xavier, and Ghazala Mansuri (2012). “Together We Will: Experimental Evidence on Female Voting Behavior in Pakistan.”↩︎\nThe estimated bias is 0.0003 with a margin of error (at the 95% confidence level) of 0.0018.↩︎\nDiana C. Mutz, Robin Pemantle, and Philip Pham (2016), “Model Choice in Experimental Design: Messy Analyses of Clean Data.”↩︎\nThomas Permutt (1990), “Testing for Imbalance of Covariates in Controlled Experiments,” Statistics in Medicine 9: 1455–1462.↩︎\nDouglas G. Altman (2005), “Covariate Imbalance, Adjustment for,” in Encyclopedia of Biostatistics.↩︎\nJohn W. Tukey (1991), “Use of Many Covariates in Clinical Trials,” International Statistical Review 59: 123–137. Italics in the original.↩︎\nSee, e.g.: D. R. Cox and N. Reid (2000), The Theory of the Design of Experiments, pp. 29–32; D. Holt and T. M. F. Smith (1979), “Post Stratification,” Journal of the Royal Statistical Society, Series A (General) 142: 33–46; Richard M. Royall (1976), “Current Advances in Sampling Theory: Implications for Human Observational Studies,” American Journal of Epidemiology 104: 463–474. For an introduction to philosophical disagreements about statistical inference, see Bradley Efron (1978), “Controversies in the Foundations of Statistics,” American Mathematical Monthly 85: 231–246.↩︎\nWinston Lin, Donald P. Green, and Alexander Coppock (2016), “Standard Operating Procedures for Don Green’s Lab at Columbia,” version 1.05, June 7. Italics in the original.↩︎\nThe estimated bias is \\(-\\) 0.459 with a margin of error (at the 95% confidence level) of 0.002.↩︎\nDavid A. Freedman (2008), “On Regression Adjustments in Experiments with Several Treatments,” Annals of Applied Statistics 2: 176–196. See also Winston Lin’s blog posts (part I and part II) discussing his response to Freedman.↩︎\nGreen, Donald P. and Aronow, Peter M., Analyzing Experimental Data Using Regression: When Is Bias a Practical Concern? (March 7, 2011). Working paper: http://ssrn.com/abstract=1466886↩︎\nMiratrix, Sekhon, and Yu (2013), cited above.↩︎\nFor more discussion of pre-analysis plans, see, e.g., Benjamin A. Olken (2015), “Promises and Perils of Pre-Analysis Plans,” Journal of Economic Perspectives 29 (3): 61–80.↩︎"
  },
  {
    "objectID": "guides/getting-started/design_en.html",
    "href": "guides/getting-started/design_en.html",
    "title": "10 Things to Know About Survey Design",
    "section": "",
    "text": "Surveys are the most frequently-used tool for collecting experimental data in social science research, and the design of these surveys can have a profound effect on the conclusions we draw about the treatments we study. Therefore, the stakes are high when designing surveys around your experimental projects.\nAt a minimum, all that is needed to estimate a treatment effect after an experiment has been conducted is a measure of the outcome, collected after the treatment has been delivered, with a sufficient number of observations across the treatment and control groups. If time and budget allow, baseline surveys, conducted before the implementation of an experiment, serve important functions as well and can improve analysis greatly.\n\n\nBaseline surveys should produce data that describe the experimental subject population as they were before the treatment is delivered. This is accomplished through the measurement of covariates, which are observed pre-treatment characteristics of experimental subjects. Using covariate data you can: 1) describe the subject population, 2) improve the precision with which you estimate treatment effects, 3) report balance, and 4) estimate heterogeneous treatment effects.\n\n\n\nCovariates improve the precision with which you can estimate treatment effects by reducing variance in three ways; covariates can be used to rescale your dependent variable, as controls when using regression to estimate treatment effects, and to construct blocks in order to conduct blocked random assignment.1 In order for covariate data to be used to reduce variance in our estimates of treatment effects, they need to be unaffected by treatment assignment, i.e. collected sometime before treatment is delivered. See the guide on covariate adjustment for more about how to use covariate data.\nThe greater the predictive power of included covariates, the greater increase in the power of your design and the precision with which you can estimate effects. If you believe covariates will likely predict outcomes in your experiment, then that is grounds to include them in your survey. For example, if the intervention involves providing a service at a cost to treated users, income will likely explain some variation in outcomes and is therefore a useful covariate to measure at the baseline stage.\nBecause pre-treatment covariates can improve precision, conducting a baseline becomes more important when the sample size is limited.\nCovariates also allow you to conduct sub-group analyses. Heterogeneous effects are not causal, and so interpretation is limited. Still, understanding how treatment effects vary by subejcts’ attributes can provide you with important clues about mechanisms. The implication for design is to include covariates for which you would like to report heterogeneous effects. Covariate data will also be used to show “balance”, or the extent to which the treatment and control populations resemble each other. Although random assignment alone ensures that outcomes across the treatment and control group are in expectation the same, it is standard practice to show that random assignment resulted in two groups that are “balanced” on covariates of interest. If, for example, the treatment group included 25% more men than the control group, we might worry that random assignment failed in some way. Collecting pre-treatment covariate data allows us to evaluate and report balance.\n\n\n\nThe baseline provides an opportunity to measure the outcome before the experiment was conducted, later allowing you to use change scores as your outcome and the difference-in-differences estimator. The difference-in-differences estimator will improve precision only when a covariate strongly predicts outcomes.2\n\n\n\nEndline surveys, conducted after the treatment is delivered, are primarily used to measure outcomes. Including questions about implementation can improve analysis and interpretation greatly.\nSurveys conducted after treatments are delivered are one way to understand if there were compliance issues or other implementation issues that may have consequences for analysis. Survey data can help to determine the scope of non-compliance with the assigned treatment, and the underlying causes. This is an opportunity to ask subjects directly about reasons for noncompliance. Subjects may have understood the treatment differently than the researchers, and survey data can be used to both show this and speculate why this may have happened.\nIn the endline, you can learn about spillover by asking subjects in the control condition about their knowledge and access to the treatment. Interviews with treated subjects are useful for understanding spillover as well, because survey data can be used to understand the networks through which the treatment could have “spilled-over” into the control group.\nDescribing the population is important here as well, but covariate data collected after implementation are less useful for improving precision. Ordinarily, covariates collected after treatment assignment are considered suspect, as they could conceivably be affected by treatment.\n\n\n\n\n\n\n\nBaseline checklist\nEndline checklist\n\n\n\n\nWill your data allow you to:\nWill your data allow you to:\n\n\n• Describe the population\n• Estimate effects\n\n\n• Adjust treatment effect estimates (are the covariates included likely to be prognostic of outcomes?)\n• Assess if spillover occurred, or if there was interference\n\n\n• Estimate heterogeneous treatment effects\n• Measure non-compliance (and the reasons for non-compliance if it occurred)\n\n\n• Design a blocked randomization procedure\n• Look for causal mechanisms (how are effects transmitted?)\n\n\n• Describe balance across treatment and control conditions"
  },
  {
    "objectID": "guides/getting-started/design_en.html#gathering-behavioral-data-doesnt-have-to-be-expensive.-here-is-how-to-develop-low-cost-measures",
    "href": "guides/getting-started/design_en.html#gathering-behavioral-data-doesnt-have-to-be-expensive.-here-is-how-to-develop-low-cost-measures",
    "title": "10 Things to Know About Survey Design",
    "section": "Gathering behavioral data doesn’t have to be expensive. Here is how to develop low-cost measures:",
    "text": "Gathering behavioral data doesn’t have to be expensive. Here is how to develop low-cost measures:\n\nBrainstorm a set of actions that subjects would do if the treatment had had an effect or would not do in the case that the treatment did not have an effect. It also works to think about behavior on a continuum—i.e., what would people be more likely to do if affected, and less likely to do if not? Local context matters a lot here; rely on your enumerators, local survey staff, or implementation partners to help you think through a set of possibilities. One nice way to think about this is to challenge yourself to think about “hints.” In the above example, we might think about a group of opposition activists wearing wristbands publicly as a “hint” that people are more likely to take risks. Keep in mind your eventual audience: what behaviors are frequently tracked in the literature you hope to speak to?\nIsolate the set of behaviors that are feasible to measure. This will most likely be the set of behaviors that can be immediately observed by the enumerator and involve minimal materials. What is the least expensive or costly action that would be associated with the behavioral change you want to detect?\nIdeally, pre-test the measures either with the rest of your survey, or in smaller focus groups. Learning why respondents did or did not behave a certain way will increase confidence in your results."
  },
  {
    "objectID": "guides/getting-started/design_en.html#how-do-you-construct-questions-that-accomplish-these-goals",
    "href": "guides/getting-started/design_en.html#how-do-you-construct-questions-that-accomplish-these-goals",
    "title": "10 Things to Know About Survey Design",
    "section": "How do you construct questions that accomplish these goals?",
    "text": "How do you construct questions that accomplish these goals?\n\nUse the simplest possible form of each question, using the most widely-understood words. Avoid jargon or technical terms, and be straightforward and brief.\nBe specific, such that if the question were to be lifted from the section and asked without context you would get the same response.\nIt helps to begin the question by providing a context. For example, you can prime a time period (“Thinking of the last year: has your income been better, the same, or worse?”), or a place (“Thinking of people in this village: have people earned more or less this year as compared to last year?”)\nAvoid measuring multiple things at once. For example, the following question measures attitudes about both the president and government concurrently, making it difficult to draw a clear conclusion from the data: “Do you think the president and the government are doing a good job in terms of protecting basic freedoms?”\nWhen constructing response categories, be as comprehensive as possible. Include all possible responses. You don’t want to record a lot of “don’t know” responses and miss important information. See below for a discussion of scales.\nKeep in mind the concerns with social desirability discussed above; the wording of the question shouldn’t lead the respondent towards a certain response."
  },
  {
    "objectID": "guides/getting-started/effect-types_en.html",
    "href": "guides/getting-started/effect-types_en.html",
    "title": "10 Types of Treatment Effect You Should Know About",
    "section": "",
    "text": "Abstract\nThis guide1 describes ten distinct types of causal effects that researchers may want to estimate. As discussed in our guide 10 Things to Know About Causal Inference, simple randomization allows one to produce estimates of the average of the unit level causal effects in a sample. This average causal effect or average treatment effect (ATE) is a powerful concept because it is one solution to the problem of not observing all relevant counterfactuals. Yet, it is not the only productive engagement with this problem. In fact, there are many different types of quantities of causal interest. The goal of this guide is to help you choose estimands (a parameter of interest) and estimators (procedures for calculating estimates of those parameters) that are appropriate and meaningful for your data.\n\n\n1 Average Treatment Effects\nWe begin by reviewing how, with randomization, a simple difference-of-means provides an unbiased estimate of the ATE. We take extra time to introduce some common statistical concepts and notation used throughout this guide.\nFirst we define a treatment effect for an individual observation (a person, household, city, etc.) as the difference between that unit’s behavior under treatment \\((Y_{i}(1))\\) and control \\((Y_{i}(0))\\):\n\\[τ_{i}=Y_{i}(1)−Y_{i}(0)\\]\nSince we can only observe either \\(Y_{i}(1)\\) or \\(Y_{i}(0)\\) the individual treatment effect is unknowable. A quantity that we can learn about, however, is the average treatment effect (ATE) across all observations in our experiment:\n\\[ATE≡\\frac{1}{N}∑^{N}_{i=1}τ_{i}=\\frac{∑^{N}_{1}Y_{i}(1)}{N}−\\frac{∑^{N}_{1}Y_{i}(0)}{N}\\]\nLet \\(D_{i}\\) be an indicator for whether we observe an observation under treatment or control. If treatment is randomly assigned, \\(D_{i}\\) is independent, not only of potential outcomes but also of any covariates (observed and unobserved) that might predict those outcomes \\(((Y_{i}(1),Y_{i}(0),X_{i}⊥⊥D_{i}))\\).2\nSuppose our design involves \\(m\\) units under treatment and \\(N−m\\) under control. Suppose we were to repeatedly reassign treatment at random many times and each time calculate the difference of means between treated and control groups and then to record this value in a list. In other words, for every repetition, we produce an estimate of the ATE using the the observed difference in means:3\n\\[\\widehat{ATE} =\\frac{∑^m_1Z_{i}Y_{i}}{m}−\\frac{∑^{N}_{m+1}(1−Z_{i})Y_{i}}{N−m}\\]\nThe average of the estimates in our list will be the same as the difference of the means of the true potential outcomes had we observed the full schedule of potential outcomes for all observations. That is \\(E(Y_i(1)|D=1)=E(Y_i(1)|D=0)=E(Y_i(1))\\) and \\(E(Y_i(0)|D=1)=E(Y_i(0)|D=0)=E(Y_i(0))\\). Another way to state this characteristic of the average treatment effect and its estimator is to say that the difference of observed means is an unbiased estimator of the average treatment effect.\nStatistical inference about the estimated ATE requires that we know how it will vary across randomizations. It turns out that we can write the variance of the ATE across randomizations as follows:\n\\[V(ATE) = \\frac{N}{N−1} [\\frac{V(Y_{i}(1))}{m}+\\frac{V(Y_{i}(0))}{N−m}]−\\frac{1}{N−1}[V(Y_{i}(1))+V(Y_{i}(0))−2∗Cov(Y_{i}(1),Y_{i}(0))]\\]\nand estimate this quantity from the sample estimates of the variance in each group.4\nA linear model regressing the observed outcome \\(Y_{i}\\) on a treatment indicator \\(D_{i}\\) provides a convenient estimator of the ATE (and with some additional adjustments, the variance of the ATE):\n\\[Y_{i}=Y_{i}(0)∗(1−D_{i})+Y_{i}(1)∗D_{i}=β_{0}+β_{1}D_{i}+u\\]\nsince we can rearrange terms so that \\(β_{0}\\) estimates the average among control observations \\((Y_{i}(0)∣D_{i}=0)\\) and \\(β_{1}\\) estimates the differences of means \\((Y_{i}(1)∣D_{i}=1)–(Y_{i}(1)∣D_{i}=0)\\). In the code below, we create a sample of 1,000 observations and randomly assign a treatment \\(D_i\\) with a constant unit effect to half of the units. We estimate the ATE using ordinary least squares (OLS) regression to calculate the observed mean difference. Calculating the means in each group and taking their difference would also produce an unbiased estimate of the ATE. Note that the estimated ATE from OLS is unbiased, but the errors in this linear model are assumed to be independent and identically distributed. When our treatment effects both the average value of the outcome and the distribution of responses, this assumption no longer holds and we need to adjust the standard errors from OLS using a Huber-White sandwich estimator to obtain the correct estimates (based on the variance of the ATE) for statistical inference.5 Finally, we also demonstrate the unbiasedness of these estimators through simulation.\n\nset.seed(1234) # For replication\nN = 1000 # Population size\nY0 = runif(N) # Potential outcome under control condition\nY1 = Y0 + 1 # Potential outcome under treatment condition\nD = sample((1:N)%%2) # Treatment: 1 if treated, 0 otherwise\nY = D*Y1 + (1-D)*Y0 # Outcome in population\nsamp = data.frame(D,Y)\nATE = coef(lm(Y~D,data=samp))[2] #same as with(samp,mean(Y[Z==1])-mean(Y[Z==0]))\n# SATE with Neyman/Randomization Justified Standard Errors\n# which are the same as OLS standard errors when no covariates or blocking\nlibrary(lmtest)\nlibrary(sandwich)\nfit<-lm(Y~D,data=samp)\ncoef(summary(fit))[\"D\",1:2]\n\n  Estimate Std. Error \n1.01820525 0.01841784 \n\nATE.se<-coeftest(fit,vcovHC(fit,type=\"HC2\"))[\"D\",2]\n# same as with(samp,sqrt(var(Y[D==1])/sum(D)+var(Y[D==0])/(n-sum(D)))\n# Assess unbiasedness and simulate standard errors\ngetATE<-function() {\n  D = sample((1:N)%%2) # Treatment: 1 if treated, 0 otherwise\n  Y = D*Y1 + (1-D)*Y0\n  coef(lm(Y~D))[[\"D\"]]\n}\nmanyATEs<-replicate(10000,getATE())\n## Unbiasedness:\nc(ATE=mean(Y1)-mean(Y0), ExpEstATE=mean(manyATEs))\n\n      ATE ExpEstATE \n1.0000000 0.9999077 \n\n## Standard Error\n### True SE formula\nV<-var(cbind(Y0,Y1))\nvarc<-V[1,1]\nvart<-V[2,2]\ncovtc<-V[1,2]\nn<-sum(D)\nm<-N-n\nvarestATE<-((N-n)/(N-1))*(vart/n) + ((N-m)/(N-1))* (varc/m) + (2/(N-1)) * covtc\n### Compare SEs\nc(SimulatedSE= sd(manyATEs), TrueSE=sqrt(varestATE), ConservativeSE=ATE.se)\n\n   SimulatedSE         TrueSE ConservativeSE \n    0.01835497     0.01842684     0.01841784 \n\n\n\n\n2 Conditional Average Treatment Effects\nThe problem with looking at average treatment effects only is that it takes attention away from the fact that treatment effects might be very different for different sorts of people. While the “fundamental problem of causal inference” suggests that measuring causal effects for individual units is impossible, making inferences on groups of units is not.\nRandom assignment ensures that treatment is independent of potential outcomes and any (observed and unobserved) covariates. Sometimes, however, we have additional information about the experimental units as they existed before the experiment was fielded, say \\(X_{i}\\), and this information can can help us understand how treatment effects vary across subgroups. For example, we may suspect that men and women respond differently to treatment, and we can test for this hetorogeneity by estimating conditional ATE for each subgroup separately \\((CATE=E(Y_{i}(1)−Y_{i}(0)∣D_{i},X_{i}))\\). If our covariate is continous, we can test its moderating effects by interacting the continous variable with the treatment. Note, however, that the treatment effect is now conditional on both treatment status and the value of the conditioning variable at which the effect is evaluated and so we must adjust our interpretation and standard errors accordingly.6\nA word of warning: looking at treatment effects across dimensions that are themselves affected by treatment is a dangerous business and can lead to incorrect inferences. For example if you wanted to see how administering a drug led to health improvements you could run separate analyses for men and women, but you could not run separate analyses for those who in fact took the drug and those who did not (this is an example of inference for compliers which requires separate techniques described in point 4 below).\n\n\n3 Intent-to-Treat Effects\nOutside of a controlled laboratory setting, the subjects we assign to treatment often are not the same as the subjects who actually receive the treatment. When some subjects assigned to treatment fail to receive it, we call this an experiment with one-sided non-compliance. When additionally, some subjects assigned to control also receive the treatment, we say there is two-sided non-compliance. For example, in a get-out-the-vote experiment, some people assigned to receive a mailer may not receive it. Perhaps they’ve changed addresses or never check their mail. Similarly, some observations assigned to control may receive the treatment. Perhaps they just moved in, and the previous tenant’s mail is still arriving.\nWhen non-compliance occurs, the receipt of treatment is no longer independent of potential outcomes and confounders. The people who actually read their mail probably differ in a number of ways from the people who throw their mail away (or read their neighbors’ mail) and these differences likely also affect their probability of voting. The difference-of-means between subjects assigned to treatment and control no longer estimates the ATE, but instead estimates what is called an intent-to-treat effect (ITT). We often interpret the ITT as the effect of giving someone the opportunity to receive treatment. The ITT is particularly relevant then for assessing programs and interventions with voluntary participation.\nIn the code below, we create some simple data with one-sided non-compliance. Although the true treatment effect for people who actually received the treatment is 2, our estimated ITT is smaller (about 1) because only some of the people assigned to treatment actually receive it.\n\nset.seed(1234) # For replication\nn = 1000 # Population size\nY0 = runif(n) # Potential outcome under control condition\nC = sample((1:n)%%2) # Whether someone is a complier or not\nY1 = Y0 + 1 +C # Potential outcome under treatment\nZ = sample((1:n)%%2) # Treatment assignment\nD = Z*C # Treatment Uptake\nY = D*Y1 + (1-D)*Y0 # Outcome in population\nsamp = data.frame(Z,Y)\nITT<-coef(lm(Y~Z,data=samp))[2]\n\n\n\n4 Complier Average Treatment Effects\nWhat if you are interested in figuring out the effects of a treatment on those people who actually took up the treatment and not just those people that were administered the treatment? For example what is the effect of radio ads on voting behavior for those people that actually hear the ads?\nThis turns out to be a hard problem (for more on this see our guide 10 Things to Know About the Local Average Treatment Effect). The reasons for non-compliance with treatment can be thought of as an omitted variable. While the receipt of treatment is no longer independent of potential outcomes, the assignment of treatment status is. As long as random assignment had some positive effect on the probability of receiving treatment, we can use it as an instrument to identify the effects of treatment on the sub-population of subjects who comply with treatment assignment.\nFollowing the notation of Angrist and Pischke,7 let \\(Z\\) be an indicator for whether an observation was assigned to treatment and \\(D_{i}\\) indicates whether that subject actually received the treatment. Experiments with non-compliance are composed of always-takers (\\(D_{i}=1\\), regardless of \\(Z_{i}\\)), never-takers (\\(D_{i}=0\\) regardless of \\(Z_{i}\\)), and compliers (\\(D_{i}=1\\) when \\(Z_{i}=1\\) and \\(0\\) when \\(Z_{i}=0\\)).8 We can estimate a complier average causal effect (CACE), sometimes also called a local average treatment effect (LATE), by weighting the ITT (the effect of \\(Z\\) on \\(Y\\)) by the effectiveness of random assignment on treatment uptake (the effect of \\(Z\\) on \\(D\\)).\n\\[CACE= \\frac{Effect of Z on Y}{Effect of Z on D}=\\frac{E(Y_i∣Z_i=1)-E(Y_i|Z_i=0)}{E(D_i|Z_i=1)-E(D_i|Z_i=0)}\\]\nThe estimator above highlights the fact that the ITT and CACE converge as we approach full compliance. Constructing standard errors for ratios is somewhat cumbersome and so we usually estimate a CACE using two-stage-least-squares regression with random assignment, \\(Z_i\\), serving as instrument for treatment receipt \\(D_i\\) in the first stage of the model. This approach simplifies the estimation of standard errors and allows for the inclusion of covariates as additional instruments. We demonstrate both strategies in the code below for data with two-sided non-compliance. Note, however, that when instruments are weak (e.g. random assignment had only a small effect on the receipt of treatment), instrumental variable estimators and their standard errors can be biased and inconsistent.9\n\nset.seed(1234) # For replication\nn = 1000 # Population size\nY0 = runif(n) # Potential outcome under control condition\nY1 = Y0 + 1 # Potential outcome under treatment\nZ = sample((1:n)%%2) # Treatment assignment\npD<-pnorm(-1+rnorm(n,mean=2*Z)) # Non-compliance\nD<-rbinom(n,1,pD) # Treatment receipt with non-compliance\nY = D*Y1 + (1-D)*Y0 # Outcome in population\nsamp = data.frame(Z,D,Y)\n# IV estimate library(AER) CACE = coef(ivreg(Y ~ D | Z, data = samp))[2]\n# Wald Estimator ITT<-coef(lm(Y~Z,data=samp))[2] ITT.D<-coef(lm(D~Z,data=samp))[2] CACE.wald<-ITT/ITT.D\n\n\n\n5 Population and Sample Average Treatment Effects\nOften we want to generalize from our sample to make statements about some broader population of interest.10 Let \\(S_i\\) be an indicator for whether an subject is in our sample. The sample average treatment effect (SATE) is defined simply as \\(E(Y_i(1)−Y_i(0)|S_i=1)\\) and the population \\(E(Y_i(1)−Y_i(0))\\). With a large random sample from a well-defined population with full compliance with treatment, our SATE and PATE are equal in expectation and so a good estimate for one (like a difference of sample means) will be a good estimate for the other.11\nIn practice, the experimental pool may consist of a group of units selected in an unknown manner from a vaguely defined population of such units and compliance with treatment assignment may be less than complete. In such cases our SATE may diverge from the PATE and recovering estimates of each becomes more complicated. Imai, King, and Stuart (2008) decompose the divergence between these estimates into error that arises from sample selection and treatment imbalance. Error from sample selection arises from different distributions of (observed and unobserved) covariates in our sample and population. For example people in a medical trial often differ from the population for whom the drug would be available. Error from treatment imbalance reflects differences in covariates between treatment and control groups in our sample, perhaps because of non-random assignment and/or non-compliance.\nWhile there are no simple solutions to the problems created by such error, there are steps you can take in both the design of your study and the analysis of your data to address these challenges to estimating the PATE or CACE/LATE. For example, including a placebo intervention provides additional information on the probability of receiving treatment, that can be used to re-weight the effect of actually receiving it (e.g Nickerson (2008)) in the presence of non-compliance. One could also use a model to re-weight observations to adjust for covariate imbalance and the unequal probability of receiving the treatment, both within the sample and between a sample and the population of interest.12\nIn the code below, we demonstrate several approaches to estimating these effects implemented in the CausalGAM package for R.13 Specifically, the package produces regression, inverse-propensity weighting (IPW), and augmented inverse-propensity weighting estimates of the ATE. Combining regression adjustment with IPW, the AIPW has the feature of being “doubly robust” in that the estimate is still consistent even if we have incorrectly specified either the regression model or the propensity score for the probability weighting.\n\n# Example adapted from ?estimate.ATE\nlibrary(CausalGAM)\nset.seed(1234) # For replication\nn = 1000 # Sample size\nX1 = rnorm(n) # Pre-treatment covariates\nX2 = rnorm(n)\np = pnorm(-0.5 + 0.75*X2) # Unequal probabilty of Treatment\nD = rbinom(n, 1, p) # Treatment\nY0 = rnorm(n) # Potential outcomes\nY1 = Y0 + 1 + X1 + X2\nY = D*Y1 + (1-D)*Y0 # Observed outcomes\nsamp = data.frame(X1,X2,D,Y)\n# Estimate ATE with AIPW, IPW, Regression weights\nATE.out <- estimate.ATE(pscore.formula = D ~ X1 +X2,\n                        pscore.family = binomial,\n                        outcome.formula.t = Y ~ X1\n                        +X2,\n                        outcome.formula.c = Y ~ X1\n                        +X2,\n                        outcome.family = gaussian,\n                        treatment.var = \"D\",\n                        data=samp,\n                        divby0.action=\"t\",\n                        divby0.tol=0.001,\n                        var.gam.plot=FALSE, nboot=50)\n\n\n\n6 Average Treatment Effects on the Treated and the Control\nTo evaluate the policy implications of a particular intervention, we often need to know the effects of the treatment not just on the whole population but specifically for those to whom the treatment is administered. We define the average effects of treatment among the treated (ATT) and the control (ATC) as simple counter-factual comparisons:\n\\[ATT=E(Y_i(1)-Y_i(0)|D_i=1)=E(Y_i(1)|D_i=1)-E(Y_i(0)|D_i=1)\\] \\[ATC=E(Y_i(1)-Y_i(0)|D_i=0)=E(Y_i(1)|D_i=0)-E(Y_i(0)|D_i=0)\\]\nInformally, the ATT is the effect for those that we treated; ATC is what the effect would be for those we did not treat.\nWhen treatment is randomly assigned and there is full compliance, \\(ATE=ATT=ATC\\), since \\(E(Y_i(0)∣D_i=1)=E(Y_i(0)∣D_i=0)\\) and \\(E(Y_i(1)∣D_i=0)=E(Y_i(1)∣D_i=1)\\) Often either because of the nature of the intervention or specific concerns about cost and ethnics, treatment compliance is incomplete and the ATE will not in general equal the ATT or ATC. In such instances, we saw in the previous section that we could re-weight observations by their probability of receiving the treatment to recover estimates of the ATE. The same logic can be extended to produce estimates of the ATT and ATC in both our sample and the population.14\nBelow, we create a case where the probability of receiving treatment varies but can be estimated using a propensity score model.15 The predicted probabilities from this model are then used as weights to recover the estimates of the ATE, ATT, and ATC. Inverse propensity score weighting attempts to balance the distribution of covariates between treatment and control groups when estimating the ATE. For the ATT, this weighting approach treats subjects in the treated group as a sample from the target population (people who received the treatment) and weights subjects in the control by their odds of receiving the treatment. In a similar fashion, the estimate of the ATC weights treated observations to look like controls. The quality (unbiasedness) of these estimates is inherently linked to the quality of our models for predicting the receipt of treatment. Inverse propensity score weighting and other procedures produce balance between treatment and control groups on observed covariates, but unless we have the “true model” (and we almost never know the true model) the potential for bias from unobserved covariates remains and should lead us to interpret our estimates of the ATT or ATC in light of the quality of the model that produced it.\n\nset.seed(1234) # For replication\nn = 1000 # Sample size\nX1 = rnorm(n) # Pre-treatment covariates\nX2 = rnorm(n)\np = pnorm(-0.5 + 0.75*X2) # Unequal probabilty of Treatment\nD = rbinom(n, 1, p) # Treatment\nY0 = rnorm(n) # Potential outcomes\nY1 = Y0 +1 +X1 +X2\nY = D*Y1 + (1-D)*Y0 # Observed outcomes\nsamp = data.frame(X1,X2,D,Y)\n# Propensity score model\nsamp$p.score<-\npredict(glm(D~X1+X2,samp,family=binomial),type=\"response\")\n# Inverse Propability Weights\nsamp$W.ipw<-with(samp, ifelse(D==1,1/p.score,1/(1-p.score)))\nsamp$W.att<-with(samp, ifelse(D==1,1,p.score/(1-p.score)))\nsamp$W.atc<-with(samp, ifelse(D==1,(1-p.score)/p.score,1))\n# IPW: ATE, ATT, ATC\nATE.ipw<-coef(lm(Y~D,data=samp,weights=W.ipw))[2]\nATT.ipw<-coef(lm(Y~D,data=samp,weights=W.att))[2]\nATC.ipw<-coef(lm(Y~D,data=samp,weights=W.atc))[2]\n\n\n\n7 Quantile Average Treatment Effects\nThe ATE focuses on the middle, in a way on the effect for a typical person, but we often also care about the distributional consequences of our treatment. We want to know not just whether our treatment raised average income, but also whether it made the distribution of income in the study more or less equal.\nClaims about distributions are difficult. Even though we can estimate the ATE from a difference of sample means, in general, we cannot make statements about the joint distribution of potential outcomes \\((F(Yi(1),Yi(0)))\\) without further assumptions. Typically, these assumptions either limit our analysis to a specific sub-population16 or require us to assume some form of rank invariance in the distribution of responses to treatment effects.17\nIf these assumptions are justified for our data, we can obtain consistent estimates of quantile treatment effects (QTE) using quantile regression.18 Just as linear regression estimates the ATE as a difference in means (or, when covariates are used in the model, from a conditional mean), quantile regression fits a linear model to a conditional quantile and this model can then be used to estimates the effects of treatment for that particular quantile of the outcome. The approach can be extended to include covariates and instruments for non-compliance. Note that the interpretation of the QTE is for a given quantile, not an individual at that quantile.\nBelow we show a case where the ATE is 0, but the treatment effect is negative for low quantiles of the response and positive for high quantiles. Estimating quantile treatment effects provides another tool for detecting heterogeneous effects and allows us to describe distributional consequences of our intervention. These added insights come at the cost of requiring more stringent statistical assumptions of our data and more nuanced interpretations of our results.\n\nset.seed(1234) # For replication\nn = 1000 # Population size\nY0 = runif(n) # Potential outcome under control condition\nY1= Y0\nY1[Y0 <.5] = Y0[Y0 <.5]-rnorm(length(Y0[Y0 <.5]))\nY1[Y0 >.5] = Y0[Y0 >.5]+rnorm(length(Y0[Y0 >.5]))\nD = sample((1:n)%%2) # Treatment: 1 if treated, 0 otherwise\nY = D*Y1 + (1-D)*Y0 # Outcome in population\nsamp = data.frame(D,Y)\nlibrary(quantreg)\nATE = coef(lm(Y~D,data=samp))[2]\nQTE = rq(Y~D,tau =\nseq(.05,.95,length.out=10),data=samp,method = \"fn\")\nplot(summary(QTE),parm=2,main=\"\",ylab=\"QTE\",xlab=\"Quantile\",mar = c(5.1, 4.1, 2.1, 2.1))\n\n\n\n\n\n\n8 Mediation Effects\nSometimes we want to describe not just the magnitude and significance of an observed causal effect, but also the mechanism (or mechanisms) that produced it. Did our intervention raise turnout in the treatment group, in part, by increasing these subjects’ sense of political efficacy? If so, how much of that total effect can be attributed to the mediated effects of our treatment on efficacy and efficacy on turnout?\nBaron and Kenny (1986) offer a general framework for thinking about mediation by decomposing the total effect of treatment into its indirect effect on a mediator that then effects the outcome, called an average causal mediation effect (ACME), and the remaining average direct effect (ADE) of the treatment. Unbiased estimation of these effects, however, requires a set of strong assumptions about the relationship between treatment, mediators, outcomes, and potential confounders, collectively called sequential ignorability (Imai, Keele, and Yamamoto (2010), Bullock, Green, and Ha (2010)).19\nMost causal effects likely operate through multiple channels, and so an assumption of sequential ignorability for your experiment can be hard to justify. For example, the top row in the figure below illustrates situations in which sequential ignorability holds, while the bottom row depicts two (of many possible) cases in which sequential ignorability is violated, and mediation analysis is biased. In essence, specifying the effects of a particular mediator requires strong assumptions about the role of all the other mediators in the causal chain. While some experimental designs can, in theory, provide additional leverage (such as running a second, parallel experiment in which the mediator is also manipulated), in practice these designs are hard to implement and still sensitive to unobserved bias. In some cases, the insights we hope to gain from mediation analysis may be more easily acquired from subgroup analysis and experiments designed to test for moderation.\nImai and colleagues propose an approach to mediation analysis that allows researchers to test the sensitivity of their estimates to violations of sequential ignorability.20 In the code we demonstrate some of the features of their approach, implemented in the mediation package in R (Tingley et al. 2014). We model the relationships with OLS, but the package is capable of handling other outcome processes, such as generalized linear models or general additive models, that may be more appropriate for your data. Most importantly, the package allows us to produce bounds that reflect the sensitivity of our point estimates to some violations of sequential ignorability. In our simulated data, just over 20 percent of the total effect is mediated by our proposed mediator, M and the bias from an unobserved pre-treatment confounder would have to be quite large (ρ=.7) before we would reject the finding of a positive ACME. These bounds are only valid, however, if we believe there are no unobserved post-treatment confounders (as in panel 4). Sensitivity analysis is still possible, but more complicated in such settings (Imai and Yamamoto 2013).\n\n\nset.seed(1234) # Replication\nn = 1000 # Sample size\nY0 = runif(n) # Potential outcome under control condition\nD = sample((1:n)%%2) # Treatment: 1 if treated, 0 otherwise\nX<-rnorm(n) # Covariate\nM<-rnorm(n=n,mean=D+rnorm(n)) # Mediator influenced by Treatment\nY1 = Y0 + 1 + M # Potential outcome under treatment\nY = D*Y1 + (1-D)*Y0 # Outcome in population\nsamp<-data.frame(D,M,Y)\nlibrary(mediation)\nmed.f<-lm(M~D+X,data=samp) # Model for mediator\nout.f<-lm(Y~M+D+X,data=samp) # Model for outcome\n#Estimate ACME and ADE\nlibrary(mediation)\nmed.out<-\nmediate(med.f,out.f,treat=\"D\",mediator=\"M\",robustSE=T,sims=1000)\n# Sensitivity of ACME to unobserved pre-treatment confounder\ns.out<-medsens(med.out)\nplot(s.out) # Plot sensistivity bounds\n\n\n\n\n\n# Structural equations estimates of ACME ADE\n# f1<-formula(Y~D+X)\n# f2<-formula(M~D+X)\n# f3<-formula(Y~D+M+X)\n#\n# med.sys<-systemfit(list(f1,f2,f3),data=samp)\n# ACME<-coef(med.sys)[\"eq1_D\"]-coef(med.sys)[\"eq3_D\"]\n# ADE<-coef(med.sys)[\"eq3_D\"]\n\n\n\n9 Log-Odds Treatment Effects\nAverage treatment effects seem a bit hard to interpret when outcomes are not continuous. For example, a very common binary outcome in the study of elections is coded as 1 when subjects voted, and 0 when they did not. The average effect might be 0.2, but what does it really mean to say that a treatment increased my voting by 0.2? Estimating causal effects for dichotomous outcomes requires some additional care, particularly when including covariates. A common quantity of causal interest for dichotomous outcomes is our treatment’s effect on the log-odds of success, defined for the experimental pool as:\n\\[\\Delta = log\\frac{E(Y_i(1))}{1-E(Y_i(1))} - log\\frac{E(Y_i(0))}{1-E(Y_i(0))}\\]\nFreedman (2008b) shows that logistic regression adjusting for covariates in a randomized experiments produces biased estimates of this causal effect. The basic intuition for Freedman’s argument comes from the fact that taking the log of averages is not the same as taking the average of logs and so the treatment coefficient estimated from a logistic regression conditioning on covariates will not provide a consistent estimator of log-odds of success. Instead, Freedman recommends taking the predicted probabilities varying subjects’ treatment status but maintaining their observed covariate profiles to produce a consistent estimator of the log-odds.\nThe basic procedure is outlined in the code below. The coefficients from the logistics regression controlling for covariate X, tend to overestimate the effect of treatment on the log odds, while the adjusted estimates from the predicted probabilities produce consistent results.\n\nset.seed(1234) # For replication\nn = 1000 # Sample size\nU = runif(n)\nX = runif(n) # Observed Covariate\nY0 = ifelse(U>.5,1,0) # Potential Outcomes\nY1 = ifelse(U+X>.75,1,0)\nD = rbinom(n,1,.75) # Randomly assign 3/4 to treatment\nY = D*Y1+Y0*(1-D)\nsamp = data.frame(X,D,Y)\naT<-with(samp, mean(Y[D==1]))\naC<-with(samp, mean(Y[D==0]))\n# Unconditional log odds\nlog.odds<-log(aT/(1-aT))-log(aC/(1-aC))\n# Logistic regression conditioning on X overestimates log odds\nfit<-glm(Y~D+X,data=samp,binomial(\"logit\"))\nlog.odds.logit<-\n  coef(glm(Y~D+X,data=samp,binomial(\"logit\")))[2]\n# Dataframes using original covariates for predicted probabilities\nD1<-data.frame(D=1,samp[,c(\"X\")])\nD0<-data.frame(D=0,samp[,c(\"X\")])\n#Adjusted log-odds produces consisted estimator of log-odds\naT.adj<-predict(fit,newdata=D1,type=\"response\")\naC.adj<-predict(fit,newdata=D0,type=\"response\")\nlog.odds.adj<-log(mean(aT.adj)/(1-mean(aT.adj)))-\n  log(mean(aC.adj)/(1-mean(aC.adj)))\n\n\n\n10 Attributable Effects\nWe conclude with a brief discussion of an alternative quantity of causal interest that may be particularly useful with binary outcomes: the attributable effect (Rosenbaum 2010). Consider a simple case with a dichotomous outcome and treatment. Let \\(A\\) be the number of outcomes attributable to treatment, that is, the number of cases in which \\(Y_i\\) equaled 1 among treated subjects which would not have occurred had these units been assigned to control. For a range of \\(A\\)’s, we adjust the observed contingency table of outcomes among the treated, and compare this resulting distribution to a known null distribution (the distribution of outcomes we would have observed had treatment had no effect). The resulting range of \\(A\\)’s for which our test continues to reject the null hypothesis of no effect provides a range of effects that are attributable to our treatment.\n\n\n\nTable 1\n\\(D=1\\)\n\\(D=0\\)\n\n\n\n\n\\(Y=1\\)\n\\(\\sum Y_iD_i-A\\)\n\\((1-Y_i)(D_i)\\)\n\n\n\\(Y=0\\)\n\\(\\sum Y_i(1-D_i)+A\\)\n\\(\\sum (1-Y_i)(1-D_i)\\)\n\n\n\nRosenbaum (2002) shows extensions of this concept to different types of outcomes (such as continuous variables). A similar logic can also be applied to detecting uncommon but dramatic responses to treatment (Rosenbaum and Silber 2008).\nHansen and Bowers (2009) use this approach to identify the number of additional votes attributable to different interventions in get-out-the-vote experiment with clustered treatment assignment and one-sided non-compliance. They show that, in large samples, one can approximate the confidence interval for attributable effects without assessing each attribution. Here is an example of that approach where covariates are used to increase precision.\nFirst, we define an attributable effect as \\(A=∑_iZ_iτ_i\\), where \\(τ_i=Y_i(1)−Y_i(0)\\) and \\(y∈0,1\\) following Rosenbaum (2002). That is, the attributable effect is the number of “yes” or “success” or other “1” responses among those treated that we would not have seen if they had been assigned control.\nSecond, notice that if we write the set \\(U\\) as the experimental pool, and the set of control units is a subset of the whole pool, \\(C⊆U\\), then we can write \\(∑_{i∈C}Y_i−Y_i(0)=0\\). This means that we can represent \\(A\\) using totals:\n\\[A = ∑_{i=1}^NZ_iτ_i=∑_{i=1}^NZ_i(Y_i(1)−Y_i(0))=∑_{i∉C}y_i(1)−∑_{i∉C}y_i(0)\\] \\[  = ∑_{i∉C}Y_i−∑_{i∉C}Y_i(0)=∑_{i=1}^NY_i−∑_{i=1}^NY_i(0)=t_U−t_C\\]\n\n= observed total overall (fixed and observed) - total outcome under control (unobserved, to estimate)\n\nThird, this representation allows us to produce a design-based confidence interval for A^ by drawing on the survey sampling literature about statistical inference for sample totals because the observed total outcomes, tU, is fixed across randomizations. We can use covariates to increase precision here because the survey regression estimator allows us to estimate the total that we would have seen in the control group: \\(\\hat{t}_c=\\sum_{i∈U}\\hat{Y}_i+\\sum_{i∈U}(Y_i-\\hat{Y}_i)\\) with \\(\\hat{Y}_i=f(X_i,\\beta)\\) (Lohr 1999). The survey sampling literature shows that as \\(N→∞\\), \\(CI(\\hat{t}_c) \\approx \\hat{t}_c \\pm z_{a/2}SE(\\hat{t}_c)\\). So, one can calculate \\(\\widehat{SE}(\\hat{t}_c)\\) from standard sampling theory and then the \\(CI(\\hat{A}) \\approx t_U-\\widehat{CI}(\\hat{t}_c)\\).\nIn the code below, we provide an illustration using simulated data for a binary response and treatment. In 85 percent of the treatment group, \\(Y=1\\) compared to 52 percent in the control. A difference of this size is consistent with our treatment having caused \\(Y=1\\) for between 92 and 138 of subjects, for whom \\(Y\\) would have otherwise equaled 0 had they not received the treatment. The regression estimator, which leverages precision gained from including covariates, produces tighter confidence intervals (98.8 to 135.1) for the attributable effects.\n\nset.seed(1234) # For replication \nn = 1000 # Sample size \nX1 = rnorm(n) # Covariates \nX2 = rnorm(n) \np = pnorm(-0.5 + 0.75*X2) # Unequal probability of treatment \nD = rbinom(n, 1, p) \np0 = pnorm(rnorm(n)) # Potential outcomes for binary response \np1 = pnorm(X1 + X2+1) \nY0 = rbinom(n, 1, p0) \nY1 = rbinom(n, 1, p1) \nY = D*Y1 + (1-D)*Y0 # Observed outcome \nsamp = data.frame(D,Y,X1,X2) # Data frame \nattribute<-function(treat,out,A,data){ \n  # Contingency Table of Treatment Status and Outcome \n  attr.tab<-with(data,table(treat,out)) # \n  # Matrix of p-values for Attributable effects, A \n  attr.ps<-\n    matrix(NA,nc=2,nr=A,dimnames=list(NULL,c(\"A\",\"p\"))) \n  for(i in 1:A){ \n    attr.ps[i,]<-\n      c(i,fisher.test(attr.tab+matrix(c(0,i,0,-i),2,2))$p) \n    }\n  # Find range of effects \n  get.bounds<-function(){ \n    diffs<-ifelse(.05-attr.ps[,\"p\"]>0,.05-\n                    attr.ps[,\"p\"],99) \n    index<-(diffs %in% \n              c(min(diffs),min(diffs[diffs>min(diffs)]))) \n    index \n    }\n  # Return range of effects \n  return (attr.ps[get.bounds(),])\n  } \nwith(samp,table(D,Y))\n\n   Y\nD     0   1\n  0 318 339\n  1  51 292\n\nwith(samp,apply(table(D,Y),1,prop.table)) \n\n   D\nY           0        1\n  0 0.4840183 0.148688\n  1 0.5159817 0.851312\n\nattribute(treat = D, out= Y, A=200,data=samp) \n\n       A          p\n[1,]  92 0.04519869\n[2,] 138 0.04587804\n\n# Regression estimator \nfit1<-lm(Y~X1+X2,data=samp,subset=D==0) \nhatYcU<-predict(fit1,newdata=samp) \nec<-Y[D==0]-hatYcU[D==0] ## same as residuals(fit1) \nhatTotYc<-sum(hatYcU)+sum(ec) \nN<-length(Y) \nnctrls<-sum(1-D) \nthefpc<- (1 - (nctrls/N)) \nvarhattC<-N*thefpc*var(Y[D==0]) \nalpha<-c(.05, 1/3) \nalpha<-sort(c(alpha/2, 1-alpha/2)) \nciTotYc<-hatTotYc+sqrt(varhattC)*qnorm(alpha) \nciAE<-sort(sum(Y) - ciTotYc ) \nnames(ciAE)<-c(\"lower 95%\",\"lower \n66%\",\"upper 66%\",\"upper 95%\") \nprint(ciAE) \n\n  lower 95% lower \\n66%   upper 66%   upper 95% \n   98.78637   107.97975   125.90114   135.09451 \n\n\n\n\nReferences\nAronow, Peter M, and Joel A Middleton. 2013. “A Class of Unbiased Estimators of the Average Treatment Effect in Randomized Experiments.” Journal of Causal Inference 1 (1): 135–54.\nAronow, Peter M, and Cyrus Samii. 2014. “Does Regression Produce Representative Estimates of Causal Effects?” In EPSA 2013 Annual General Conference Paper. Vol. 585.\nBaron, Reuben M, and David A Kenny. 1986. “The Moderator–Mediator Variable Distinction in Social Psychological Research: Conceptual, Strategic, and Statistical Considerations.” Journal of Personality and Social Psychology 51 (6). American Psychological Association: 1173.\nBound, John, David A Jaeger, and Regina M Baker. 1995. “Problems with Instrumental Variables Estimation When the Correlation Between the Instruments and the Endogenous Explanatory Variable Is Weak.” Journal of the American Statistical Association 90 (430). Taylor & Francis: 443–50.\nBrambor, Thomas, William R. Clark, and Matt Golder. 2006. “Understanding Interaction Models: Improving Empirical Analyses.” Political Analysis 14 (1): 63–82.\nBullock, John G, Donald P Green, and Shang E Ha. 2010. “Yes, but What’s the Mechanism?(don’t Expect an Easy Answer).” Journal of Personality and Social Psychology 98 (4). American Psychological Association: 550.\nChernozhukov, Victor, and Christian Hansen. 2005. “An IV Model of Quantile Treatment Effects.” Econometrica 73 (1). Wiley Online Library: 245–61.\nDunning, Thad. 2010. “Design-Based Inference: Beyond the Pitfalls of Regression Analysis?” Rethinking Social Inquiry: Diverse Tools, Shared Standards. 2nd Ed. Lanham, Md.: Rowman and Littlefield.\nFreedman, David A. 2008a. “On Regression Adjustments to Experimental Data.” Advances in Applied Mathematics 40 (2). Elsevier: 180–93. ———. 2008b. “Randomization Does Not Justify Logistic Regression.” Statistical Science 23 (2). Institute of Mathematical Statistics: 237–49.\nFrölich, Markus, and Blaise Melly. 2010. “Estimation of Quantile Treatment Effects with Stata.” Stata Journal 10 (3): 423.\nGerber, Alan S, and Donald P Green. 2012. Field Experiments: Design, Analysis, and Interpretation. WW Norton.\nGreen, Donald P. 2009. “Regression Adjustments to Experimental Data: Do David Freedman’s Concerns Apply to Political Science?” In 26th Annual Meeting of the Society for Political Methodology, Yale University, July, 23–25.\nHansen, Ben, and Jake Bowers. 2009. “Attributing Effects to a Cluster-Randomized Get-Out-the-Vote Campaign.” Journal of the American Statistical Association 104 (487). Taylor & Francis: 873–85.\nHartman, Erin, RD Grieve, R Ramsahai, and Jasjeet S Sekhon. forthcoming. “From SATE to PATT: Combining Experimental with Observational Studies.” Journal of the Royal Statistical Society.\nHirano, Keisuke, Guido W Imbens, and Geert Ridder. 2003. “Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score.” Econometrica 71 (4). Wiley Online Library: 1161–89.\nHolland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association 81 (396). Taylor & Francis: 945–60.\nImai, K., L. Keele, D. Tingley, and T. Yamamoto. 2011. “Unpacking the Black Box of Causality: Learning About Causal Mechanisms from Experimental and Observational Studies.” American Political Science Review 105 (4). Cambridge Univ Press: 765–89.\nImai, Kosuke, and Teppei Yamamoto. 2013. “Identification and Sensitivity Analysis for Multiple Causal Mechanisms: Revisiting Evidence from Framing Experiments.” Political Analysis 21 (2). SPM-PMSAPSA: 141–71.\nImai, Kosuke, Luke Keele, and Teppei Yamamoto. 2010. “Identification, Inference and Sensitivity Analysis for Causal Mediation Effects.” Statistical Science. JSTOR, 51–71.\nImai, Kosuke, Gary King, and Elizabeth A Stuart. 2008. “Misunderstandings Between Experimentalists and Observationalists About Causal Inference.” Journal of the Royal Statistical Society: series A (Statistics in Society) 171 (2). Wiley Online Library: 481–502.\nImai, Kosuke, Dustin Tingley, and Teppei Yamamoto. 2013. “Experimental Designs for Identifying Causal Mechanisms.” Journal of the Royal Statistical Society: Series A (Statistics in Society) 176 (1). Wiley Online Library: 5–51.\nLin, Winston. 2013. “Agnostic Notes on Regression Adjustments to Experimental Data: Reexamining Freedman’s Critique.” The Annals of Applied Statistics 7 (1). Institute of Mathematical Statistics: 295–318.\nLohr, Sharon L. 1999. “Sampling: DesignandAnalysis.” Pacific Grove, CA: Brooks/Cole.\nNeyman, Jerzy. 1990 [1923]. “On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9.” Statistical Science 5 (4). Institute of Mathematical Statistics: 465–72 (Translated by D.M. Dabrowska and T.P. Speed from the original Polish).\nNickerson, D.W. 2008. “Is Voting Contagious? Evidence from Two Field Experiments.” American Political Science Review 102 (1). Cambridge Univ Press: 49.\nRosenbaum, Paul. 2002. “Attributing Effects to Treatment in Matched Observational Studies.” Journal of the American Statistical Association 97 (457). Taylor & Francis: 183–92.\nRosenbaum, Paul R. 2002. Observational Studies. Springer.\nRosenbaum, Paul, and Donald B. Rubin. 1983. “The Central Role of the Propensity Score in Observational Studies for Causal Effects.” Biometrika 70 (1). Biometrika Trust: 41–55.\nRosenbaum, Paul, and Jeffrey H Silber. 2008. “Aberrant Effects of Treatment.” Journal of the American Statistical Association 103 (481). Taylor & Francis: 240–47.\nRosenbaum, PR. 2010. “Design of Observational Studies.” Springer Series in Statistics. New York [etc.]: Springer. Tingley, Dustin, Teppei Yamamoto, Kentaro Hirose, Luke Keele, and Kosuke Imai. 2014. “mediation: R Package for Causal Mediation Analysis.” Journal of Statistical Software 59 (5): 1–38. http://www.jstatsoft.org/v59/i05/.\n\n\n\n\n\nFootnotes\n\n\nFor a more formal discussion of independence and the assumptions necessary to estimate causal effects, see Holland (1986) and Angrist, Joshua, and Jörn-Steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.↩︎\nSee Holland and Angrist & Pischke again for more formal discussion of independence and the assumptions necessary to estimate causal effects.↩︎\nEstimates are often written with a hat ( \\(\\widehat{ATE}\\) ) to reflect the difference between the estimate from our particular sample and the estimand, target of our estimation that is unobserved. Unless otherwise stated, in this guide we focus on generating sample estimates and subsequently omit this explicit notation for brevity. See Gerber and Green (2012) for concise introduction to this distinction and Imbens and Wooldridge (2007) for a thorough treatment of these concepts.↩︎\nThe covariance of \\(Y_{i}(1),Y_{i}(0)\\) is impossible to observe but the “Neyman” estimator of the variance omitting the covariance term provides a conservative (too large) estimate of the true sample variance because we tend to assume that the covariance is positive. Since we are generally worried about minimizing type I error rate (incorrectly rejecting true null hypothesis), we prefer using conservative estimates of the variance. See also Dunning (2010) and Gerber and Green (2012) for justification of the conservative variance estimator.↩︎\nLin (2013)↩︎\nBrambor, Clark, and Golder (2006)↩︎\nAngrist, Joshua, and Jörn-Steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton university press.↩︎\nWe typically assume monotonicity, meaning there are no defiers or people who only take the treatment when assigned to control (\\(D_{i}=1\\) when \\(Z_i=0\\)) and refuse the treatment when assigned to treatment (\\(D_{i}=0\\) when \\(Z_{i}=1\\)).↩︎\nAngrist, Joshua, and Jörn-Steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton university press.; Bound, Jaeger, and Baker (1995)↩︎\nSee Imai, King, and Stuart (2008) for a more detailed review of the issues discussed in this section.↩︎\nImbens, Guido, and Jeffrey M Wooldridge. 2007. What’s New in Econometrics? NBER.↩︎\nAngrist and Pischke (2008) provide a brief introduction of topics covered in more detail by Hirano, Imbens, and Ridder (2003), Aronow and Middleton (2013), Glynn and Quinn (2010), and Hartman et al. (forthcoming)↩︎\nGlynn, Adam N, and Kevin M Quinn. 2010. “An Introduction to the Augmented Inverse Propensity Weighted Estimator.” Political Analysis 18 (1):36–56.↩︎\nSee Hartman et al. (forthcoming) for an example of efforts to combine experimental and observational data to move from a sample ATE to an estimate of a population ATT.↩︎\nRosenbaum and Rubin (1983)↩︎\nAbadie, Angrist, and Imbens (2002)↩︎\nChernozhukov and Hansen (2005). That is, treatment can have heterogeneous effects but the ordering of potential outcomes is preserved. See Angrist and Pischke Angrist, Joshua, and Jörn-Steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton university press. See Frölich and Melly (2010) for fairly concise discussions of these issues and Abbring and Heckman (Abbring, Jaap H, and James J Heckman. 2007. “Econometric Evaluation of Social Programs, Part III: Distributional Treatment Effects, Dynamic Treatment Effects, Dynamic Discrete Choice, and General Equilibrium Policy Evaluation.” Handbook of Econometrics 6. Elsevier: 5145–5303.) (2007) for a thorough overview.↩︎\nSee Koenker, Roger, and Kevin Hallock. 2001. “Quantile Regression: An Introduction.” Journal of Economic Perspectives 15 (4): 43–56. for a concise overview of quantile regression↩︎\nFormally, Imai, Keele, and Yamamoto (2010) define the necessary conditions of sequential ignorability as: \\({Y_i(d',m),M_i(d)}⊥D_i|X_i=x, Y_i(d',m)⊥M_i(d)|D_i=d,X_i=x\\). That is, first, given pre-treatment covariates, the potential outcomes of Y and M are independent of treatment D, and, second, that conditional on pre-treatment covariates and treatment status, potential outcomes are also independent of the mediator.↩︎\nSee for example Imai, Keele, and Yamamoto (2010), Imai et al. (2011), Imai, Tingley, and Yamamoto (2013), Imai and Yamamoto (2013). Also see the discussion of Imai, Tingley, and Yamamoto (2013) for different perspectives on the desirability of addressing mediation-type claims with sensitivity or bounds-style analyses.↩︎"
  },
  {
    "objectID": "guides/getting-started/eval_conversations_en.html",
    "href": "guides/getting-started/eval_conversations_en.html",
    "title": "10 Conversations that Implementers and Evaluators Need to Have",
    "section": "",
    "text": "Abstract\nIf you are a practitioner or official from a governmental or non-governmental organization (an \"implementer\"), this guide is intended to help you to take advantage of opportunities to collaborate with external researchers (\"evaluators\") to evaluate your organization's policies or programs. Researchers working on evaluations can also benefit from this guide by understanding how to take implementers' needs into account.\nAs an implementer, what should you expect or request when collaborating with an external evaluator? How can that evaluation be designed to help your organization and the broader field to learn and innovate? What conversations should you have with an evaluator upfront so that the evaluation runs smoothly? How can you work with the evaluator to decide on and communicate actionable and convincing analyses about the impact of a program? How will you and the evaluator share what you learned to improve the practice of your organization and others? How can you ensure that what you learn helps the whole community of practice so that overall social welfare improves? This short guide offers questions to guide conversations with prospective evaluators, points to some practices that have worked well elsewhere, and explains why they might be important or useful in future evaluations.1\n\n\n1) What is the goal of the evaluation?\nThis may seem blatantly straightforward–the evaluation is to see if the program worked. Yet most policy evaluation efforts involve multiple goals. The program may be in a pilot stage, and you want to gather preliminary evidence before expanding the program. The program may have worked in one context (country, community), and you would like to know how generalizable it is. You may want to know who the program works for. Does it work differently for men or women? Marginalized communities or wealthy and powerful groups? You may want to know how part of your intervention affects other aspects of your existing interventions (e.g., cash vs. cash + training) or what combination of activities are most cost effective. You may want to know if you should try to scale the program. Or you may want to know not so much whether or not the program works, but why it works.\nAdditionally, many programs have multiple components. The program may not only be delivering a service (e.g., distributing information on how to access health services), but it may also be trying to build the capacity of a local agency; (e.g., help a public health agency to identify households for additional forms of support ). As a result, there are potentially both individual-level (i.e., micro) questions–the effect of school lunches on children–and more macro questions–how are local governments better able to identify vulnerable children?–that need answers. While both may be asked in one evaluation, the evaluators need to understand how the implementer prioritizes the two questions. This prioritization will affect the evaluation design (see the next Conversation).\nAs implementers, it's important to be clear on your goal of what you want to learn among yourselves and be clear about those goals with the evaluation team. The evaluation team or person, particularly if they are an academic or publish their work more widely, will also have goals about what they want to learn. Without being clear about what you and your organization need to learn, the evaluator may not design the most appropriate evaluation method. This takes us to the next question.\n\n\n2) What is the best method for the evaluation?\nSince evaluation efforts may serve multiple purposes for different audiences, no single research design is always best. We suggest that evaluation and implementation teams not take for granted any given approach: some evaluation teams specialize in human-centered design research which is very similar to ethnographic research in the social sciences; other teams specialize in randomized controlled trials (RCTs). The fact that any given team has expertise in one particular mode of research should not outweigh the need to connect purposes to evaluation design. We have seen such conversations yield realizations that, in fact, an \"evaluation\" ought to be a multi-step process with learning about the context and the intervention occurring along the way –- more akin to adding evidence to hone a learning agenda than to report on the estimated causal effect of a given intervention in a given place and time.\nOpenness about the evaluation approach can also prepare teams to adapt as new information arises. For example, at the end of an RCT one of the authors conducted in Nigeria, we learned that the program diffused from direct participants to some non- participants. However, we did not know why and could immediately think of competing explanations after the fact: Was it a result of non-participants witnessing cooperation among direct participants? Did the people who directly participated talk about their experience with non-participants? Did norms in these communities change? Pairing this work with interviews and observations earlier in the process would have helped us understand why we found the effect, and then we could have better tested these new ideas with follow-up studies.\nRCTs can be used to test insights that are derived from more unstructured observation. For example, the Los Angeles-based campaign specialist, David Fleischer, noticed from his own experience and those of others that certain interactions during door-to-door canvassing appeared to be particularly compelling for changing people's minds about sensitive topics. Communications between him and a pair of academics led to a series of RCTs to verify and unpack the mechanisms behind this phenomenon (called \"deep canvassing\").\nThis conversation about approach, method, and maybe iteration, between the evaluator and the implementer, can also help identify whether the intervention can be conducted in a way to better answer the questions of interest. For example, is there a way to phase in or layer parts of the program so you could test mechanisms? How might you recruit individuals into the program so that it is more representative of the populations you care about, or so that the results will be generalizable? Our general theme here (and elsewhere in this guide) is that the most useful evaluations often occur when both the evaluation and the program design are created collaboratively (see Conversation 6 below).\n\n\n3) Who are the stakeholders?\nOften there are multiple stakeholders both within the organization whose work is subject to the evaluation, but also externally (not to mention the evaluator themself, and the audiences they may want to influence by publicizing the results). Within an organization, some people work across contexts and want to understand how a program may vary in its results across those contexts. Some people implement in a specific context and want to know how to do it better in that place. Then there may be executives who are focused on external influence and raising the profile of the organization versus the program managers who are trying to use the information to adapt their programming. For example, when one of the authors was working on an evaluation related to host and refugee relationships, the HQ team cared most about the pooled results across Lebanon and Jordan. Such results allowed them to speak to the larger issue of host-refugee relations. In contrast, the field teams cared more about country-specific data so they could adapt their programming. The evaluation team worked with both the field and HQ teams to prioritize which results to produce first. In this case, the different needs within an organization did not change the evaluation design. But one could easily imagine a situation where an evaluation designed to be sensitive to the effects of a program in one place would be inappropriate in another context. If a multi-context analysis is of primary importance, then one will be glad to have had this conversation early in the design process rather than discovering that one cannot easily combine datasets.\nBoth implementers and evaluators who are committed to benefiting the larger social good will also want to influence external stakeholders, particularly policymakers. Discussing who these people are and what questions and information they will find most persuasive needs to happen not just after the data is analyzed, but at the design phase. Otherwise, the implementing organization may be disappointed that the results are not able to speak to certain debates and as a result may be less likely to invest in evidence generation in the future. We discuss more about publicizing results below.\n\n\n4) How can our evaluation enable learning within our organization?\nAn organization decides to evaluate the performance of a new (or old) policy because its members desire to learn how to improve. We state this point first and foremost because resistance to evaluation often arises from different stakeholders who think of the word \"evaluate\" and connect it with \"grade\" or \"rank\" or other attempts to measure that often distribute rewards or punishments. An organization that primarily evaluates as a form of ranking or grading will quickly run into resistance and all of the problems associated with replacing internal motivations with external carrots and sticks — carrots and sticks are blunt instruments that rarely lead to the best performance from anyone.\nIf, however, an organization uses evaluations to learn, then the structure of an evaluation should take the desire to learn into account. Some questions that might well orient any such evaluation include:\n\nWhat decisions will the organization make in the short term which would change depending on this evaluation?\nWhat hypothetical results from this evaluation could contribute to which pending and consequential decisions by the organization?\n\nEven when the purpose is to learn, not grade, some within an organization may still be fearful of the results, as they believe their careers are tied to achieving strong results. If they are not bought into the learning agenda, they may resist cooperation with the evaluators or refuse to use the results of the evaluation, limiting the evaluation's utility. Ensuring that the questions the team closest to the ground wants to learn about are incorporated into the evaluation helps ensure the success both in evaluating the program, and that people will use the results of the evaluation to learn and improve future programs.\n\n\n5) How might this evaluation connect to a broader and shared learning agenda?\nOne way to think about learning for an organization is to think about its high level goals: What is the mission of your organization and what part of that mission do you want your programs to contribute to? For example, say a county government has an overall goal of reducing racial inequality. Next imagine that you are implementing a program which provides reduced bus fares with the assumption that reduced bus fares increase employment opportunities with higher wages. You want to test this assumption, and evaluate whether the subsidies contributed to the larger goal of reducing racial inequality. In that case, one might imagine a figure or diagram illustrating this theory of change that by reducing bus fares, People of Color are better able to commute to jobs with higher wages, thus reducing racial inequality. The implementer can then work with the evaluator to design the evaluation to learn about (a) the effects of reducing bus fares on employment options and (b) about how reducing bus fares affects our overall goal of reducing racial inequality in our county.\"\nBy having this type of conversation–about how a specific program or policy may contribute to larger change–there is a recognition that one evaluation or one program is part of a larger learning agenda. This conversation then can shape a deeper collaboration between the implementer and evaluator (see the next Conversation). Evaluators are often based in academia and bring a passion to engage pressing questions of theory to their work with the hope that they uncover some underlying and generalizable truths. They also have read extensively in the field, and may be able to bring additional evidence to bear on your policy or program. If the high level learning goals of a community of evaluators and implementers can connect, then one hopes the results of individual evaluations more easily connect and cumulate into even more effective policy creation and implementation.\n\n\n6) On what parts of the project should we collaborate?\nIn our experience, when a new policy design arises from a creative collaboration between evaluators (who are often academics) and implementers, everyone wins. Often, for example, a better evaluation design can be incorporated into the implementation if discussed early, in a way that creates fewer burdens on the implementer and/or those benefiting from the new policy (e.g., aligning data collection or phasing in of intervention sites). Another benefit arising from such creative co-creation is that different people will bring different perspectives and evidence-bases to the table for the design of both the program and the evaluation. For example, the U.S. government's Office of Evaluation Sciences (OES) has institutionalized this process. They write:\nOur collaborators, who are civil servants with years of experience working to deliver programs across the government, are experts on how their programs work and often have the best ideas for how to improve them. OES team members support their efforts by bringing diverse academic and applied expertise to more deeply understand program bottlenecks and offer recommendations drawn from peer-reviewed evidence in the social and behavioral sciences.\nThe Immigration Policy Lab at Stanford uses this co-creation process as a basis for their collaboration with implementers. They work with organizations not only to research policies and programs but work with the implementer from the start. Through this process, evaluators bring the latest evidence related to a specific policy issue (e.g., refugee resettlement) and co-design the intervention with the implementer utilizing the best evidence with on-the-ground experience. Together, they then evaluate the intervention, adding to the knowledge on immigration policies.\nOther evaluations involve an evaluator brought on after the fact — perhaps the funders and/or the implementer desire a fresh perspective on the data and design, or the original implementation was rushed. Either way, \"how and on which parts should we collaborate\" is still a crucial conversation to have.\n\n\n7) How will we communicate within and across teams?\nCollaboration requires communication. This means that the parties to an evaluation agreement must agree to speedy feedback in mutually agreed upon forms and processes for how to do so. For example, some complex evaluations might create a quick web dashboard so that sample sizes and implementation can be easily seen by the whole team. Other, simpler projects may agree to use existing tools for project management and communication. Not everyone checks email all the time. And many people silence their phones as they try to focus. Having this conversation about communication allows new partners to avoid misunderstanding email or Slack silence.\nCalendars and deadlines are also an important part of this conversation. During certain periods, evaluators may be less available (e.g, when grades or a grant application is due); the implementer may need at least preliminary results for an important donor meeting. Knowing these time windows can help understand availability, know when responses may be slow, and allow both sides to plan accordingly.\nThe communication discussion is also an opportunity to envision the final products: the one-pager, the anticipated three challenges and hoped for three successes for the external-facing report, the number of drafts of the different final projects the team expects to go through, and who is expected to take the lead on which ones. This might be a time where evaluators and implementers share draft reports or report templates that they have liked in the past.\n\n\n8) How and where shall we make the results of this study public? (i.e., communicate externally)\nA well-done public evaluation report is a gift to humanity.\nConsider who will benefit from a public report of positive, negative, or null results:\n\nFuture members of your organization will be able to use the information to craft better policies.\nMembers of other organizations like yours and funders can also learn. If they share their results publically then policy learning can occur more quickly than if each organization or funder has to pay for and field its own evaluation.\nScientists and others who focus on theoretical explanations will move more quickly and will generate more ideas if they can see whether certain ideas work or not (or how they work). Published results and analysis plans help spur learning by the originating organization, by other organizations, and by science.\n\nPublishing results of evaluations also helps your organization in two important and related ways. 1) It enhances your organization's influence with donors and other policymakers, as you can inform key debates with evidence. 2) It enhances your organization's reputation as trustworthy and willing to provide a public good to improve the field. When one of the authors of this guide was working inside an implementing organization, donors often complimented the organization's commitment to sharing results that contradicted conventional wisdom.\nMoreover, publishing all results helps quell other criticisms that can be aimed at organizations that are contributing to knowledge generation. For example, some criticize evidence-based policy by calling it \"policy-based evidence.\" The criticism suggests that evaluations serve only to add a veneer of respectability to the pre-conceived notions of organizational leaders. This idea — that careful research and analyses are merely rhetoric — can diminish trust in individual organizations and in government and science as institutions. Instead, if an organization says, \"We publish all of our evaluations and invite others to scrutinize our results and join us in learning how to better serve the public,\" then it is hard for detractors to claim that the organization is hiding the truth and hard for others to pressure the organization to hide the truth in turn.\nThe timelines that implementers and evaluators, especially ones who come from academia, have for publishing results are likely different. Your organization may want to use or share the results as soon as possible, so that you can improve your programming or influence policy. However, cleaning and analyzing data takes time. And a review of the results before publishing can improve the quality of the presentation and analysis. Some academic publications prefer that the results not be shared publicly before publication in other formats. Given these benefits and constraints, it's important to talk with the evaluator about how to share the results and when and how.\n\n\n9) What if things do not go as expected or hoped?\nIn conducting an evaluation, numerous things may not go according to plan. There are many operational issues, and since an evaluation can be a multi-month or multi-year process, complications always arise. There may be staffing changes, and their commitment to the evaluation may vary. Or new staff members are interested in different questions. The context may change and the teams have to adapt. The Covid pandemic is a good example of this, as programming and how data was collected had to change practically overnight. Good communication within the team (see above) is essential for navigating these unexpected issues that will arise in some form, and ensuring the integrity of the program and evaluation.\nIn addition to these operational issues, we may find unexpected results from the evaluation. The evaluation may find that the program or policy had little effect. While null results can be disappointing, in of themselves, they can provide important learning. If the results show null effects, then the organization can re-evaluate and generate more ideas for how to implement the program. Null results can encourage more learning than one might think when they are combined with prior beliefs. Also, null results can arise for reasons that have more to do with sample size or other artifacts of the evaluation (e.g., how the outcomes were operationalized) than with the impact of the intervention. A null result arising from an intervention that, in theory, really should have had a big effect, can be particularly fruitful for science — it sends scientists back to the drawing board and forces re-evaluation of well-established theories. Perhaps those theories had only been tested in the context of university laboratories rather than in the real world. Or perhaps the real world in which the theories had been assessed in the past has now changed. See for example the handout on How to Use Unexpected and Null Results by the OES and our 10 Things Your Null Result Might Mean methods guide.\nWhile nulls or other unintended impacts provide important learning for an organization, they can create uncomfortable conversations with the evaluator and internally within an organization. As a result, thinking through these possibilities ahead of time can be very useful so that people are not surprised. There are a couple of tools that help the implementer and evaluator think through these together.\nOne approach arising from project management in business involves the creation of pre-mortems in which the implementer and evaluator begin by imagining that the evaluation has returned a null or negative result. What might have led to this result? The teams list the possibilities that they can imagine and thereby become prepared for those and similar problems.\nAnother related approach from public health uses the name 'Dark Logic' to evoke the idea that one uses imagination and logic together to create negative scenarios, which in turn may (1) help an organization and evaluator avoid worst-case scenarios and (2) prepare an organization to react to such scenarios should they occur.\nA third approach that is becoming the norm for experimental research in political science, economics, and social psychology is to use a pre-analysis plan. People can sometimes disregard an evaluation if the results do not confirm their beliefs. A pre-analysis plan helps prevent criticism of the results of the evaluation based on methods or analysis choices. See 10 Things to Know about Pre-Analysis Plans for more on why and how. See also Preregistration as a Tool for Strengthening Federal Evaluation from OES.\nA pre-analysis plan also can help stakeholders within an organization, perhaps stakeholders with conflicting prior beliefs, think through what analyses they would find convincing before the study has been fielded/data have been analyzed. For example, an evaluator could generate hypothetical tables and figures and show them to stakeholder meetings asking: \"What would your reaction be to a figure like this?\" This process helps stakeholders begin to assess the evaluation questions in more detail, ensure that measures are operationalized appropriately, and consider the level of implementation that is needed for the desired results. It also helps stakeholders become aware of the possibility that we may learn something unexpected.\n\n\n10) How can our evaluation contribute to the social good?\nA premise of this guide is that the evaluation will contribute to the social good. Yet we think that a conversation about this more generally can help implementers and evaluators collaborate more effectively by providing a superordinate goal to unite the whole team. Further, we encourage this conversation to ensure that all of the evaluation effort adds to the overall efforts to improve the world.\nAlthough we exhort such conversations in general terms, we also think that an evaluation can add to the social good fairly directly via transparency of methods and, to the extent possible, by sharing data. That is, in addition to the evaluation itself, the data you collect as part of the evaluation, the plans you make, the code the evaluators write, is also a social good. In the social sciences, there is a movement towards more openness of data–sharing the data and how it is analyzed – as an effort to speed scientific learning. This, in addition to a pre-analysis plan or pre-registration, is becoming required of many journals. We see this kind of transparency as adding to the impact of an evaluation outside of a given organization and providing a net benefit for your organization and the field for several reasons.2\n\nEfficiency of time and money: Collecting data is time consuming and expensive. The data you collect may be analyzed by others in additional ways to answer different questions, and help explore potential innovations.\nEnhances data quality: In some places, participants in programs may suffer from being over-surveyed. By sharing data, it reduces the need to ask people the same questions repeatedly. This helps reduce survey fatigue and enhances data quality.\nIncreases confidence in results: Others can replicate your findings with the same or different analysis choices. Real world data analysis involves many choices, and data flows from the world of administrative data, surveys, and interviews into the hands of the analyst via a twisting and turning path. Some of the reasonable choices made by one analyst may not be the reasonable choices made by another. Since both choices may be reasonable, and even correct, it is worth having a second team, blind to the results of the first analysis, follow the analysis plan following their own interpretation. The OES have institutionalized this practice: See \"Step 5: Ensure our work meets evaluation best practice\" of the OES Project Process for their re-analysis report document and explanation.\nIncreases the trust in your organization: That your organization is willing to share data demonstrates that you have nothing to hide and that you are willing to contribute to the public good.\n\nFor more on Open Science, see 10 Things to Know About Project Workflow which is based on the more fun titled paper \"How to Improve Your Relationship With Your Future Self.\"\n\n\n\n\n\nFootnotes\n\n\nMuch of this document is inspired by the Project Process of the OES as well as discussions hosted by the Causal Inference for Social Impact project at CASBS and the Evidence in Governance and Politics network. See the MIT Gov Lab Guide to Difficult Conversations for more guidance about academic-practitioner collaborations as well as the Research4Impact findings about cross-sector collaborations. We anticipate that this document will be open source and revised over time based on your comments and suggestions. Thanks much to Carrie Cihak, Matt Lisiecki, Ruth Ann Moss, Betsy Rajala, Cyrus Samii, Rebecca Thornton,, and folks at the organizations listed above for helpful comments.↩︎\nWe do recognize that some donors may not allow this (though many are becoming proponents of it), and the competitive nature of fundraising may make sharing data seem risky, especially as a first mover.↩︎"
  },
  {
    "objectID": "guides/getting-started/external-validity_en.html",
    "href": "guides/getting-started/external-validity_en.html",
    "title": "10 Things You Need to Know About External Validity",
    "section": "",
    "text": "Abstract\nAfter months or years under development and implementation, navigating the practical, theoretical and inferential pitfalls of experimental social science research, your experiment has finally been completed. Comparing the treatment and control groups, you find a substantively and statistically significant result on an outcome of theoretical interest. Before you can pop the champagne in celebration of an intervention well evaluated, a friendly colleague asks: “But what does this tell us about the world?”\n\n\n1. What is external validity?\nExternal validity is another name for the generalizability of results, asking “whether a causal relationship holds over variation in persons, settings, treatments and outcomes.”1 A classic example of an external validity concern is whether traditional economics or psychology lab experiments carried out on college students produce results that are generalizable to the broader public. In the political economy of development, we might consider how a community-driven development program in India might apply (or not) in West Africa, or Central America.\nExternal validity becomes particularly important when making policy recommendations that come from research. Extrapolating causal effects from one or more studies to a given policy context requires careful consideration of both theory and empirical evidence. This methods guide discusses some key concepts, pitfalls to avoid, and useful references to consider when going from a Local Average Treatment Effect to the larger world.\n\n\n2. How is this different than internal validity?\nInternal validity refers to the quality of causal inferences being made for a given subject pool. As originally posited by Campbell,2 internal validity asks, “did in fact the experimental stimulus make some significant difference in this specific instance.” This concept dovetails with the counterfactual approach to causality that experimentalists typically use, which asks whether outcomes change depending on the presence or absence of a treatment.3\nBefore you can extrapolate a causal effect to a distinct population, it is vital that the original Average Treatment Effect be based on a well-identified result. For most experimentalists, random assignment provides the requisite identifying variation, provided no attrition, interference, spillovers, or other threats to inference. For observational studies, additional identifying assumptions are needed, such as conditional independence of the treatment from potential outcomes.\n\n\n3. Navigating the trade-offs between internal and external validity\nThere has been an ongoing debate within the social sciences regarding the relative importance of identifying internally valid results, which by definition apply to a local sample, and generating results that can be extrapolated to broader populations of interest. It is helpful to be familiar with this discussion when considering design trade-offs that inevitably crop up in resource-limited interventions. That both sides of the argument include luminaries of econometrics attests to the importance of the topic.\nOn one side of the argument fall advocates of “identification first,” who argue that without internally valid results, a study simply does not contribute useful information, regardless of whether it is a local or general population or context. As put by Imbens,4 “without strong internal validity studies have little to contribute to policy debates, whereas [internally valid] studies with very limited external validity often are, and in my view should be, taken seriously in such discussions.”\nOthers argue that even without full identification of an internally valid result, useful information can be salvaged, especially if it is relevant for important questions that affect a broad context. Manski5 writes that “what matters is the informativeness of a study for policy making, which depends jointly on internal and external validity.” With data from a broad but a poorly identified study, Manski argues, bounds on the estimand of interest can be generated that, while not as useful as a precise point estimate, still moves science forward.\n\n\n4. Theory and generalization\nExtrapolating a result to a distinct context, outcome, population or treatment is not a mechanical process. As discussed by Samii6 and Rosenbaum,7 relevant theory should be used to guide generalization, taking the relevant existing evidence and making predictions for other contexts in a principled fashion. Theories boil down complex problems into more parsimonious representations, and help to elucidate what factors matter. Just as theory guides the content of interventions and research designs, theoretical propositions can tell you which scope conditions are relevant for extrapolating a result. What covariates matter? What contextual information matters?\n\n\n5. How can I determine where my results apply?\nThere are two primary means of generalizing results, one based on the covariates of units in the study and the other based on actual experimental manipulation of moderating variables. Observing how a treatment effect varies over a non-randomized pre-treatment variable can describe treatment effect heterogeneity, which can be highly suggestive about where or for whom the intervention is likely to be most effective, beyond the original sample. Note, however, that this type of analysis cannot pin down whether the treatment-effect heterogeneity is caused by that pre-treatment variable. The concern—endemic to observational research—is that the non-randomized covariate may be correlated with an unobserved variable, and it is this “unseen” factor that in fact is responsible for the heterogeneous impacts of the treatment.8 Ideally, therefore, we want to leverage exogenous variation in the moderator of interest, thereby ruling out the possibility of such confounding. A factorial experimental design in which the researcher assigns the moderator independently of the main treatment of interest can generate especially compelling evidence about a moderator’s role. Though, of course, considerations of cost and statistical power may preclude this approach in practice.\nBecause generalization is primarily a prediction exercise, asking where we can expect a causal relationship similar to one observed locally, extrapolating heterogeneous effects based on similar covariates is often reasonable, provided theory does not indicate sources of confounding.9 Nonetheless, the strongest evidence for the generalizability of a result comes from a well-identified interaction between an exogenous moderator and the treatment, then projected across the covariate profile of a target population. Indeed, with some strong assumptions extrapolation can provide as good or better results than carrying out a second experiment in situ.10 The calculation of an extrapolated estimate can often be best performed using machine learning, although linear regression also performs reasonably well.11\n\n\n6. Strategic behavior can scuttle your extrapolations\nExtrapolating a local result to a different context can prove challenging even with a compelling covariate profile to which you want to generalize effects. A randomized experimental manipulation in a local area generates a “partial equilibrium effect.” Strategic dynamics, including compensatory behavior or backlashes, outside the local context of an experimental intervention can complicate efforts to generalize a result. Suppose, for example, that an unconditional cash transfer intervention is shown to increase welfare, entrepreneurship, and employment in a sample of 200 villages. What would happen if the intervention were extended to encompass 1000 villages? At this point, one could imagine that regions excluded from the program are more likely to learn about it. Untreated units may start to demand other types of transfers from the government, giving rise to effects similar to those produced by the direct cash transfer. In a similar vein, sometimes causal relationships only work when they are applied to some people. For example, imagine a job skills program that functions very well (as compared to those who did not receive it), what would happen if it were extended to all workers? Even if there are positive effects across all participants, there could be reduced or no average effects as higher skilled jobs are already filled by the first batch and the second batch is forced to remain in their previous jobs, now overqualified. In short, under general equilibrium conditions we might expect different results even where the covariate profile matches.\n\n\n7. Don’t confuse external validity with construct validity or ecological validity\nInternal and external validity are not the only ‘validity’ concerns that can be leveled at experimental work, and though relevant, they are also distinct. Ecological validity, as defined by Shadish, Cook and Campbell12 concerns whether an intervention appears artificial or out of place when deployed in a new context. For example, does an information workshop in a rural town carried out by experimenters resemble the kinds of information sharing that the population may experience in regular life? Similarly, if the same workshop were held in a large city, would it appear out of place?\nConstruct validity considers whether a theoretical concept being tested in a study is appropriately operationalized by the treatment(s). If your experiment is testing the effect of anger on political reciprocity and you are in fact manipulating fear or trust in your treatment, construct validity may be violated. Both construct and ecological validity are relevant for generalizations, and thus useful for making claims about external validity.\n\n\n8. Extrapolation across treatments and outcomes\nWhile much of this guide has implicitly focused on porting a given treatment to a new place or time, external validity also considers variations in treatments and outcomes. That is, imagine we did the same experiment on the same sample, but with a variation on the treatment, would we predict the local causal effect to be similar? Similarly, can we predict if a given treatment will produce the same or different causal effects on a different outcome? Sometimes we can address these concerns by conducting experiments that assess alternative treatments and outcomes. When follow-up experiments are in short supply, such issues have to be settled analytically. Rather than considering the features of subjects, extrapolation in this case requires thinking through, aided by theory, the characteristics of the treatments or outcomes and making reasonable predictions.\n\n\n9. Replication is important\nNo single study represents the final word on a scholarly question. Following the logic of Bayesian updating, additional evidence in favor of or against a given theory allows the scientific and policy community to update their beliefs about the strength and validity of a causal relationship.\nReplication of studies is an important part of this: scholars should replicate studies in contexts that look very different, but also in some contexts that look very similar. The former allows us to identify local causal relationships that can be triangulated with existing evidence and generalized as appropriate. At the same time, it is important to directly replicate existing studies under conditions that are as close as possible to the original in order to verify that local effects one may be interested in extrapolating are indeed reliable. The Open Science Collaboration13 found, for example, that when reproducing 100 major psychology experiments, just 47% of the original reported effect sizes fell within the 95% confidence interval of the effect size shown in the replication.\n\n\n10. Don’t forget time\nWhen thinking about causal relationships of interest, it is important also to consider time: do things we learn about the past extend to the future? How do an individual’s potential outcomes change over time? Immutable laws govern the physical and chemical worlds; hence what we learn about these laws today will always remain true. By contrast, we understand far less about the underlying drivers of social behavior and whether they hold constant in the same way. The answer may well be no. When making decisions about the policy relevance and generalizability of results, these considerations can help scholars determine a reasonable level of uncertainty and help policy makers adjust accordingly.\n\n\n\n\n\nFootnotes\n\n\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002). Experimental and quasi-experimental designs for generalized causal inference. Houghton, Mifflin and Company.↩︎\nCampbell, D. T. (1957). Factors relevant to the validity of experiments in social settings. Psychological bulletin, 54(4), 297.↩︎\nMore details can be found in the causal inference methods guide: https://egap.org/resource/10-things-to-know-about-causal-inference↩︎\nImbens, G. (2013). Book Review Feature: Public Policy in an Uncertain World: By Charles F. Manski. The Economic Journal,123(570), F401-F411.↩︎\nManski, C. F. (2013). Response to the review of ‘public policy in an uncertain world’. The Economic Journal 123: F412–F415.↩︎\nSamii, Cyrus. (2016). “Causal Empiricism in Quantitative Research.” Journal of Politics 78(3):941–955.↩︎\nRosenbaum, Paul R. (1999). “Choice as an Alternative to Control in Observational Studies” (with discussion). Statistical Science 14(3): 259–304.↩︎\nGerber, A. S., & Green, D. P. (2012). Field experiments: Design, analysis, and interpretation. WW Norton.↩︎\nBisbee, James; Rajeev Dehejia; Cristian Pop-Eleches & Cyrus Samii. (2016). “Local Instruments, Global Extrapolation: External Validity of the Labor Supply-Fertility Local Average Treatment Effect.” Journal of Labor Economics↩︎\nBisbee, James; Rajeev Dehejia; Cristian Pop-Eleches & Cyrus Samii. (2016). “Local Instruments, Global Extrapolation: External Validity of the Labor Supply-Fertility Local Average Treatment Effect.” Journal of Labor Economics↩︎\nKern, H. L., Stuart, E. A., Hill, J., & Green, D. P. (2016). Assessing methods for generalizing experimental impact estimates to target populations. Journal of Research on Educational Effectiveness, 9(1), 103-127.↩︎\nShadish, W. R., Cook, T. D., & Campbell, D. T. (2002). Experimental and quasi-experimental designs for generalized causal inference. Houghton, Mifflin and Company.↩︎\nOpen Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.↩︎"
  },
  {
    "objectID": "guides/getting-started/het-effects_en.html",
    "href": "guides/getting-started/het-effects_en.html",
    "title": "10 Things to Know About Heterogeneous Treatment Effects",
    "section": "",
    "text": "Abstract\nThis guide1 discusses methods for analyzing heterogeneous treatment effects: testing for heterogeneity, estimating subgroup treatment effects and their differences, and addressing the pitfalls of multiple comparisons and ad hoc specification search.2\n\n\n1 What Is Treatment Effect Heterogeneity?\nAny given treatment might affect different experimental subjects in different ways. The study of treatment effect heterogeneity is the study of these differences across subjects: For whom are there big effects? For whom are there small effects? For whom does treatment generate beneficial or adverse effects? Research on such questions can help inform theories about the conditions under which treatments are especially effective or ineffective; it can also help inform ways of designing and deploying policies so as to maximize their effectiveness.\n\n\n2 Testing for Heterogeneity\nAs a first step, one might be interested in whether the variance of the treatment effect \\(\\tau_i\\) across subjects is statistically distinguishable from zero and seek to test the null hypothesis that \\(Var(\\tau_i) = 0\\) (which is equivalent to the hypothesis of a constant treatment effect, i.e., \\(\\tau_i = \\tau, \\forall i\\)). However, it is not possible to estimate \\(Var(\\tau_i)\\) in an experimental setting because you never get to see the treatment effect for any particular individual. Instead, you only get to see the outcome for each person either in the treatment or in the control condition.3\nTo illustrate this, we can rewrite \\(Var(\\tau_i)\\) as \\[\n\\begin{aligned}\nVar(\\tau_i) &= Var(Y_i(1) - Y_i(0)) \\\\\n&= Var(Y_i(1)) + Var(Y_i(0)) - 2Cov(Y_i(1),Y_i(0))\n\\end{aligned}\n\\] The term \\(Cov(Y_i(1),Y_i(0))\\) on the right-hand side cannot be estimated in an experiment because we only observe a subject’s treated potential outcome or untreated potential outcome, not both.\nAlthough we cannot estimate \\(Var(\\tau_i)\\), the hypothesis that \\(Var(\\tau_i) = 0\\) does have the testable implication that the distributions of the treated and untreated potential outcomes are identical except for a constant shift \\(\\tau\\). Randomization inference (Fisher 1935) allows us to test this implication without additional modeling assumptions, asymptotics, or regularity conditions.4\n1. Compare treatment and control outcome variances. Under the null hypothesis of a constant treatment effect, the variances of the treated and untreated potential outcomes are equal: \\(Var(Y_i(1)) = Var(Y_i(0))\\). This is because \\[\n\\begin{aligned}\nVar(Y_i(1)) &= Var(Y_i(0) + \\tau_i) \\\\\n&= Var(Y_i(0)) + Var(\\tau_i) + 2 \\cdot Cov(Y_i(0),\\tau_i)\n\\end{aligned}\n\\] and under the null hypothesis, \\(Var(\\tau_i) = 0\\) and \\(Cov(Y_i(0),\\tau_i) = 0\\). Thus, we can test the null by testing the implication that \\(Var(Y_i(1)) = Var(Y_i(0))\\).\nTo implement the test, first use the experimental data to estimate the average treatment effect (ATE) and the difference in variances \\(Var(Y_i(1)) - Var(Y_i(0))\\). Next, create a full hypothetical schedule of potential outcomes assuming that the true treatment effect is constant and equal to the estimated ATE. Finally, to obtain a \\(p\\)-value, simulate random assignment a large number of times and calculate how often the simulated estimate of the difference in variances is at least as large (in absolute value) as the actual estimate.\n\nrm(list = ls(all = TRUE))\nset.seed(1234567)\n# Sample data generating process\nn = 100\nY0 = rnorm(n)\nY1 = Y0 + 2*(1:n)/n  # Treatment effect ranging from 0.02 to 2\nt = sample( rep(c(TRUE, FALSE), each = n/2) )  # Randomly assign treatment\nY = t * Y1 + (1 - t) * Y0  # Observed outcome\n# Estimate ATE\ndiff.mean = function(treated, Y) {\n  mean(Y[treated]) - mean(Y[!treated])\n}\nest.ate = diff.mean(t, Y)\nest.ate\n\n[1] 1.282838\n\n# Estimate absolute value of the difference in variances\nabs.diff.var = function(treated, Y) {\n  abs( var(Y[treated]) - var(Y[!treated]) )\n}\nobserved.stat = abs.diff.var(t, Y)\nobserved.stat\n\n[1] 0.3654271\n\n# Create hypothetical schedule of potential outcomes assuming that\n# the true treatment effect is constant and equal to est.ate\nY0.hyp  =  Y - est.ate * t\nY1.hyp  =  Y + est.ate * (1 - t)\n# Calculate p-value\np.value = function(observed.stat, treated, Y1, Y0, sims = 1000) {\n  sim.stats = numeric(sims)\n  for (i in 1:sims) {\n    t.sim  =  sample(treated)  # Simulate random assignment\n    Y.sim  =  t.sim * Y1  +  (1 - t.sim) * Y0\n    sim.stats[i]  =  abs.diff.var(t.sim, Y.sim)\n  }\n  mean(sim.stats >= observed.stat)\n}\np.value(observed.stat = observed.stat, treated = t, Y1 = Y1.hyp, Y0 = Y0.hyp)\n\n[1] 0.203\n\n# Additional code to calculate power\nreps = 1000\nsim.p.values = numeric(reps)\nfor (i in 1:reps) {\n  t.sim  =  sample(t)\n  Y.sim  =  t.sim * Y1  +  (1 - t.sim) * Y0\n  est.ate.sim = diff.mean(t.sim, Y.sim)\n  Y0.hyp.sim  =  Y.sim - est.ate.sim * t.sim\n  Y1.hyp.sim  =  Y.sim + est.ate.sim * (1 - t.sim)    \n  sim.p.values[i] = p.value(observed.stat = abs.diff.var(t.sim, Y.sim), treated = t.sim,\n                            Y1 = Y1.hyp.sim, Y0 = Y0.hyp.sim)\n}\nmean(sim.p.values < 0.05)  # Estimated power\n\n[1] 0.181\n\n\nThis approach is limited because power for tests of differences in variances is weaker than power for tests of differences in means; thus you might often fail to reject the null hypothesis of a constant treatment effect even when there is real heterogeneity in effects. Another limitation of this method is that it is uninformative when heterogeneous treatment effects exist but the variances of \\(Y_i(0)\\) and \\(Y_i(1)\\) are equal. A third limitation, discussed by Ding, Feller, and Miratrix (2016), is that because the hypothetical schedule of potential outcomes is based on the estimated ATE instead of the unknown true ATE, the approach is not guaranteed to yield a valid test of the constant treatment effect hypothesis. To address this problem, they suggest a “Fisher randomization test confidence interval” (FRT CI) method, described below.\n2. Compare treatment and control marginal cumulative distribution functions. As an alternative to comparing variances, one can compare the marginal cumulative distribution functions (CDFs) of the outcome between treatment and control. Under the null hypothesis of a constant treatment effect, the two CDFs differ only by a constant shift.\nThe first key change to the randomization inference procedure detailed above is the use of a different test statistic. Ding, Feller, and Miratrix (2016) suggest using a Kolmogorov-Smirnov (KS) statistic to measure the maximum pointwise distance between the treatment and control CDFs after shifting the treatment CDF by a constant treatment effect \\(\\tau\\). The test statistic is \\[ t_{KS}(\\tau) = \\max_y | \\hat{F}_0(y) - \\hat{F}_1(y + \\tau) | \\] where \\(\\hat{F}_0(\\cdot)\\) and \\(\\hat{F}_1(\\cdot)\\) denotes the empirical CDFs of the outcome in the control group and treatment group, respectively.\nDing, Feller, and Miratrix suggest plugging in the estimated average treatment effect \\(\\hat{\\tau}\\) for \\(\\tau\\). Their “shifted” KS statistic \\[ t_{SKS} = \\max_y | \\hat{F}_0(y) - \\hat{F}_1(y + \\hat{\\tau}) | \\] is appropriate for testing the hypothesis that the true treatment effect is constant and equal to the estimated ATE.\nThe second key change that Ding, Feller, and Miratrix suggest is the FRT CI method, which addresses the problem that the true ATE may differ from the estimated ATE. The basic idea is that instead of using just one value for the hypothesized constant treatment effect to create the full schedule of potential outcomes for a randomization test, we can try a range of hypothesized constant treatment effects and find the maximum \\(p\\)-value over all the resulting randomization tests. They first construct a 99.9% confidence interval for the ATE (using the Neyman variance estimator), which becomes the range of hypothesized constant treatment effects. They then find the maximum \\(p\\)-value over all the resulting randomization tests and add an increment of 100% - 99.9% = 0.001. This method is guaranteed to yield a valid test of the constant treatment effect hypothesis if the confidence interval used is exactly valid. In practice, the CI is only approximately valid, but the FRT CI method with the shifted KS statistic still yields an exact or conservative test in their simulations.\n\n\n3 Conditional Average Treatment Effects (CATEs)\nA more structured, theory-driven inquiry of treatment effect heterogeneity involves pre-specifying and investigating conditional average treatment effects (CATEs). A CATE is an average treatment effect specific to a subgroup of subjects, where the subgroup is defined by subjects’ attributes (e.g., the ATE among female subjects) or attributes of the context in which the experiment occurs (e.g., the ATE among subjects at a specific site in a multi-site field experiment).\n\n\n4 Interaction Effects: Treatment-by-Covariate versus Treatment-by-Treatment\nIn addition to CATEs, researchers are also interested in treatment-by-covariate interaction effects, or the difference between two CATEs when the covariate partitioning subjects into subgroups is not experimentally manipulated. For example, one might estimate an ATE for female subjects and an ATE for male subjects but actually care about whether the difference in ATEs between the female and male subgroups is statistically distinguishable from zero. To ensure unbiased estimation of CATEs and of interaction effects, the covariate used to partition subjects into subgroups must be a pre-treatment covariate and must be measured using the same procedure for all subjects across experimental groups. A treatment-by-covariate interaction can be interpreted as a descriptive measure of association between the covariate and the treatment effect, but does not necessarily represent the causal effect of a change in the covariate value on the ATE if the covariate is not randomly assigned.\nIn contrast to treatment-by-covariate interactions, treatment-by-treatment interactions are differences in CATEs where the personal or contextual attribute partitioning subjects into subgroups is experimentally manipulated. Because the covariate is randomly assigned, treatment-by-treatment interactions may be interpreted causally. Factorial and partial factorial designs allow researchers to randomly assign subjects to different combinations of “cross-cutting” treatment conditions and to estimate treatment-by-treatment interactions as allowed by the design.\n\n\n5 Estimating CATEs and Interaction Effects\nEstimating CATEs and interaction effects is straightforward. Nonparametrically, the CATE may be estimated by calculating the ATE among subjects in the specific subgroup of interest. Interaction effects may be estimated by differencing relevant CATEs.\nCATEs and interaction effects may also be estimated in a regression framework. Here is an example for a hypothetical experiment evaluating the effect of a job training program on future earnings. Let \\(Y\\) be the outcome (future earnings), \\(Z\\) be the treatment variable (1=job training program, 0=control), and \\(X\\) be a pre-treatment covariate (1=scholarship receipt, 0=no scholarship). The model \\[\n\\begin{aligned}\nY_i &= \\alpha + \\beta Z_i + \\gamma X_i + \\varepsilon_i \\label{null}\n\\end{aligned}\n\\] allows us to estimate the ATE (\\(\\beta\\)) only. We can add an additional term interacting \\(Z\\) and \\(X\\), which yields \\[\n\\begin{aligned}\nY_i &= \\alpha + \\beta Z_i + \\gamma X_i + \\delta Z_iX_i + \\varepsilon_i \\label{alt}\n\\end{aligned}\n\\] where the coefficient \\(\\delta\\) is the interaction effect and is interpreted as the difference between the ATE of the job training program among subjects receiving a scholarship and the ATE of the job training program among subjects not receiving a scholarship. This has a causal interpretation (i.e., \\(\\delta\\) is a treatment-by-treatment interaction) when scholarship receipt is randomly assigned and a descriptive interpretation (i.e., \\(\\delta\\) is a treatment-by-covariate interaction) when scholarship receipt is not randomly assigned.\nThe model with the interaction also allows us to back out the values of the CATEs. The ATE of the job training program among subjects who do not receive a scholarship is \\(\\beta\\). The ATE of the job training program among subjects who receive a scholarship is \\((\\beta + \\delta)\\).\n\n\n6 Hypothesis Testing for Interaction Effects\nTo test whether the estimated interaction effect could have occurred by chance, one can use randomization inference: First generate a full schedule of potential outcomes under the null hypothesis that the true treatment effect is constant and equal to the estimated ATE. Then simulate random assignment a large number of times and calculate how often the simulated estimate of the interaction effect is at least as large (in absolute value) as the actual estimate.\nOne can also conduct randomization inference in a regression framework. One method suitable for two-sided tests involves using the \\(F\\)-statistic as the test statistic, where the null model is \\[\n\\begin{aligned}\nY_i &= \\alpha + \\beta Z_i + \\gamma X_i + \\varepsilon_i\n\\end{aligned}\n\\] and the alternative model is \\[\n\\begin{aligned}\nY_i &= \\alpha + \\beta Z_i + \\gamma X_i + \\delta Z_iX_i + \\varepsilon_i .\n\\end{aligned}\n\\]\n\n# Sample code for RI using F-stat as test statistic\n# Code adapted from: http://isps.its.yale.edu/isps/public/Gerber_Green_FEDAI_2012/\n#                    Chapter-9/GerberGreenBook_Chapter9_PlotandFtest_Figure_9_1.R\nrm(list = ls(all = TRUE))\nset.seed(1234567)\n# Let:\n# Y = observed outcome\n# Z = treatment assignment (complete randomization)\n# X = covariate\nn <- 1000\nZ <- sample( rep(c(1, 0), each = n/2) )\nX <- sample( rep(c(1, 0), each = n/2) )\nY <- rnorm(n)\nnumiter <- 1000 # No. of RI iterations (use more for greater precision, fewer for greater speed)\n# estimate ATE\nestate <- mean(Y[Z==1]) - mean(Y[Z==0])\n# construct hypothetical schedule of potential outcomes\n# using constant effects assumption where tau_i == estate\nY0 <- Y - estate*Z\nY1 <- Y + estate*(1-Z)\n# estimate CATEs\nestcate0 <- mean(Y[X==0 & Z==1]) - mean(Y[X==0 & Z==0])\nestcate1 <- mean(Y[X==1 & Z==1]) - mean(Y[X==1 & Z==0])\nlm1  <- lm(Y~Z*X)  # alternative model\nlm2  <- lm(Y~Z+X)  # null model\nFtest <- (sum(lm2$residuals^2) - sum(lm1$residuals^2)) / (sum(lm1$residuals^2) / (n - 4))\n# or alternatively\n# library(lmtest)\n# Ftest <- waldtest(lm1,lm2)$F[2]\nFdist <- rep(NA,numiter)\nfor (i in 1:numiter) {\n    Zri <- sample(Z)\n    Yri <- Y0*(1-Zri) + Y1*Zri\n    estcate0ri <- mean(Yri[X==0 & Zri==1]) - mean(Yri[X==0 & Zri==0]) \n    estcate1ri <- mean(Yri[X==1 & Zri==1]) - mean(Yri[X==1 & Zri==0])\n    \n    lm1ri  <- lm(Yri~Zri*X)\n    lm2ri  <- lm(Yri~Zri+X)\n    Fdist[i] <- (sum(lm2ri$residuals^2) - sum(lm1ri$residuals^2)) / (sum(lm1ri$residuals^2) / (n - 4))\n    # or alternatively\n    # Fdist[i] <- waldtest(lm1ri, lm2ri)$F[2]   \n    }\n#p-value\nmean(Fdist >= Ftest)\n\n[1] 0.525\n\n\nFor one-sided tests, the coefficient on the interaction term may be used as the test statistic, given the appropriate model.\n\n\n7 Multiple Comparisons\nResearchers interested in heterogeneous treatment effects are likely to encounter the problem of multiple comparisons: for example, when numerous subgroup analyses are conducted, the probability that at least one result looks statistically significant at the 5 percent level may be considerably greater than 5 percent even when the treatment has no effect on anyone.5\nOne way to mitigate the multiple comparisons problem is to reduce the number of tests conducted (e.g., by analyzing a small number of pre-specified subgroups). Another approach is to adjust the \\(p\\)-values to account for the fact that multiple hypotheses are being tested simultaneously.\n7.1 Familywise error rate (FWER) control methods\nFamilywise error rate (FWER) control methods limit the probability of making at least one type I error given the number of tests conducted. Suppose one is testing \\(K\\) hypotheses, \\(H_1, H_2, \\ldots, H_K\\), and \\(K_0\\) of the \\(K\\) hypotheses are true, where \\(K_0 \\le K\\). The familywise error rate is the probability that at least one of the \\(K_0\\) true hypotheses is falsely rejected. The FWER increases in the number of hypotheses tested. FWER control methods adjust the \\(p\\)-values so that, for example, if we reject a hypothesis only when the adjusted \\(p\\)-value is less than 0.05, the FWER will not exceed 5 percent.\nThe most conservative FWER control method is the Bonferroni correction, which multiplies the \\(p\\)-values by the number of tests conducted. (If the result exceeds 1, the adjusted \\(p\\)-value is set to 1.) For example, suppose we tested the significance of four interaction effects and found unadjusted \\(p\\)-values of 0.02, 0.04, 0.2, and 0.3. The adjusted \\(p\\)-values would then be 0.08, 0.16, 0.8, and 1. This approach has limitations because one quickly loses statistical power with just a few tests.\nThe Westfall–Young step-down procedure is an alternative FWER control method that can be more powerful than the Bonferroni correction because it takes into account correlations between the tests.6 The procedure involves the following steps:7\n\nGiven a family of \\(K\\) null hypotheses (where each hypothesis corresponds to a subgroup or interaction of interest), sort the hypotheses in order of decreasing statistical significance (increasing \\(p\\)-value): \\(p_1 \\leq p_2 \\leq \\ldots \\leq p_K\\).\nSimulate the sharp null hypothesis of no treatment effect by performing a large number \\(L\\) of replications of random assignment of treatment, leaving the outcome and covariate data unchanged.\nFor each replication, compute a set of simulated \\(p\\)-values, \\(p_1^*, \\ldots, p_K^*\\). (Do not sort the simulated \\(p\\)-values. Keep the ordering of hypotheses from step 1, so that, e.g., \\(p_1^*\\) corresponds to the same hypothesis as \\(p_1\\).)\nCompute the adjusted \\(p\\)-values as follows:\n\n\\[ p_1^{adj} = \\frac{\\mbox{No. of replications where } \\min (p_1^*, \\ldots, p_K^*) \\leq p_1}{L}\\]\n\\[ p_2^{adj} = \\max \\left(p_1^{adj}, \\ \\frac{\\mbox{No. of replications where } \\min (p_2^*, \\ldots, p_K^*) \\leq p_2}{L} \\right)\\]\n\\[ p_3^{adj} = \\max \\left(p_2^{adj}, \\ \\frac{\\mbox{No. of replications where } \\min (p_3^*, \\ldots, p_K^*) \\leq p_3}{L} \\right)\\]\n\\[ \\ldots \\]\n\\[ p_K^{adj} = \\max \\left(p_{K-1}^{adj} \\, , \\ \\frac{\\mbox{No. of replications where } p_K^* \\leq p_K}{L} \\right)\\]\nR functions to implement the Westfall–Young step-down procedure are available in Porter (2016)8 and the package multtest9.\n7.2 False discovery rate (FDR) control methods\nFalse discovery rate (FDR) control methods control the expected proportion of rejected null hypotheses that are type I errors. Formally, \\(FDR = E[V \\, / \\, R]\\) where \\(V\\) is the number of rejected nulls that are actually true, \\(R\\) is the total number of rejected nulls, and \\(V \\, / \\, R\\) is defined as \\(0\\) if \\(R = 0\\). An equivalent definition is \\(FDR = Pr[R > 0] \\times E[V \\, / \\, R \\mid R > 0]\\).\nThe basic procedure developed by Benjamini and Hochberg (1995)10 involves the following steps to control the FDR. As in the setup to control the FWER, specify \\(K\\) hypotheses \\(H_1, \\ldots, H_K\\) and index the hypotheses in order of decreasing statistical significance so that \\(p_1 \\leq p_2 \\leq \\ldots \\leq p_K\\). Let \\(q \\in (0,1)\\) be the desired upper limit on the FDR. Let \\(c\\) be the largest index for which \\(p_c \\leq (cq \\, / \\, K)\\). Reject \\(H_1, \\ldots, H_c\\) but do not reject any other hypotheses in the family. This procedure controls the FDR at level \\(q\\, (K_0 \\, / \\, K) \\leq q\\) where \\(K_0\\) is the number of true null hypotheses.11\nFDR control tends to be less conservative than FWER control and is popular in fields such as genomics, where, as Westfall et al. (2011, p. 14) write, “the number of hypotheses can easily be in the thousands or millions, [and] you usually do not expect that every significant result is real and replicable. Rather, you just want to ensure that a controlled high proportion (e.g., 0.95 or more) of the significant results is real and replicable.” FDR control methods have also been used in the social sciences—for example, Anderson (2008) uses FDR control for exploratory analyses and FWER control for confirmatory analyses. However, the concept of the FDR can be difficult to interpret, for several reasons:\n\nAs noted above, the FDR is equivalent to \\(Pr[R > 0] \\times E[V \\, / \\, R \\mid R > 0]\\). Thus, Westfall et al. (2011, p. 496) note that interpreting the FDR as “the expected proportion of false rejections” is reasonable when thousands or millions of null hypotheses are tested and \\(Pr[R > 0]\\) (the probability that at least one null is rejected) is close to 1, but “in cases where \\(R\\) can be \\(0\\) with reasonably high probability, the interpretation of FDR is unclear” (because then \\(E[V \\, / \\, R \\mid R > 0]\\) can be much higher than the FDR) and “it is better to use FWE-controlling methods in these cases” because they “have more straightforward interpretation.”\nThe FDR is defined as an expectation: the average value of \\(V \\, / \\, R\\) across an infinite number of hypothetical replications of the study. “Controlling the FDR” means keeping this expectation less than or equal to some threshold \\(q\\). But this says nothing about the variability of \\(V \\, / \\, R\\) across replications and thus does not by itself control the probability that \\(V \\, / \\, R\\) substantially exceeds \\(q\\) (Efron 2010, pp. 51, 55–57).12\nAs Gelman, Hill, and Yajima (2012) write: “Methods that control for the FDR may make particular sense in fields like genetics where one would expect to see a number of real effects amidst a vast quantity of zero effects such as when examining the effect of a treatment on differential gene expression. … They may be less useful in social science applications when we are less likely to be testing thousands of hypotheses at a time and when there are less likely to be effects that are truly zero (or at least the distinction between zero and not-zero may be more blurry).”\n\n\n\n8 Use a Pre-Analysis Plan To Reduce the Number of Hypothesis Tests\nYou can also reduce the numbers of CATEs and interactions under consideration for hypothesis testing by pre-specifying the tests of primary interest in a registered pre-analysis plan (PAP). Additional subgroup analyses can be conceptualized and specified as exploratory or descriptive analyses in the PAP. Another bonus is that if you prefer a one-sided test, you can commit to that choice in the PAP before seeing the outcome data, so that you “cannot be justly accused of cherry-picking the test after the fact” (Olken 2015).13 See our guide 10 Things to Know About Pre-Analysis Plans for more on pre-registration.\n\n\n9 Automate the Search for Interactions\nMachine learning methods are useful to automate the search for systematic variation in treatment effects. These automated approaches are attractive because they minimize researchers’ use of ad hoc discretion in selecting and testing interactions, and are useful for conducting exploratory analyses.\nPopular machine learning methods include support vector machines (R package FindIt),14 Bayesian additive regression trees (R package BayesTree),15 classification and regression trees (R package causalTree),16 random forests,17 and kernel regularized least squares (R package KRLS).18\nIn addition to single machine learning methods, ensemble methods may be used. Ensemble methods estimate a weighted average of multiple machine learning estimates of heterogeneous effects where the weights are a function of out-of-sample prediction performance.19\n\n\n10 A Note on Interactions between Treatment and Post-Treatment Covariates\nThe discussion thus far has assumed that the treatment effect heterogeneity of interest involves pre-treatment covariates, to ensure unbiased estimation of CATEs and treatment-by-covariate interaction effects.\nSome researchers may be interested in post-treatment effect modification, or the interaction between a treatment and a post-treatment covariate. For example, how do the effects of a job search assistance program vary with participants’ levels of depression during the followup period? Conditioning on a post-treatment covariate may lead to bias, because biased estimation of both the main effect and the interaction effects is possible when a post-treatment covariate is included as a regressor. This is especially likely when the covariate is affected by the treatment.\nThere is a burgeoning body of methodological research on the conditions under which CATEs involving post-treatment covariates are identified. These methods rely on model-based identification.20\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Albert Fang, 3 Jun 2016. Revisions: Winston Lin and Don Green, 16 Jan 2017. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits.↩︎\nThis guide draws heavily from Alan S. Gerber and Donald P. Green (2012), Field Experiments: Design, Analysis, and Interpretation (New York: WW Norton), and from Don Green’s course notes for Experimental Methods at Columbia University.↩︎\nThis is known as the Fundamental Problem of Causal Inference. For more background, see 10 Things You Need to Know About Causal Inference.↩︎\nFor further reading, see Gerber and Green (2012) and Peng Ding, Avi Feller, and Luke Miratrix (2016), “Randomization Inference for Treatment Effect Variation,” Journal of the Royal Statistical Society, Series B 78: 655–671.↩︎\nFor more background and a range of views on the multiple comparisons problem, see, e.g.: 10 Things You Need to Know About Multiple Comparisons; Richard J. Cook and Vern T. Farewell (1996), “Multiplicity Considerations in the Design and Analysis of Clinical Trials,” Journal of the Royal Statistical Society, Series A 159: 93–110; Kenneth F. Schulz and David A. Grimes (2005), “Multiplicity in Randomised Trials I: Endpoints and Treatments,” Lancet 365: 1591–1595; Schulz and Grimes (2005), “Multiplicity in Randomised Trials II: Subgroups and Interim Analyses,” Lancet 365: 1657–1661; Michael L. Anderson (2008), “Multiple Inference and Gender Differences in the Effects of Early Intervention: A Reevaluation of the Abecedarian, Perry Preschool, and Early Training Projects,” Journal of the American Statistical Association 103: 1481–1495; Peter H. Westfall, Randall D. Tobias, and Russell D. Wolfinger (2011), Multiple Comparisons and Multiple Tests Using SAS, 2nd ed.; Andrew Gelman, Jennifer Hill, and Masanao Yajima (2012), “Why We (Usually) Don’t Have to Worry About Multiple Comparisons,” Journal of Research on Educational Effectiveness 5: 189–211.↩︎\nThe Westfall–Young method’s ability to control the FWER depends on a “subset pivotality” assumption that may be violated when outcomes are heteroskedastic or when there are multiple treatment arms. Westfall et al. (2011, p. 421) write: “However, this theoretical shortcoming is only rarely a practical one for continuously distributed data. Experience shows that this issue is most likely to arise in cases with extreme heteroscedasticity and unbalanced sample sizes. … These issues can become even more problematic when testing binary data.” See also Frank Bretz, Torsten Hothorn, and Peter Westfall (2011), Multiple Comparisons Using R, pp. 133–137. Bootstrap methods that relax the subset pivotality assumption are discussed in: Joseph P. Romano and Michael Wolf (2005), “Exact and Approximate Stepdown Methods for Multiple Hypothesis Testing,” Journal of the American Statistical Association 100: 94–108; Romano and Wolf (2005), “Stepwise Multiple Testing as Formalized Data Snooping,” Econometrica 73: 1237–1282; Romano and Wolf (2016), “Efficient Computation of Adjusted \\(p\\)-Values for Resampling-Based Stepdown Multiple Testing,” Statistics and Probability Letters 113: 38–40; John A. List, Azeem M. Shaikh, and Yang Xu (2016), “Multiple Hypothesis Testing in Experimental Economics,” NBER Working Paper 21875.↩︎\nThis description of the algorithm is adapted from Anderson (2008) and Daniel Gubits, Winston Lin, Stephen Bell, and David Judkins (2014), “BOND Implementation and Evaluation: First- and Second-Year Snapshot of Earnings and Benefit Impacts for Stage 2,” Abt Associates report submitted to the Social Security Administration.↩︎\nKristin E. Porter (2016), “Statistical Power in Evaluations That Investigate Effects on Multiple Outcomes: A Guide for Researchers,” MDRC working paper.↩︎\nKatherine S. Pollard, Sandrine Dudoit, and Mark J. van der Laan (2004), “Multiple Testing Procedures: R multtest Package and Applications to Genomics,” working paper; Sandrine Dudoit and Mark J. van der Laan (2008), Multiple Testing Procedures with Applications to Genomics.↩︎\nYoav Benjamini and Yosef Hochberg (1995), “Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing,” Journal of the Royal Statistical Society, Series B 57: 289–300.↩︎\nStrictly speaking, to guarantee that the Benjamini–Hochberg procedure controls the FDR, we need to assume either that the \\(p\\)-values corresponding to the true null hypotheses are independent or that they obey a positive dependence condition. For a brief overview of work addressing dependence, see section 3.2 of Yoav Benjamini (2010), “Discovering the False Discovery Rate,” Journal of the Royal Statistical Society, Series B 72: 405–416.↩︎\nBradley Efron (2010), Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction.↩︎\nBenjamin A. Olken (2015), “Promises and Perils of Pre-Analysis Plans,” Journal of Economic Perspectives 29(3): 61–80.↩︎\nSee, for example, Kosuke Imai and Marc Ratkovic (2013), “Estimating Treatment Effect Heterogeneity in Randomized Program Evaluation,” Annals of Applied Statistics 7(1): 443–470.↩︎\nH. A. Chipman, E. I. George, and R.E. McCulloch (2010), “BART: Bayesian Additive Regression Trees,” Annals of Applied Statistics 4: 266–298; Jennifer L. Hill (2011), “Bayesian Nonparametric Modeling for Causal Inference,” Journal of Computational and Graphical Statistics 20(1): 217–240; Donald P. Green and Holger L. Kern (2012), “Modeling Heterogeneous Treatment Effects in Survey Experiments with Bayesian Additive Regression Trees,” Public Opinion Quarterly 76(3): 491–511.↩︎\nSusan Athey and Guido W. Imbens (2016), “Recursive Partitioning for Heterogeneous Causal Effects,” Proceedings of the National Academy of Sciences 113: 7353–7360.↩︎\nStefan Wager and Susan Athey (2016), “Estimation and Inference of Heterogeneous Treatment Effects using Random Forests,” arXiv.↩︎\nJens Hainmueller and Chad Hazlett (2013), “Kernel Regularized Least Squares: Reducing Misspecification Bias with a Flexible and Interpretable Machine Learning Approach,” Political Analysis.↩︎\nMark van der Laan, Eric Polley, and Alan Hubbard (2007), “Super Learner,” Statistical Applications in Genetics and Molecular Biology 6(1); Justin Grimmer, Solomon Messing, and Sean J. Westwood (2014), “Estimating Heterogeneous Treatment Effects and the Effects of Heterogeneous Treatments with Ensemble Methods,” working paper.↩︎\nFor further reading (at an advanced technical level), see S. Vansteelandt and E. Goetghebeur (2003), “Causal Inference with Generalized Structural Mean Models,” Journal of the Royal Statistical Society, Series B 65: 817–835; Vansteelandt and Goetghebeur (2004), “Using Potential Outcomes as Predictors of Treatment Activity via Strong Structural Mean Models,” Statistica Sinica 14: 907–925; S. Vansteelandt (2010), “Estimation of Controlled Direct Effects on a Dichotomous Outcome using Logistic Structural Direct Effect Models,” Biometrika 97: 921–934; Alisa Stephens, Luke Keele, and Marshall Joffe (2016), “Generalized Structural Mean Models for Evaluating Depression as a Post-Treatment Effect Modifier of a Jobs Training Intervention,” working paper. Footer↩︎"
  },
  {
    "objectID": "guides/getting-started/implementation_en.html",
    "href": "guides/getting-started/implementation_en.html",
    "title": "10 Things to Know About Survey Implementation",
    "section": "",
    "text": "1 Decide whether or not to work with a local firm\nThere are two discrete skill sets needed on the ground when implementing a survey. The first skill set is focused on administration/logistics, and the second skill set is focused on research design. The first set of skills is needed for administration: budgeting, creating route plans, recruitment, and management of staff. Administration requires a level of familiarity with local conditions; for example, the ability to quickly estimate costs and troubleshoot logistical issues are important here. The second skill set requires knowledge of research methods to ensure that survey implementation is consistent with the research design. Researchers must be able to recognize any deviations from the protocol and address them in a way that leads to as little bias as possible. Important here is a deep understanding of the survey protocols and possible alternatives, in the case that changes need to be made on the ground.\nIf you will not be present during survey administration, you will need to either hire a firm or individuals who can work together to cover both sets of needs. There are clear advantages to hiring a firm if you have the budget, the biggest being that firms coordinate internally and balance both sets of needs, ensuring that logistics accommodate the design and vice versa. A possible drawback is that firms frequently have their own protocols, and these default procedures are usually at a lower standard than the latest protocol being used in academia. Upgrading protocols is a costly process and firms may push back against the use of stricter, or simply different, practices.\nIf you will be present during enumeration but you have a small budget, or do not feel you could manage the entire implementation (administration and design) yourself, a good alternative is to hire a field coordinator from a survey or research firm on a consultant basis. This person can help with administration while you take on the design-related work. Additionally, hiring someone for administration locally can do a lot to help with cross-cultural management. The types of management procedures that might work to motivate or sanction employees in the US may not work in another context, so someone who knows what is acceptable and effective can add a lot of value.\n##Contracts with local firms When setting up contracts with local firms it is important to get the incentives right—thorough and good work should also be the most profitable for the firm. You can do a lot to set expectations and incentives in the contract. For example, pay on delivery where possible (although it is customary to pay some costs upfront to cover fixed expenses like transport and early salaries). You can also choose to impose financial penalties for late or low-quality data, but be sure to make these requirements clear up front and provide specific rules for what constitutes low-quality work and how late penalties will be assigned.\nIn addition to direct costs, it is reasonable for a local firm to charge overhead. This can vary from context to context, and it is best to check against the budgets of other similar projects to make sure the rate is reasonable.\n\n\n2 Budgeting\nAs you prepare to begin survey implementation, the first and most important part of the survey is budgeting expected costs. It’s important to be thorough and detailed in putting together your budget; it will be critical throughout implementation and will be closely considered by potential funders.\nThe total cost of a survey is the sum of fixed costs, like transportation and equipment costs, and variable expenses like salaries, per diems, and administration costs. See the attached budget template for an overview of typical costs and notes on how to estimate them.\n##Salaries Estimating total salary costs before drawing the sample (needed in order to determine the teams and route plans) requires a bit of guesswork. One approach is to estimate the work-hours needed to conduct the survey (survey length x sample size) and divide by some estimated number of enumerators to come up with the number of enumerator days you will need to pay. The per diem may need to cover food and lodging, and make this clear to enumerators so they can plan accordingly. For surveys that will require long fieldwork, it is good practice to pay salary on a rest day each week although some enumerators prefer to work continuously in order to finish sooner and return home. This choice is context-specific.\n##Per Diems Per diems cover enumerator’s expenses associated with doing fieldwork. This means lodging for overnight stays, all meals, and sometimes also transportation. Per diems should also be paid on rest days that fall in between work days. In the case that the variation in lodging and food costs is low, it is not important to change the per diem rate according to location. Teams will know when to save and when to spend.\n####Quick calculator: ((survey time to complete * sample size)/workable hours in a day)/# of enumerators = number of days\nnumber of days * (daily rate + per diem) + supervisors = approx. total salary cost\n##Transportation It’s important to, ex ante, be as accurate as possible in estimating the full cost of transportation as this is frequently both least flexible and most variable cost. Typically, it is good practice to build in contingency on the cost of fuel, as the price can change over the several months it takes to go from the grant application stage to the implementation stage. If you are budgeting before drawing your sample, pay particular attention to hard-to-reach areas in your population (islands, places without road access) and pad your transport line for the possibility you randomly sample enumeration areas that carry these higher costs.\n##Equipment Later on in this guide we present the benefits of using personal digital assistants (PDAs) or tablets for data collection (see section 3). PDAs/tablets can be either purchased using survey funds or leased from a research firm, university, or other researchers.\n\n\n3 Should you use PDAs or tablets instead of paper?1\n##Why Personal Digital Assistants [PDAs] or Tablets are better (if you have the budget) Use of a PDA/tablet allows the collection of more accurate and detailed data (Goldstein, 2012) because of:\n\nAutomated skip patterns\nMore detail, e.g. the ability to program a multi-stage code list\nThe ability to program some randomization algorithms (permuted block randomization, for example)\nSensitive questions can be recorded by the respondent themselves on the tablet (instead of the enumerator). There are even ways, using sound and video playback, to do this with illiterate respondents\nThe ability to audio record responses for later transcription\n\nPDAs/tablets have lower error rates than paper-based surveys (Caeyers, 2010) and have superior quality control options including:\n\nReal-time data upload\nReal-time survey modification in the case of error or oversight in terms of questions included\nAudio recording of portions of surveys to verify enumerator delivery\nTimers that measure how long respondents spend on the entire survey and each individual question\nReal-time validation checks to make sure numerical questions don’t have answers that are nonsensical\nThe ability to generate several orthogonal treatments within a single survey (either for multiple experiments or for conjoint experiments)\n\n##Tips for PDA or tablet use * Always buy extra equipment – chargers, battery packs, power strips, and tablets can go missing, be stolen, or get broken. In many countries you can’t buy extra equipment, even in capital cities, and it’s often more expensive and lower quality than what you can get at your home base. Buying 10-20% more equipment than you need can be expensive, but it is usually far cheaper than the salaries that you will have to pay for enumerators with equipment problems who do not have backups. * Pay close attention to battery life when you buy your equipment. If you want full days of enumeration, some of the cheaper tablets will not work. * Budget for extra battery packs for your enumerators to carry in the field, particularly if they will travel to rural areas where they may not always be able to charge the tablets every night. * Forecast how frequently teams will be able to upload recorded data. The PDAs/tablets need to be able to store data from completed interviews until uploading is possible. In rural environments this can mean quite a lot of memory is needed, particularly if the survey is long and/or complex. * Budget extra costs for charging of the PDAs or tablets in the field (i.e. paying for extra generator time from hotels) and for potential delays because of lack of power. * Budget extra time for exhaustive testing of the PDA/tablet once the survey is fully coded. Code failures can be disastrous the more complex the code/randomization becomes. Run through as many different responses to the survey as you can yourself, and do a “fake” pre-test during training in which you collect data and inspect it to make sure there are no errors. * Have someone available to make on-the-spot changes to the code in case problems are discovered in the field that stall enumeration until the change is implemented. In addition, give your enumerators enough paper versions of the survey to last for one or more days to serve as a holdover until the code is remedied. * If possible, name your variables in the survey software to avoid a really laborious process of manually re-naming later. This also makes it easier to inspect the data in real-time. * Code answer values (i.e. the values that will be outputted into the dataset) in advance so that you can standardize scales and easily clean the data (for example, use different negative numbers for “don’t know” and “refuse” options so a 10-character command in R can clean the whole dataset). * Take advantage of having more space for text by giving enumerators directions for complicated items in the displayed question text itself.\n\n\n4 Establish a Management Structure\n\nParallel reporting chains can greatly improve the reliability of data by providing incentives to declare errors and mistakes. Under a parallel structure, oversight staff reports directly to survey manager, while surveying staff reports to field coordinator. The aim is to use the auditing and back checking reports in order to cleanly identify problems, and field supervision to then correct any issues.\n##Surveying Field teams are made up of enumerators and a team leader. Team leaders report to a field manager, or in a case of a large survey, a regional supervisor.\n\nThe enumerator’s role is sampling and selecting households and respondents within enumeration areas, gain consent, and conduct the interview. The enumerator’s tasks include:\n\nSelecting the household. For an enumerator this is the first stage in the random selection process and is done according to a clearly specified procedure, which should be easily referenced in both the manual and the survey instrument itself.\nSelecting respondents. Once the household has been selected, the enumerator should follow a similarly-specified random (or systematic) selection process in order to select the subject.\nConsent. Enumerators need to know the definition of informed consent and how to make sure the respondent understands his/her rights during the interview.\nConducting the interview. This will involve asking questions and closely following the instructions communicated in training and on the questionnaires. A hard copy of question-by-question instructions should be provided to enumerators for use as a reference.\nControlling the interview situation. The enumerator must work towards reducing or eliminating suspicion and prejudice within the interview environment. This may involve asking bystanders not to congregate or dealing with sensitive situations with respect to other family members within the home.\nAvoiding bias. The enumerator’s personal views must not be reflected in the data collected. This means, among other things, that the enumerator must remain neutral and respectful during the data collection by not expressing his or her opinion and ensuring that the respondent trusts that the enumerator will respect his or her privacy. Emphasize during training that there really is no right answer and that the goal of the survey is to find out what people really think – because without knowing that, we can’t find solutions to problems.\nPresentation. Interpersonal skills such as manners, dressing, body language and ability to persuade are all important for data quality and will help in obtaining the target respondents for each day.\n\nThe team leader manages a group of enumerators and can conduct interviews him/herself. The team leader is responsible for:\n\nLogistics. The team leader is responsible for organizing the transport of teams, gathering materials, transporting paper instruments, and managing the technology.\nPermissions. Team leaders make contact with local authorities to introduce and explain the survey and get permission to work.\nSupervising. Team Leaders ensure the team arrives on time to the enumeration area and proceeds to oversee within-enumeration area selection of households.\nCorrecting. Once interviewing has begun, team leaders should move between enumerators and check they are following protocols. Supervision should not, however, make subjects feel uncomfortable.\nData Quality. Team Leaders check all questionnaires in the field and at the end of the day. If PDAs/tablets are used either the team leader or an RA will check data. The team leader ensures that data errors are fixed by revisiting respondents.\n\n\n\n##Oversight Enumeration teams and field management can quite easily deviate from important protocols—these deviations can range from replacing sampled households based on the ease of getting respondents to creating fake data. In many cases, cutting corners is not easy to detect and can save money and time for the enumerators, field managers, and even the survey research firm. PDAs/tablets can reduce the number of total possible types of fraud, but some level of field supervision is always necessary. A parallel reporting structure, with independent oversight, can help guard against these deviations.\nOn the oversight side, there are two types of checks that should be conducted– audits and backchecks:\n\nAuditors arrive at randomly selected villages on the days they are slated for enumeration, without advance warning to the team. When an auditor visits a team, they make sure the team is in the correct enumeration area, that they have sought consent from local leaders, complied with the household selection procedure, and that all team members are working. The auditor then tracks the performance of the team throughout the day— as they seek consent, build rapport, conduct within-enumeration area sampling, and survey respondents.\nA backcheck consists of a revisit to a respondent who completed a survey not more than a few days prior. Using the data collected, they locate respondents and verify responses on a few key questions, for which the response was not likely to have changed (for example, age or household size) in the period since they were initially contacted. Backchecking can both help to identify enumerators who are not performing and establish an error rate. If phone numbers are being collected in the survey, this can be done more cheaply by telephone.\n\nConducting both audits and backchecks means that for each individual survey there is some non-zero probability that the work will be checked in some way. In the case that there are only backchecks, teams will never be monitored in terms of their adherence to protocols as they sample and conduct interviews. In the case that there are only audits, if a team is not visited on a particular day of work there is no chance to check that they actually interviewed subjects and recorded their responses accurately.\nAuditors and backcheckers must report directly to survey management. Imagine an example: Say a village is difficult to find and the team of enumerators chooses a replacement (rather than resampling by the PIs), and the auditors visit the sampled village and uncover it was not surveyed. If this error is communicated to someone also managing the enumerators, their best response is to cover this up or try to fix it without the PI knowing. This prevents having to admit a management mistake, and having to add a day of work to revisit the original or resampled village. If the survey team is notified directly, there is an opportunity to fix the mistake and make personnel changes as needed. Unmonitored communication between auditing teams and enumeration teams can result in a lot of unauthorized fixes and unexplainable data patterns.\n\n\n5 Recruit enumerators\n##Sources If you are working alone, recruit experienced enumerators through contacts at survey firms, NGOs, or universities. It is important that enumerators are experienced, literate, educated, and able to build rapport with subjects. Hiring enumerators who are connected, in some way, with the survey leaders or local coordinator, e.g. through a youth organization or other social tie, can help immensely with oversight as the enumerators have bigger reputational costs if they shirk their duties.\n##Languages The foremost requirement is that the enumerators speak the required local languages. We know that coethnicity between enumerators and subjects can reduce bias, so recruitment of coethnic interviewers, and balancing across the sample if using treatment and control groups, is important.\n##Gender parity Having a team of mostly male enumerators interview a sample with equal numbers of men and women there can introduce response bias. For sensitive questions, such as questions on sexual behavior or violence, it is strongly recommended that women interview other women. If it is difficult to recruit experienced women enumerators, it usually makes sense to hold a special training for women candidates with less experience in order to ensure teams are balanced in the end.\n\n\n6 You must pre-test!\nThere are several different and necessary phases of pre-testing:\n\nThe first pre-test is for instrument clarity and is typically conducted by the researcher(s) or the wider survey team. This step involves a thorough review of the instrument after all the questions have been written—the focus here is on order, clarity, and flow.\nThe second phase of pre-testing focuses on the translated version of the instrument; the key concern is that the questions are easily understood by native speakers while retaining the meaning intended by the researcher. This is best done by a group of translators or members of your survey team, as it often it takes several people to discuss and settle upon the widely understood meaning of words and phrases. If you are translating into multiple languages, it’s important to have people from every language represented for consistency, working together to ensure consistency across versions. Fellow enumerators can work here, but it is better to recruit people of varying education levels.\nThe third phase of pre-testing ensures that respondents understand the intended meaning of each question and are comfortable responding. The best way to get at this is to observe enumerators conduct practice surveys in the field. You’ll want to get as close as you can to the real sample for this test, incorporating different subgroups within the real sample, e.g. men and women, more and less educated. Instruct enumerators on how to identify and record issues, so that they can describe them after to the PI and survey manager, but also observe these practice interviews first-hand. Key concerns are clarity and length: respondents should not become confused, tired, unfocused, or disinterested. You want to understand how the questions are understood by respondents and if enumerators are changing questions at all during the survey. This step will also, importantly, give the project team a good idea of how long the average survey should take, so you can adjust expectations of how many surveys can be done per enumerator per day.\n\n\n\n7 Training\n##Standards Trainings establish consistent standards for data collection. If you are contracting a survey firm and are not on the ground yourself, training is the most important part of the process to personally attend. It’s a key moment to communicate quality standards, expectations, the intended meaning of each question, and teach important procedures that may be more technical than what the firm is used to, such as a list experiment. It is also a key moment to motivate the team, by communicating the project’s goals and importance. In order to ensure that the each member of the team is prepared to a certain standard, it is a good idea to test each team member at the end of the training period. There should be an expectation that some team members will be asked not to proceed any further with the project as a result of the test, which will emphasize the importance of taking training to heart and taking the test seriously.\n##Assessment Trainings are a key moment for assessment as well. If you train teams together it is easy to spot management issues and leadership capabilities. A good practice is to train teams together, and select team leaders at the end of training—this gives you a few days to gauge skills and also incentivizes trainees to perform during the training.\n##Participation Trainings set the tone for the rest of fieldwork. Beyond communicating standards and expectations, this is also a key moment to create a culture of participation. Encouraging trainees to speak out about issues with the survey can show that you are open to feedback and increase the chances that they will report adverse events or challenges during the actual data collection.\nTraining sections:\n\nProtocol review, e.g. how to get permission to work in village/household, how to select respondent, etc.\nDiscussion of unforeseen contingencies, e.g. what happens when you get a refusal, when enumerators are targeted or threatened, when enumerators observe perverse reactions to or consequences of the survey\nQuestion by question review\nInterviewing techniques (rapport building, discussions)\nReview translated instrument\nUsing a PDA/tablet and conducting the interview on a PDA/tablet\nUsing GPS\nGroup practice (enumerators interview each other and get feedback)\nField practice– at least one day of training (or more for complicated or long surveys) should be spent interviewing real people who are similar to the survey subjects\nCertification exam\n\nTraining usually takes several more days than you expect. See below for a rough guide to realistic training schedules.\n\nList of documents needed for training:\n\nInstrument + translated instrument\nQuestion-by-question guide\nManual with expectations, instructions for filling responses, tips on interviewing etc.\nProtocol for sampling, consent, reporting, and unforeseen contingencies\n\nBefore being deployed to the field, each enumerator must:\n\nBe able to correctly list, sample and interview individuals in the enumeration area\nUnderstand their role\nUnderstand and correctly follow interviewing protocols\nBe informed about oversight procedures\nComplete an IRB-approved module on human subjects protection\n\nData from mock surveys must be individually assessed and feedback given to each enumerator. You can check whether certain enumerators are entering data differently than their peers, for example by entering lots of “Don’t know” or “Refuse” answers, finding low prevalence of sensitive behaviors, or entering data that is logically inconsistent. However, there is a lot that you can’t tell from the data alone. Spending a lot of time observing enumerators while they run surveys can greatly increase the quality of the data by improving their training, allowing you to select the best enumerators more accurately, and allowing you to understand how the questions are being implemented in the field.\n\n\n8 Employee incentives\nTo a large extent, the quality of the data collected is determined by the behavior the enumerators. Throughout the hiring, training, and field stages of the survey it is important to get the incentives right so that enumerators are motivated to do high quality work.\n##Expectations and Quality Control Expectations should be laid out clearly during training, in a manual, and reiterated in clearly worded contracts (signed after training).\nBasic expectations of enumerators:\n\nBeing on time\nAdhering to within-enumeration area sampling and replacement scheme\nGetting informed consent\nBuilding rapport with subjects\nAccurately recording responses\nCommunication with supervisors\n\n##Contracts and Payment As much as possible, make payment dependent on delivery. Enumerators have less and less incentive to stick with the project towards the end of fieldwork. The marginal returns are lower and they may be concerned about finding new work. In order to offset this, it is good practice to withhold a portion of their total salary (+/- 30%) until the end of fieldwork, and sometimes until data has been thoroughly reviewed if using paper instruments that need to be entered manually. At the same time, enumerators are often living paycheck to paycheck and may have expenses to cover during their long absence in the field. It is important to pay an advance up front to allow enumerators to take care of personal expenses that may otherwise make them anxious and unhappy during fieldwork. Having a strong local manager who understands the enumerators financial situations can help you create incentives while still making sure that they perceive the compensation structure as fair and adequate.\n##Soft Incentives Soft incentives help to keep teams happy and motivated throughout work. Some examples are:\n\nPerformance-based bonuses: Allowing managers to give performance-based bonuses for exceptional performance on a daily or weekly basis.\nCertificates: Survey trainings often involve learning portable skills, like the use of tablets or PDAs. Certificates can help enumerators prove to new employers that that they have these skills.\nLetters of Recommendation\nRecommendations to other survey firms, NGOs, etc.\nWrap party\n\n\n\n9 Map out your routes\nMake route plans that set the order in which enumeration areas [EAs] will be covered, and then assign teams to routes. The basic idea is to minimize transportation costs while taking into account regional differences in languages or dialects that could mean that only some teams can work in certain areas.\nA good way to visualize route plans is to mark sampled EAs on a map, using different colors to indicate different languages spoken in each EA. [SAMPLE PHOTO HERE]. Rely on team leaders to gauge travel time between sampled points and to suggest best routes.\n\n\n10 Checking the data\nWrite code to clean data and check for errors, and run it on available data as soon as possible. This code should check for nonsensical responses or patterns, both within and across instruments (enumerator error).\nIf you are using tablets or PDAs, you should begin to run the cleaning and error script on the incoming data as soon as interviewing begins. If you are not using PDAs/tablets, you’ll need to develop a procedure for checking the paper instruments in the field (the job of the team leader), and also begin checking and cleaning of entered data as soon as possible.\n##Checking data entered from paper instruments After interviewing the team leader needs to review all instruments for completeness and accuracy. If there are missing data or other inconsistencies, the team leader should send the enumerator back to revisit the respondent to correct all problems before leaving the area.\nOnce instruments are collected, data entry should commence as soon as possible. All data should be entered twice, and any discrepancies should be checked by a supervisor against the paper instrument.\n##Checking data gathered using PDAs or tablets When using tablets or PDAs, checking the data is the responsibility of the RA and PIs. In addition to using a script that checks for patterns and outliers, it is also best practice to record selected portions of the interview and listen to a subsample of responses, both for errors and quality.\n\n\n\n\n\nFootnotes\n\n\nThanks to Brandon de la Cuesta for help with this section↩︎"
  },
  {
    "objectID": "guides/getting-started/late_en.html",
    "href": "guides/getting-started/late_en.html",
    "title": "10 Things You Need to Know About the Local Average Treatment Effect",
    "section": "",
    "text": "Abstract\nSometimes a treatment or a program is delivered but for some reason or another only some individuals or groups actually take the treatment. In this case it can be hard to estimate treatment effects for the whole population. For example maybe people for whom the treatment would have had a big effect decided not to take up the treatment. In these cases it is still possible to estimate what’s called the “Local Average Treatment Effect,” or LATE. This guide1 discusses the LATE: what it is, how to estimate it, and how to interpret it.2\n\n\n1 What the LATE is\nWhen subjects do not receive the treatment to which they were assigned, the experimenter faces a “noncompliance” problem. Some subjects may need the treatment so badly that they will always take up treatment, irrespective of whether they are assigned to the treatment or to the control group. These are called “Always-Takers”. Other subjects may not take the treatment even if they are assigned to the treatment group: the “Never-Takers”. Some subjects are “Compliers”. These are the subjects that do what they are supposed to do: they are treated when assigned to the treatment group, and they are not treated when they are assigned to the control group. Finally, some subjects do the exact opposite of what they are supposed to do. They are called “Defiers”. Table 1 shows these four different types of subjects in the population.\n\nNoncompliance can make it impossible to estimate the average treatment effect (ATE) for the population. For example, say that in a population of 200, 100 people are randomly assigned to treatment and we find that only 80 people are actually treated. What is the impact of the treatment? One method to answer this question is simply to ignore the noncompliance and compare the outcome in the treatment (100 people) and control (100 people) groups. This method estimates the average intention-to-treat effect (ITT). (See our guide on different kinds of treatment effects for more on the ITT.) While informative, this method does not give a measure of the effect of the treatment itself. Another approach would be to compare the 120 really-untreated and 80 really-treated subjects. Doing so, however, might give you biased estimates. The reason is that the 20 subjects that did not comply with their assignment are likely to be a nonrandom subset of those that were assigned to treatment.\nSo what now? In some cases it is possible to estimate the “Local Average Treatment Effect” (LATE), also known as the “Complier Average Causal Effect” (CACE). The LATE is the average treatment effect for the Compliers. Under assumptions discussed below, the LATE equals the ITT effect divided by the share of compliers in the population.\n\n\n2 With one-sided noncompliance you need to satisfy an exclusion restriction to estimate the LATE\nThe example introduced above is termed one-sided noncompliance: 80% of the population respond to the treatment assignment (the “Compliers”) and 20% do not (the “Never-Takers”). Say that after the treatment, the experimenter measures the average outcome to be 50 in the treatment group and 10 in the control group. This situation is illustrated in Table 2. Note that only those indicated with blue in Table 2 were in fact treated.\n\nBefore we can calculate the LATE under one-sided noncompliance we need to make an assumption. The exclusion restriction (also called “excludability”) stipulates that outcomes respond to treatments, not treatment assignments. In normal words this simply means that the outcome for a Never-Taker is the same regardless of whether they are assigned to the treatment or control group: in both cases the subject is not treated, and that is what matters.\nBecause the treatment was randomly assigned, we know that if there are 20% Never-Takers in the treatment group (left column), there are probably about 20% Never-Takers in the control group. Because of the exclusion restriction, the Never-Takers have the same outcome under both assignment conditions, and thus the difference in average outcomes (40) cannot be attributed to the Never-Takers. We can thus attribute the entire ITT effect to the Compliers. The LATE can therefore be estimated by dividing the ITT estimate by the share of Compliers: 40/0.8 = 50.\n\n\n3 With two-sided noncompliance the LATE can be estimated assuming both the exclusion restriction and a “no defiers” assumption\nThe experimenter may also face two-sided noncompliance. In this case, some subjects in the treatment group go untreated and some in the control group receive the treatment. In this world, the population consists of the Compliers, the Never-Takers, the Always-Takers, and the Defiers. To estimate LATE under two-sided noncompliance we need a second assumption: that the population contains no Defiers (the assumption is also called the “monotonicity” assumption). To see the use of this assumption look at Table 3, which illustrates our example under two-sided noncompliance. Again, after the treatment the experimenter measures the average outcome to be 50 in the treatment group and 10 in the control group. Note that those subjects in blue were in fact treated.\n\nWith the exclusion restriction and the no Defiers assumption we can estimate the LATE. Because of the exclusion restriction, we can attribute the entire ITT effect to Compliers and not to Never-Takers or Always-Takers. Given that we have an estimate of the ITT effect (40), what remains is to estimate the share of Compliers in the population. (Table 3 shows the subjects’ types as seen by an omniscient deity. The experimenter cannot observe these types, but can estimate their shares, as explained below.)\nWe cannot observe whether any given subject is a Complier, but we do observe whether they took the treatment. In the treatment group, we observe that 90 people took the treatment (and thus must be either Compliers or Always-Takers) and 10 did not (and thus must be Never-Takers, since there are no Defiers). Thus, 10% of the treatment group are Never-Takers, and since treatment was assigned randomly, we estimate that about 10% of the control group are Never-Takers. Similarly, in the control group, we observe that 10 people took the treatment (and thus must be Always-Takers, since there are no Defiers) and 90 did not (and thus must be either Compliers or Never-Takers). Thus, 10% of the control group are Always-Takers, and we estimate that about 10% of the treatment group are Always-Takers. From all this, we can estimate the share of Compliers as 100% - 10% (Never-Takers) - 10% (Always-Takers) = 80%. Finally, we can estimate the LATE as 40/0.8=50.\n\n\n4 You can estimate the LATE using an instrumental variables approach\nThe LATE estimate is equivalent to an instrumental variables estimate. This is most easily illustrated following a set of regressions. Say that 50 individuals from a population of 100 are randomly assigned to treatment. Regressing treatment status (D) on the treatment assignment (Z) gives the estimated share of compliers: 80%. The ITT effect is estimated by regressing outcome Y on the assignment to treatment (Z). Again, LATE is estimated by dividing the ITT estimate by the estimated share of compliers. A researcher will get exactly the same results when running a two-stage least squares (2SLS) regression in which the outcome (Y) is regressed on the treatment (D), using the assignment to treatment as an instrumental variable (Z). This is shown in the code below.\n\nZ <- rep(0:1,50) # Assign 50 to treatment group (Z = 1), 50 to control group (Z = 0)\nD <- Z           # Compliers have D (treatment received) = Z (treatment assignment)\nD[1:10]  <- 0    # 10 Never Takers\nD[11:20] <- 1    # 10 Always Takers\nY        <- 50*D # Compliers have Y = 50 if treated, 0 if not treated\nY[1:10]  <- 100  # Never takers have high Y\nY[11:20] <- 0    # Always takers have low Y\n# Estimated share of compliers \nITTD <- coef(lm(D~Z))[2] \n# Estimated intention-to-treat effect\nITT  <- coef(lm(Y~Z))[2] \n# LATE estimate\nLATE <- ITT / ITTD\ncbind(Y_1 = mean(Y[Z==1]), Y_0=mean(Y[Z==0]), ITTD, ITT, LATE)\n\n  Y_1 Y_0 ITTD ITT LATE\nZ  50  10  0.8  40   50\n\n# library(AER) \nsummary(ivreg(Y~ D | Z)) \n\n\nCall:\nivreg(formula = Y ~ D | Z)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n   -55     -5     -5     -5     95 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.000      5.660   0.883    0.379    \nD             50.000      8.839   5.657 1.53e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 35.36 on 98 degrees of freedom\nMultiple R-Squared: -0.1136,    Adjusted R-squared: -0.125 \nWald test:    32 on 1 and 98 DF,  p-value: 1.528e-07 \n\n\n\n\n5 How to conduct statistical inference about the LATE\nBecause the LATE equals the ratio of the ITT and the share of Compliers, the LATE will be equal to zero whenever the ITT equals zero. To test the null hypothesis that the LATE is zero, you can thus rely on tests of the null hypothesis that the ITT is zero. This is a straightforward way to go if you would like to rely on randomization inference for hypothesis tests. (See our guides on hypothesis testing and randomization inference for more.) Alternatively, you can make use of the conventional standard errors and confidence intervals generated by instrumental variables regression, which rely on parametric assumptions about the sampling distribution. As a rule of thumb, the standard error of the CACE will be roughly equal to the standard error of the ITT divided by the share of Compliers.\n\n\n6 The LATE only reflects treatment effects among compliers\nWhile a LATE estimate is better than nothing, it provides a consistent estimate of the average treatment effect only for a subgroup of the population: the Compliers. It does not capture effects of the treatment among everyone in the experimental sample (ATE). For instance, Angrist and Evans (1998) study the effect of childbearing on a mother’s labor supply. In their paper, compliers account for only 6% of the total population, while we would like to know the effect for everyone, or at least for a larger subgroup of the population of interest.3 Whether or not only obtaining the effect for Compliers is problematic depends on an experimenter’s objectives. Sometimes the LATE is exactly what the researcher is interested in: the average effect on those that actually comply with the assignment to treatment. Moreover, LATE might not be very different from the ATE if the share of compliers is large and the treatment effects for the different types in the population are similar enough. To explore the latter, researchers can compare the background attributes of the Compliers and Never-takers in the treatment group. Another approach is to compare the average outcomes of Always-Takers and Compliers among those that are treated (those in blue in Table 3), and the average outcomes of Never-Takers and Compliers among those that are not treated.4 Finally, it is important to keep in mind that whether a subject is a Defier, Complier, Never-Taker or Always-Taker also depends on the experimental design and the context in which the experiment is conducted. For example, using phone calls instead of a monetary incentive to encourage treatment take-up can alter the share of compliers in the population. As a result, different instruments will estimate different LATEs.\n\n\n7 The LATE estimate is always larger than the ITT estimate\nThe LATE estimate is calculated as the intention-to-treat estimate (ITT) divided by the estimated share of Compliers in the population. With noncompliance, the share of Compliers in the population is smaller than one. As a result, the LATE estimate will always be larger than the ITT estimate. Another way to look at this is that following the exclusion restriction (reminder: the exclusion restriction states that the outcome for a Never-Taker or Always-Taker is the same regardless of whether they are assigned to the treatment or control group), the ITT effect for the Never-Takers and the Always-Takers is zero. Thus, given any positive number of Never and/or Always-Takers, the average ITT effect is smaller than the LATE.\n\n\n8 The LATE is an important estimand in “encouragement” designs and in downstream experiments\nEncouragement Designs: In an encouragement design, subjects are randomly invited to participate in the treatment. The reason to do so is that in some cases it might be unethical to make subjects adhere to the treatment assignment. In other cases, it might require unnecessarily large incentives to obtain adherence. As a result, in encouragement designs subjects self-select into treatment. For example, Hirano et al (2000) study the impact of a letter encouraging inoculation of patients at risk for flu, sent to a randomly selected set of physicians. The outcome of interest is an indicator for flu-related hospital visits. Needless to say, the incentives for the treatment (the letter) have only a limited effect on the actual treatment received (a flu shot by the physician), and thus the study population will consist of Compliers, Always-Takers, and Never-Takers. (We assume there are no Defiers, patients who would get the flu shot if and only if their physician did not get the letter.) It is thus easy to see how such an encouragement design corresponds to the two-sided noncompliance case.5\nDownstream experiments: Downstream experiments are studies in which an initial randomization (e.g. distribution of school vouchers) causes a change in an outcome (e.g. education level), and this outcome is then considered a treatment affecting a subsequent outcome (e.g. income).6 Also, these experiments correspond to our two-sided noncompliance setup. Noncompliance occurs because the random intervention is just one of many “encouragements” that cause people to take the treatment. Downstream experiments place particular pressure on the exclusion restriction, which requires that (following the example) school vouchers influences income only through higher education. This assumption would be violated if school vouchers affected income for reasons other than education.\n\n\n9 You can use a placebo-controlled design to identify the LATE\nAnother strategy to estimate the LATE involves designing your experiment in such a way that you can find out who the Compliers are even among those who did not receive the treatment. One way to do so is to create a placebo group that receives a version of the treatment without the treatment’s “active ingredient.” Gerber, Green, Kaplan, and Kern (2010), for example, study the effect of an automated phone call that delivers an encouragement to vote on whether study participants turn out to vote.7 The experiment included a placebo group in which study participants received automated phone calls that encouraged them to recycle. Because respondents in the placebo group also received calls, it is possible to observe which respondents in the placebo group answered the phone. Under the assumption that the content of the phone call does not affect who answers the phone, one can estimate the LATE by comparing turnout rates among those who answered the phone in the treatment group to turnout rates among those who answered the phone in the placebo group. The key assumption which makes this strategy work is that respondents who comply with the treatment (pick up the voting phone call) also comply with the placebo (pick up the recycling phone call) and vice versa. Gerber, Green, Kaplan, and Kern (2010) discuss the advantages of having both a pure control and a placebo group for estimating the LATE.\n\n\n10 Addressing partial compliance can be complicated\n“Partial compliance” occurs when a subject is assigned to a treatment but receives less than “all” of the treatment. This is possible in designs with compound treatments, multi-arm designs like factorial designs, and in dose-response trials where the treatment variable is continuous. For example, subjects assigned to a three-session job training program may only attend two of the three sessions. Patients in a clinical trial assigned to receive 100 mg dosages of an experimental drug once every week for five weeks may only receive four of the five assigned doses. Addressing partial compliance can be especially complicated because the effective number of treatment conditions exceeds the number intended in the original design. This expansion of the number of treatment conditions affects the definition of the LATE and how to estimate it. First, the number and definition of compliance statuses changes. The categories used in designs with a binary treatment (Always-Takers, Never-Takers, Compliers, and Defiers) no longer suffice. Instead, the set of possible compliance statuses is determined by all possible combinations of treatment assignment and treatment receipt. In the binary case, we ruled out Defiers. In the partial compliance case, we can make similar (design-specific) monotonicity assumptions that rule out some theoretically possible compliance statuses. Finally, we are no longer interested in a single LATE. Partial compliance means that the number of quantities we are trying to estimate increases. Unfortunately, the IV/2SLS estimator used under one- and two-way noncompliance in two-group designs is a biased estimator of LATEs under partial compliance. Instead, Bayesian approaches have emerged as an alternative method for inference.8\n\n\n\n\n\nFootnotes\n\n\nOriginating author: Peter van der Windt, 20 October 2014. Revisions: Winston Lin, 22 August 2016. The guide is a live document and subject to updating by EGAP members at any time; contributors listed are not responsible for subsequent edits. Thanks to Albert Fang for point 10.↩︎\nFor more extensive overviews, see: J. D. Angrist, G. W. Imbens, and D. B. Rubin (1996), “Identification of Causal Effects Using Instrumental Variables” (with discussion), Journal of the American Statistical Association 91: 444-472; J. D. Angrist (2006), “Instrumental Variables Methods in Experimental Criminological Research: What, Why and How,” Journal of Experimental Criminology 2: 23-44; J. D. Angrist and J.-S. Pischke (2009), Mostly Harmless Econometrics, sections 4.4-4.6 and 6.2; T. Dunning (2012), Natural Experiments in the Social Sciences; M. Baiocchi, J. Cheng, and D. S. Small (2014), “Instrumental Variable Methods for Causal Inference,” Statistics in Medicine 33: 2297-2340 (with correction in Statistics in Medicine 33: 4859-4860).↩︎\nAngrist, J. D. Evans, W. N. 1998. Children and their Parents’ Labor Supply: Evidence from Exogenous variation in family size. American Economic Review, 88(3), 450-477.↩︎\nSee: Imbens, G. W. (2010). Better LATE Than Nothing: Some Comments on Deaton (2009) and Heckman and Urzua (2009). Journal of Economic Literature, 48, 399-423. And Imbens, G. W., & Angrist, J. D. (1994). Identification and Estimation of Local Average Treatment Effects. Econometrica, 62(2), 467-475, and 2). And Imbens, G. W. & Wooldridge, J. 2007. Lecture notes and slides at: http://www.nber.org/minicourse3.html.↩︎\nHirano, K., Imbens, G.W., Rubin, D.B. & Zhou, X. (2000). Assessing the Effect of an Influenza Vaccine in an Encouragement Design. Biostatistics, 1(1), 69-88.]↩︎\nSee: Green, D. P. & Gerber, A. S. 2002. The Downstream Benefits of Experimentation. Political Analysis, Vol. 10(4), 394-402.↩︎\nSee Gerber, Alan S., Donald P. Green, Edward H. Kaplan, and Holger L. Kern. 2010. “Baseline, Placebo, and Treatment: Efficient Estimation for Three-Group Experiments.” Political Analysis, Vol.18(3), 297-315.↩︎\nSee Qi Long, Roderick J. A. Little, and Xihong Lin. 2010. Estimating Causal Effects in Trials Involving Multi-Treatment Arms Subject to Non-compliance: A Bayesian framework. Journal of the Royal Statistical Society: Series C (Applied Statistics), 59(3): 513-531.; Jin, H. & Rubin, D. B. (2009). Public schools versus private schools: Causal inference with Partial Compliance. Journal of Educational and Behavioral Statistics, 34, 24-45; Jin, H. & Rubin, D. B. (2008). Principal Stratification for Causal Inference with Extended Partial Compliance. Journal of the American Statistical Association, 103, 101-111.↩︎"
  }
]